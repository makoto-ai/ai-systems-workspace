#!/usr/bin/env python3
"""
Data-Driven Quality Fixer
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãåŠ¹æœçš„ãªå“è³ªä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 

Phase 13-B: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®å“è³ªæ”¹å–„
æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ãŸä¿®æ­£å‡¦ç†
"""

import json
import os
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

class DataDrivenFixer:
    def __init__(self):
        self.workspace = Path.cwd()
        self.out_dir = self.workspace / "out"
        self.learning_data = self._load_learning_data()
        self.success_patterns = self._analyze_success_patterns()
        
    def _load_learning_data(self) -> Dict[str, Any]:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        data = {}
        
        # ä¸»è¦ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
        learning_files = [
            "adaptive_guidance.json",
            "autonomous_fix_results.json", 
            "learning_insights.json",
            "auto_guard_learning.json"
        ]
        
        for filename in learning_files:
            file_path = self.out_dir / filename
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data[filename] = json.load(f)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ in {filename}: {e}")
                    data[filename] = {}
        
        return data
        
    def _analyze_success_patterns(self) -> Dict[str, Any]:
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        insights = self.learning_data.get("learning_insights.json", {})
        fix_rates = insights.get("fix_success_rates", {})
        
        return {
            "yaml_fixes": {
                "count": fix_rates.get("yaml_fixes", 0),
                "approach": "æ®µéšçš„ä¿®æ­£",
                "priority": "high"
            },
            "context_warnings": {
                "count": fix_rates.get("context_warnings", 0),
                "approach": "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿®æ­£", 
                "priority": "high"
            },
            "bash_syntax": {
                "count": fix_rates.get("bash_syntax", 0),
                "approach": "æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å¾Œä¿®æ­£",
                "priority": "medium"
            }
        }
    
    def apply_yaml_fixes(self) -> Dict[str, Any]:
        """YAMLã‚¨ãƒ©ãƒ¼ä¿®æ­£ï¼ˆæˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³æ´»ç”¨ï¼‰"""
        print("ğŸ”§ YAMLä¿®æ­£é–‹å§‹ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•ï¼‰...")
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "method": "data_driven_yaml_fix",
            "success_pattern_applied": True,
            "fixes_applied": []
        }
        
        try:
            # yamllintå®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼æ¤œå‡ºï¼‰
            cmd = ["yamllint", ".github/workflows/", "-f", "parsable"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                results["status"] = "no_errors_found"
                results["message"] = "YAML ã‚¨ãƒ©ãƒ¼ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
                return results
            
            # ã‚¨ãƒ©ãƒ¼è§£æã¨ä¿®æ­£
            errors = result.stdout.strip().split('\n')
            yaml_files = set()
            
            for error in errors:
                if error and ':' in error:
                    file_path = error.split(':')[0]
                    yaml_files.add(file_path)
            
            # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãä¿®æ­£å‡¦ç†
            for file_path in yaml_files:
                fix_result = self._apply_safe_yaml_fix(file_path)
                results["fixes_applied"].append(fix_result)
            
            results["status"] = "completed"
            results["total_files_processed"] = len(yaml_files)
            
        except Exception as e:
            results["status"] = "error"
            results["error"] = str(e)
        
        return results
    
    def _apply_safe_yaml_fix(self, file_path: str) -> Dict[str, Any]:
        """å®‰å…¨ãªYAMLä¿®æ­£ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨ï¼‰"""
        fix_result = {
            "file": file_path,
            "timestamp": datetime.now().isoformat(),
            "approach": "data_driven_safe_fix"
        }
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_path = f"{file_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            subprocess.run(["cp", file_path, backup_path], check=True)
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨
            # Line-length ã‚¨ãƒ©ãƒ¼ã®å ´åˆ â†’ ã‚³ãƒ¡ãƒ³ãƒˆæ”¹è¡Œ
            # Indentation ã‚¨ãƒ©ãƒ¼ã®å ´åˆ â†’ ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
            # Truthy ã‚¨ãƒ©ãƒ¼ã®å ´åˆ â†’ å¼•ç”¨ç¬¦è¿½åŠ 
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³1: é•·ã„è¡Œã®ã‚³ãƒ¡ãƒ³ãƒˆæ”¹è¡Œ
            lines = content.split('\n')
            modified = False
            
            for i, line in enumerate(lines):
                # 120æ–‡å­—ã‚’è¶…ãˆã‚‹è¡Œã®å‡¦ç†
                if len(line) > 120 and '#' in line and not line.strip().startswith('#'):
                    comment_pos = line.find('#')
                    if comment_pos > 80:  # ã‚³ãƒ¡ãƒ³ãƒˆä½ç½®ãŒå¾ŒåŠã«ã‚ã‚‹å ´åˆ
                        before_comment = line[:comment_pos].rstrip()
                        comment_part = line[comment_pos:]
                        indent = len(line) - len(line.lstrip())
                        
                        # ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ¬¡ã®è¡Œã«ç§»å‹•
                        lines[i] = before_comment
                        lines.insert(i + 1, ' ' * indent + comment_part)
                        modified = True
                        break
            
            if modified:
                content = '\n'.join(lines)
            
            # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                fix_result["status"] = "applied"
                fix_result["changes"] = "line_length_comment_fix"
                fix_result["backup"] = backup_path
            else:
                # å¤‰æ›´ãªã—ã®å ´åˆã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
                os.remove(backup_path)
                fix_result["status"] = "no_changes_needed"
            
        except Exception as e:
            fix_result["status"] = "error"
            fix_result["error"] = str(e)
        
        return fix_result
    
    def analyze_ide_warnings(self) -> Dict[str, Any]:
        """IDEè­¦å‘ŠçŠ¶æ³ã®åˆ†æ"""
        print("ğŸ“Š IDEè­¦å‘ŠçŠ¶æ³åˆ†æä¸­...")
        
        analysis = {
            "timestamp": datetime.now().isoformat(),
            "method": "ide_warning_analysis",
            "phase13a_effect": None
        }
        
        try:
            # yamllint ã§ç¾åœ¨ã®çŠ¶æ³ç¢ºèª
            cmd = ["yamllint", ".github/workflows/", "-f", "parsable"]
            yamllint_result = subprocess.run(cmd, capture_output=True, text=True)
            
            analysis["yamllint_errors"] = len(yamllint_result.stdout.strip().split('\n')) if yamllint_result.stdout.strip() else 0
            
            # actionlint ã§ç¢ºèª
            try:
                cmd = ["actionlint", ".github/workflows/"]
                actionlint_result = subprocess.run(cmd, capture_output=True, text=True)
                analysis["actionlint_errors"] = len(actionlint_result.stdout.strip().split('\n')) if actionlint_result.stdout.strip() else 0
            except FileNotFoundError:
                analysis["actionlint_errors"] = "tool_not_found"
            
            # shellcheck ã§ç¢ºèª
            try:
                cmd = ["find", ".github/workflows/", "-name", "*.yml", "-exec", "grep", "-l", "run:", "{}", "\\;"]
                workflow_files = subprocess.run(cmd, capture_output=True, text=True).stdout.strip().split('\n')
                
                shellcheck_errors = 0
                for file in workflow_files:
                    if file and os.path.exists(file):
                        cmd = ["shellcheck", "--format=json", file]
                        result = subprocess.run(cmd, capture_output=True, text=True)
                        if result.stdout:
                            try:
                                shellcheck_data = json.loads(result.stdout)
                                shellcheck_errors += len(shellcheck_data)
                            except json.JSONDecodeError:
                                pass
                
                analysis["shellcheck_errors"] = shellcheck_errors
                
            except Exception:
                analysis["shellcheck_errors"] = "analysis_failed"
            
            # Phase 13-A åŠ¹æœã®è©•ä¾¡
            total_errors = 0
            if isinstance(analysis["yamllint_errors"], int):
                total_errors += analysis["yamllint_errors"]
            if isinstance(analysis["actionlint_errors"], int):
                total_errors += analysis["actionlint_errors"]
            if isinstance(analysis["shellcheck_errors"], int):
                total_errors += analysis["shellcheck_errors"]
                
            analysis["total_linter_errors"] = total_errors
            analysis["phase13a_effect"] = "significant_improvement" if total_errors < 5 else "partial_improvement"
            
        except Exception as e:
            analysis["error"] = str(e)
        
        return analysis
    
    def generate_learning_report(self) -> Dict[str, Any]:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("ğŸ“ˆ å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "phase": "13-B",
            "title": "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•å“è³ªæ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆ",
            "success_patterns": self.success_patterns,
            "ide_analysis": self.analyze_ide_warnings(),
            "recommendations": []
        }
        
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ¨å¥¨äº‹é …
        yaml_success = self.success_patterns["yaml_fixes"]["count"]
        if yaml_success > 0:
            report["recommendations"].append({
                "priority": "high",
                "action": "YAMLä¿®æ­£ã®ç¶™ç¶šå¼·åŒ–",
                "reason": f"éå»{yaml_success}ä»¶ã®æˆåŠŸå®Ÿç¸¾",
                "method": "æ®µéšçš„ä¿®æ­£ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ´»ç”¨"
            })
        
        context_success = self.success_patterns["context_warnings"]["count"] 
        if context_success > 0:
            report["recommendations"].append({
                "priority": "high",
                "action": "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè­¦å‘Šã®ä½“ç³»çš„è§£æ¶ˆ",
                "reason": f"éå»{context_success}ä»¶ã®æˆåŠŸå®Ÿç¸¾",
                "method": "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨"
            })
        
        # autonomous_fix æ”¹å–„ææ¡ˆ
        autonomous_data = self.learning_data.get("autonomous_fix_results.json", {})
        if autonomous_data.get("success_rate", 1.0) < 0.5:
            report["recommendations"].append({
                "priority": "medium",
                "action": "autonomous_fix æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹å¼·åŒ–",
                "reason": f"ç¾åœ¨ã®æˆåŠŸç‡: {autonomous_data.get('success_rate', 0):.1%}",
                "method": "ã‚ˆã‚Šå®‰å…¨ãªæ®µéšçš„æ¤œè¨¼ã®å®Ÿè£…"
            })
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ Phase 13-B: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•å“è³ªæ”¹å–„é–‹å§‹")
    print("=" * 50)
    
    fixer = DataDrivenFixer()
    
    # 1. IDEè­¦å‘Šåˆ†æ
    ide_analysis = fixer.analyze_ide_warnings()
    print(f"ğŸ“Š ç¾åœ¨ã®ãƒªãƒ³ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼æ•°: {ide_analysis.get('total_linter_errors', 'unknown')}")
    
    # 2. YAMLä¿®æ­£ã®å®Ÿè¡Œ
    yaml_results = fixer.apply_yaml_fixes()
    print(f"ğŸ”§ YAMLä¿®æ­£çµæœ: {yaml_results.get('status', 'unknown')}")
    
    # 3. å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = fixer.generate_learning_report()
    
    # çµæœä¿å­˜
    output_file = Path("out/phase13b_learning_report.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")
    print("ğŸŠ Phase 13-B å®Œäº†ï¼")

if __name__ == "__main__":
    main()



