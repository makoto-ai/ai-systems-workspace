#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ 
Gité€£æºã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è‡ªå‹•åŒ–

ä½œæˆæ—¥: 2025-08-09
ç›®çš„: ã‚«ãƒ¼ã‚½ãƒ«ãŒæ¶ˆã—ã¦ã‚‚ git log ã§å¾©å…ƒå¯èƒ½ã«ã™ã‚‹
"""

import os
import json
import subprocess
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
import shutil
import hashlib

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/auto_backup.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AutoBackupSystem:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.backup_dir = self.project_root / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        self.config_file = self.project_root / "backup_config.json"
        self._load_config()
        
        # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.critical_paths = [
            ".cursor/",
            "config/",
            "app/",
            "paper_research_system/",
            "modules/",
            "scripts/",
            "main_hybrid.py",
            "system_monitor.py",
            "quality_metrics.py",
            "streamlit_app.py"
        ]
    
    def _load_config(self):
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        default_config = {
            "auto_backup_enabled": True,
            "backup_interval_minutes": 30,
            "max_backups": 10,
            "git_auto_commit": True,
            "git_auto_push": False,
            "protect_cursor_configs": True,
            "backup_before_changes": True,
            "notify_on_backup": True
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = {**default_config, **json.load(f)}
            except Exception as e:
                logger.error(f"è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.config = default_config
        else:
            self.config = default_config
            self._save_config()
    
    def _save_config(self):
        """è¨­å®šä¿å­˜"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def create_backup(self, backup_type: str = "auto") -> str:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{backup_type}_{timestamp}"
        backup_path = self.backup_dir / backup_name
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            backup_path.mkdir(exist_ok=True)
            
            # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            copied_files = []
            for path in self.critical_paths:
                source = self.project_root / path
                if source.exists():
                    dest = backup_path / path
                    dest.parent.mkdir(parents=True, exist_ok=True)
                    
                    if source.is_file():
                        shutil.copy2(source, dest)
                        copied_files.append(str(path))
                    elif source.is_dir():
                        shutil.copytree(source, dest, dirs_exist_ok=True)
                        copied_files.append(str(path))
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            metadata = {
                "backup_name": backup_name,
                "timestamp": datetime.now().isoformat(),
                "backup_type": backup_type,
                "copied_files": copied_files,
                "git_status": self._get_git_status(),
                "file_hashes": self._calculate_file_hashes()
            }
            
            with open(backup_path / "backup_metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_name} ({len(copied_files)}ãƒ•ã‚¡ã‚¤ãƒ«)")
            return backup_name
            
        except Exception as e:
            logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def git_auto_commit(self, message: str = None) -> bool:
        """Gitè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ"""
        if not self.config["git_auto_commit"]:
            return True
        
        try:
            # å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            status = subprocess.check_output(
                ["git", "status", "--porcelain"], 
                cwd=self.project_root,
                text=True
            ).strip()
            
            if not status:
                logger.info("ã‚³ãƒŸãƒƒãƒˆã™ã‚‹å¤‰æ›´ãªã—")
                return True
            
            # ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if not message:
                message = f"ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ã¨ã‚³ãƒŸãƒƒãƒˆ
            subprocess.run(["git", "add", "."], cwd=self.project_root, check=True)
            subprocess.run(["git", "commit", "-m", message], cwd=self.project_root, check=True)
            
            logger.info(f"Gitè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆå®Œäº†: {message}")
            return True
            
        except Exception as e:
            logger.error(f"Gitè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def git_auto_push(self) -> bool:
        """Gitè‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥"""
        if not self.config["git_auto_push"]:
            return True
        
        try:
            subprocess.run(["git", "push"], cwd=self.project_root, check=True)
            logger.info("Gitè‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥å®Œäº†")
            return True
        except Exception as e:
            logger.error(f"Gitè‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def protect_cursor_configs(self):
        """Cursorè¨­å®šã®ä¿è­·"""
        if not self.config["protect_cursor_configs"]:
            return
        
        cursor_dir = self.project_root / ".cursor"
        if not cursor_dir.exists():
            return
        
        # é‡è¦ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gitã§ä¿è­·
        important_configs = [
            "mcp.json", "composer.json", "memory_composer.json",
            "mcp_security.json", "mcp_audit.json", "project-rules.json"
        ]
        
        for config in important_configs:
            config_path = cursor_dir / config
            if config_path.exists():
                try:
                    # å¤‰æ›´ã‚’é˜²ãï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ã«ã—ãªã„ï¼‰
                    logger.info(f"Cursorè¨­å®šä¿è­·: {config}")
                except Exception as e:
                    logger.error(f"Cursorè¨­å®šä¿è­·ã‚¨ãƒ©ãƒ¼ {config}: {e}")
    
    def cleanup_old_backups(self):
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤"""
        max_backups = self.config["max_backups"]
        
        backups = sorted(
            [d for d in self.backup_dir.iterdir() if d.is_dir()],
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        
        if len(backups) > max_backups:
            for backup in backups[max_backups:]:
                try:
                    shutil.rmtree(backup)
                    logger.info(f"å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤: {backup.name}")
                except Exception as e:
                    logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {backup.name}: {e}")
    
    def restore_from_backup(self, backup_name: str) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        backup_path = self.backup_dir / backup_name
        
        if not backup_path.exists():
            logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_name}")
            return False
        
        try:
            # å¾©å…ƒå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if self.config["backup_before_changes"]:
                self.create_backup("before_restore")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            metadata_file = backup_path / "backup_metadata.json"
            if metadata_file.exists():
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ
            restored_files = []
            for path in self.critical_paths:
                source = backup_path / path
                dest = self.project_root / path
                
                if source.exists():
                    if source.is_file():
                        shutil.copy2(source, dest)
                        restored_files.append(str(path))
                    elif source.is_dir():
                        if dest.exists():
                            shutil.rmtree(dest)
                        shutil.copytree(source, dest)
                        restored_files.append(str(path))
            
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒå®Œäº†: {backup_name} ({len(restored_files)}ãƒ•ã‚¡ã‚¤ãƒ«)")
            return True
            
        except Exception as e:
            logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _get_git_status(self) -> dict:
        """GitçŠ¶æ…‹å–å¾—"""
        try:
            commit_hash = subprocess.check_output(
                ["git", "rev-parse", "HEAD"], 
                cwd=self.project_root,
                text=True
            ).strip()
            
            branch = subprocess.check_output(
                ["git", "branch", "--show-current"], 
                cwd=self.project_root,
                text=True
            ).strip()
            
            return {
                "commit_hash": commit_hash,
                "branch": branch,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            return {"error": str(e)}
    
    def _calculate_file_hashes(self) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        hashes = {}
        
        for path in self.critical_paths:
            source = self.project_root / path
            if source.exists() and source.is_file():
                try:
                    with open(source, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                        hashes[str(path)] = file_hash
                except Exception as e:
                    hashes[str(path)] = f"error: {e}"
        
        return hashes
    
    def start_auto_backup(self):
        """è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹"""
        logger.info("è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        while True:
            try:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
                backup_name = self.create_backup("auto")
                
                # Gitè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ
                self.git_auto_commit()
                
                # Gitè‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥ï¼ˆè¨­å®šãŒæœ‰åŠ¹ãªå ´åˆï¼‰
                self.git_auto_push()
                
                # Cursorè¨­å®šä¿è­·
                self.protect_cursor_configs()
                
                # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
                self.cleanup_old_backups()
                
                # é€šçŸ¥
                if self.config["notify_on_backup"]:
                    print(f"âœ… è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_name}")
                
                # å¾…æ©Ÿ
                interval = self.config["backup_interval_minutes"] * 60
                time.sleep(interval)
                
            except KeyboardInterrupt:
                logger.info("è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åœæ­¢")
                break
            except Exception as e:
                logger.error(f"è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--create", action="store_true", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ")
    parser.add_argument("--restore", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ")
    parser.add_argument("--auto", action="store_true", help="è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹")
    parser.add_argument("--list", action="store_true", help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§è¡¨ç¤º")
    parser.add_argument("--config", action="store_true", help="è¨­å®šè¡¨ç¤º")
    
    args = parser.parse_args()
    
    backup_system = AutoBackupSystem()
    
    if args.create:
        backup_name = backup_system.create_backup("manual")
        if backup_name:
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_name}")
    
    elif args.restore:
        success = backup_system.restore_from_backup(args.restore)
        if success:
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒå®Œäº†: {args.restore}")
        else:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒå¤±æ•—: {args.restore}")
    
    elif args.auto:
        backup_system.start_auto_backup()
    
    elif args.list:
        backups = sorted(
            [d for d in backup_system.backup_dir.iterdir() if d.is_dir()],
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        print("ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§:")
        for backup in backups:
            print(f"  - {backup.name}")
    
    elif args.config:
        print("âš™ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š:")
        for key, value in backup_system.config.items():
            print(f"  {key}: {value}")

if __name__ == "__main__":
    main() 