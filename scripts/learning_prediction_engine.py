#!/usr/bin/env python3
"""
ğŸ§  Learning & Prediction Engine - å­¦ç¿’ãƒ»äºˆæ¸¬æ©Ÿèƒ½ã‚·ã‚¹ãƒ†ãƒ 
æ”¹å–„æ¡ˆ2: éå»ã®å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã€å•é¡Œç™ºç”Ÿäºˆæ¸¬ã€è‡ªå‹•æ”¹å–„ææ¡ˆ
"""

import os
import json
import pickle
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
import datetime
import re


class LearningPredictionEngine:
    """å­¦ç¿’ãƒ»äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.data_dir = self.project_root / "data"
        self.models_dir = self.data_dir / "models"
        self.learning_dir = self.data_dir / "learning"

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.data_dir.mkdir(exist_ok=True)
        self.models_dir.mkdir(exist_ok=True)
        self.learning_dir.mkdir(exist_ok=True)

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        self.problem_patterns = defaultdict(list)
        self.threat_history = []
        self.repair_history = []

        print("ğŸ§  å­¦ç¿’ãƒ»äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")

    def collect_historical_data(self) -> Dict[str, Any]:
        """éå»ã®ãƒ‡ãƒ¼ã‚¿åé›†"""
        print("ğŸ“Š éå»ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")

        historical_data = {
            "security_reports": [],
            "threat_patterns": [],
            "repair_records": [],
            "system_events": [],
        }

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒãƒ¼ãƒˆã®åé›†
        report_files = list(self.data_dir.glob("*security_report*.json"))
        for report_file in report_files:
            try:
                with open(report_file, "r", encoding="utf-8") as f:
                    report_data = json.load(f)
                    historical_data["security_reports"].append(report_data)
            except Exception as e:
                print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {report_file}: {e}")

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        log_files = list(self.data_dir.glob("*.log"))
        for log_file in log_files:
            try:
                with open(log_file, "r", encoding="utf-8") as f:
                    log_content = f.read()

                # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
                error_patterns = re.findall(r"ERROR.*", log_content)
                warning_patterns = re.findall(r"WARNING.*", log_content)

                historical_data["system_events"].extend(
                    [
                        {"type": "error", "message": pattern, "file": str(log_file)}
                        for pattern in error_patterns
                    ]
                )
                historical_data["system_events"].extend(
                    [
                        {"type": "warning", "message": pattern, "file": str(log_file)}
                        for pattern in warning_patterns
                    ]
                )

            except Exception as e:
                print(f"âš ï¸ ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {log_file}: {e}")

        print(
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {len(historical_data['security_reports'])}ä»¶ã®ãƒ¬ãƒãƒ¼ãƒˆ"
        )
        return historical_data

    def learn_problem_patterns(self, historical_data: Dict[str, Any]) -> Dict[str, Any]:
        """å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’"""
        print("ğŸ§  å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’é–‹å§‹...")

        patterns = {
            "frequent_threats": Counter(),
            "error_sequences": [],
            "time_patterns": defaultdict(list),
            "file_patterns": defaultdict(list),
            "severity_trends": [],
        }

        # è„…å¨ã®é »åº¦åˆ†æ
        for report in historical_data["security_reports"]:
            vulnerabilities = report.get("vulnerabilities", {})
            for vuln_type, issues in vulnerabilities.items():
                patterns["frequent_threats"][vuln_type] += len(issues)

                for issue in issues:
                    file_path = issue.get("file", "")
                    severity = issue.get("severity", "MEDIUM")

                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                    if file_path:
                        file_ext = Path(file_path).suffix
                        patterns["file_patterns"][file_ext].append(vuln_type)

                    # é‡è¦åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
                    patterns["severity_trends"].append(
                        {
                            "type": vuln_type,
                            "severity": severity,
                            "timestamp": report.get("scan_timestamp", ""),
                        }
                    )

        # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        for event in historical_data["system_events"]:
            event_type = event.get("type", "")
            message = event.get("message", "")

            # æ™‚é–“å¸¯åˆ¥ã®å•é¡Œç™ºç”Ÿãƒ‘ã‚¿ãƒ¼ãƒ³
            try:
                # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ™‚åˆ»æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                time_match = re.search(r"(\d{2}):(\d{2}):(\d{2})", message)
                if time_match:
                    hour = int(time_match.group(1))
                    patterns["time_patterns"][hour].append(event_type)
            except:
                pass

        # ã‚¨ãƒ©ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†æ
        error_sequences = []
        current_sequence = []

        for event in historical_data["system_events"]:
            if event["type"] == "error":
                current_sequence.append(event["message"][:50])  # æœ€åˆã®50æ–‡å­—
                if len(current_sequence) >= 3:
                    error_sequences.append(current_sequence.copy())
                    current_sequence = current_sequence[-2:]  # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
            else:
                if current_sequence:
                    current_sequence = []

        patterns["error_sequences"] = error_sequences

        # å­¦ç¿’çµæœä¿å­˜
        patterns_file = (
            self.learning_dir
            / f"learned_patterns_{datetime.datetime.now().strftime('%Y%m%d')}.json"
        )
        with open(patterns_file, "w", encoding="utf-8") as f:
            # Counter ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            serializable_patterns = {
                "frequent_threats": dict(patterns["frequent_threats"]),
                "error_sequences": patterns["error_sequences"],
                "time_patterns": {
                    k: list(v) for k, v in patterns["time_patterns"].items()
                },
                "file_patterns": {
                    k: list(v) for k, v in patterns["file_patterns"].items()
                },
                "severity_trends": patterns["severity_trends"],
            }
            json.dump(serializable_patterns, f, ensure_ascii=False, indent=2)

        print(f"ğŸ§  ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’å®Œäº†: {patterns_file}")
        return patterns

    def predict_future_threats(
        self, patterns: Dict[str, Any], current_state: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å°†æ¥ã®è„…å¨äºˆæ¸¬"""
        print("ğŸ”® å°†æ¥è„…å¨äºˆæ¸¬é–‹å§‹...")

        predictions = {
            "high_risk_threats": [],
            "predicted_timeframes": {},
            "risk_scores": {},
            "preventive_actions": [],
        }

        # é »å‡ºè„…å¨ã«åŸºã¥ãäºˆæ¸¬
        frequent_threats = patterns.get("frequent_threats", {})

        for threat_type, frequency in frequent_threats.items():
            if frequency > 2:  # 3å›ä»¥ä¸Šç™ºç”Ÿã—ãŸè„…å¨
                risk_score = min(95, frequency * 15)  # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—

                predictions["high_risk_threats"].append(
                    {
                        "threat_type": threat_type,
                        "risk_score": risk_score,
                        "frequency": frequency,
                        "prediction": f"{threat_type}ã®å†ç™ºãƒªã‚¹ã‚¯ãŒé«˜ã„",
                    }
                )

                predictions["risk_scores"][threat_type] = risk_score

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãäºˆæ¸¬
        file_patterns = patterns.get("file_patterns", {})
        current_files = self._get_current_file_structure()

        for file_ext, threat_types in file_patterns.items():
            if file_ext in current_files:
                file_count = current_files[file_ext]
                threat_likelihood = len(set(threat_types)) * file_count

                if threat_likelihood > 5:
                    predictions["high_risk_threats"].append(
                        {
                            "threat_type": f"{file_ext}_files_vulnerability",
                            "risk_score": min(90, threat_likelihood * 10),
                            "file_type": file_ext,
                            "file_count": file_count,
                            "prediction": f"{file_ext}ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®è„†å¼±æ€§ç™ºç”Ÿãƒªã‚¹ã‚¯",
                        }
                    )

        # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãäºˆæ¸¬
        time_patterns = patterns.get("time_patterns", {})
        current_hour = datetime.datetime.now().hour

        if str(current_hour) in time_patterns:
            hourly_events = time_patterns[str(current_hour)]
            if len(hourly_events) > 3:
                predictions["predicted_timeframes"][current_hour] = {
                    "risk_level": "HIGH",
                    "expected_events": len(hourly_events),
                    "prediction": f"{current_hour}æ™‚å°ã¯å•é¡Œç™ºç”Ÿé »åº¦ãŒé«˜ã„",
                }

        # äºˆé˜²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        predictions["preventive_actions"] = self._generate_preventive_actions(
            predictions
        )

        # äºˆæ¸¬çµæœä¿å­˜
        prediction_file = (
            self.learning_dir
            / f"threat_predictions_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(prediction_file, "w", encoding="utf-8") as f:
            json.dump(predictions, f, ensure_ascii=False, indent=2)

        print(
            f"ğŸ”® è„…å¨äºˆæ¸¬å®Œäº†: {len(predictions['high_risk_threats'])}ä»¶ã®é«˜ãƒªã‚¹ã‚¯è„…å¨ã‚’æ¤œå‡º"
        )
        return predictions

    def generate_improvement_suggestions(
        self, patterns: Dict[str, Any], predictions: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è‡ªå‹•æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        print("ğŸ’¡ æ”¹å–„ææ¡ˆç”Ÿæˆé–‹å§‹...")

        suggestions = {
            "immediate_actions": [],
            "long_term_improvements": [],
            "automation_opportunities": [],
            "monitoring_enhancements": [],
        }

        # å³åº§ã®å¯¾å¿œãŒå¿…è¦ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        for threat in predictions["high_risk_threats"]:
            if threat["risk_score"] > 80:
                suggestions["immediate_actions"].append(
                    {
                        "priority": "HIGH",
                        "action": f'{threat["threat_type"]}ã®å³åº§å¯¾å¿œ',
                        "description": f'ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢{threat["risk_score"]}ã®è„…å¨ã«å¯¾ã™ã‚‹ç·Šæ€¥å¯¾å¿œ',
                        "estimated_time": "1-2æ™‚é–“",
                    }
                )

        # é•·æœŸæ”¹å–„ææ¡ˆ
        frequent_threats = patterns.get("frequent_threats", {})

        for threat_type, frequency in frequent_threats.items():
            if frequency > 5:  # éå¸¸ã«é »å‡ºã™ã‚‹è„…å¨
                suggestions["long_term_improvements"].append(
                    {
                        "priority": "MEDIUM",
                        "action": f"{threat_type}ã®æ ¹æœ¬çš„å¯¾ç­–",
                        "description": f"{frequency}å›ç™ºç”Ÿã—ãŸ{threat_type}ã®æ ¹æœ¬åŸå› è§£æ±º",
                        "estimated_time": "1-2æ—¥",
                    }
                )

        # è‡ªå‹•åŒ–æ©Ÿä¼š
        error_sequences = patterns.get("error_sequences", [])

        if len(error_sequences) > 3:
            suggestions["automation_opportunities"].append(
                {
                    "priority": "MEDIUM",
                    "action": "ã‚¨ãƒ©ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹è‡ªå‹•æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ",
                    "description": f"{len(error_sequences)}å€‹ã®ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•æ¤œçŸ¥ãƒ»å¯¾å¿œ",
                    "estimated_time": "åŠæ—¥",
                }
            )

        # ç›£è¦–å¼·åŒ–ææ¡ˆ
        time_patterns = patterns.get("time_patterns", {})

        high_activity_hours = [
            hour for hour, events in time_patterns.items() if len(events) > 5
        ]

        if high_activity_hours:
            suggestions["monitoring_enhancements"].append(
                {
                    "priority": "LOW",
                    "action": f"{len(high_activity_hours)}æ™‚é–“å¸¯ã®ç›£è¦–å¼·åŒ–",
                    "description": f'é«˜æ´»å‹•æ™‚é–“å¸¯ï¼ˆ{", ".join(high_activity_hours)}æ™‚ï¼‰ã®ç›£è¦–é »åº¦å‘ä¸Š',
                    "estimated_time": "30åˆ†",
                }
            )

        # æ”¹å–„åŠ¹æœäºˆæ¸¬
        suggestions["expected_benefits"] = {
            "risk_reduction": f'{len(suggestions["immediate_actions"]) * 20}%',
            "efficiency_improvement": f'{len(suggestions["automation_opportunities"]) * 30}%',
            "monitoring_coverage": f'{len(suggestions["monitoring_enhancements"]) * 15}%',
        }

        # ææ¡ˆä¿å­˜
        suggestions_file = (
            self.learning_dir
            / f"improvement_suggestions_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(suggestions_file, "w", encoding="utf-8") as f:
            json.dump(suggestions, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¡ æ”¹å–„ææ¡ˆç”Ÿæˆå®Œäº†: {suggestions_file}")
        return suggestions

    def _get_current_file_structure(self) -> Dict[str, int]:
        """ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ å–å¾—"""
        file_counts = defaultdict(int)

        for file_path in self.project_root.glob("**/*"):
            if file_path.is_file():
                ext = file_path.suffix
                if ext:
                    file_counts[ext] += 1

        return dict(file_counts)

    def _generate_preventive_actions(self, predictions: Dict[str, Any]) -> List[str]:
        """äºˆé˜²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        actions = []

        for threat in predictions["high_risk_threats"]:
            threat_type = threat["threat_type"]

            if "sql_injection" in threat_type:
                actions.append("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã®ä½¿ç”¨ã‚’å¾¹åº•ã™ã‚‹")
            elif "hardcoded_secrets" in threat_type:
                actions.append("ç’°å¢ƒå¤‰æ•°ã¸ã®ç§˜å¯†æƒ…å ±ç§»è¡Œã‚’å®Ÿæ–½ã™ã‚‹")
            elif "dependency" in threat_type:
                actions.append("ä¾å­˜é–¢ä¿‚ã®å®šæœŸçš„ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’å®Ÿæ–½ã™ã‚‹")
            elif "command_injection" in threat_type:
                actions.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å³æ ¼ãªæ¤œè¨¼ã‚’å®Ÿè£…ã™ã‚‹")
            else:
                actions.append(f"{threat_type}ã«å¯¾ã™ã‚‹äºˆé˜²çš„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–")

        return list(set(actions))  # é‡è¤‡é™¤å»

    def run_learning_cycle(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        print("ğŸ”„ å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹...")

        # ãƒ‡ãƒ¼ã‚¿åé›†
        historical_data = self.collect_historical_data()

        # ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        patterns = self.learn_problem_patterns(historical_data)

        # è„…å¨äºˆæ¸¬
        current_state = {"timestamp": datetime.datetime.now().isoformat()}
        predictions = self.predict_future_threats(patterns, current_state)

        # æ”¹å–„ææ¡ˆ
        suggestions = self.generate_improvement_suggestions(patterns, predictions)

        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        learning_report = {
            "cycle_timestamp": datetime.datetime.now().isoformat(),
            "data_summary": {
                "reports_analyzed": len(historical_data["security_reports"]),
                "events_processed": len(historical_data["system_events"]),
                "patterns_learned": len(patterns["frequent_threats"]),
                "threats_predicted": len(predictions["high_risk_threats"]),
                "suggestions_generated": (
                    len(suggestions["immediate_actions"])
                    + len(suggestions["long_term_improvements"])
                    + len(suggestions["automation_opportunities"])
                ),
            },
            "patterns": patterns,
            "predictions": predictions,
            "suggestions": suggestions,
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = (
            self.learning_dir
            / f"learning_cycle_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_file, "w", encoding="utf-8") as f:
            # Counter ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‡¦ç†
            if "frequent_threats" in learning_report["patterns"]:
                learning_report["patterns"]["frequent_threats"] = dict(
                    learning_report["patterns"]["frequent_threats"]
                )
            json.dump(learning_report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ”„ å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Œäº†: {report_file}")
        return learning_report


if __name__ == "__main__":
    # å­¦ç¿’ãƒ»äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ
    engine = LearningPredictionEngine()

    print("ğŸ§  å­¦ç¿’ãƒ»äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹")

    # å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
    report = engine.run_learning_cycle()

    # çµæœè¡¨ç¤º
    summary = report["data_summary"]
    print(f"\nğŸ“Š å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«çµæœ:")
    print(f"åˆ†æãƒ¬ãƒãƒ¼ãƒˆæ•°: {summary['reports_analyzed']}ä»¶")
    print(f"å‡¦ç†ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {summary['events_processed']}ä»¶")
    print(f"å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {summary['patterns_learned']}ä»¶")
    print(f"äºˆæ¸¬è„…å¨æ•°: {summary['threats_predicted']}ä»¶")
    print(f"æ”¹å–„ææ¡ˆæ•°: {summary['suggestions_generated']}ä»¶")

    if report["suggestions"]["immediate_actions"]:
        print(f"\nğŸš¨ å³åº§å¯¾å¿œãŒå¿…è¦:")
        for action in report["suggestions"]["immediate_actions"][:3]:
            print(f"- {action['action']}: {action['description']}")

    print("\nğŸ‰ å­¦ç¿’ãƒ»äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³å®Œäº†ï¼")
