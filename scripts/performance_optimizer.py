#!/usr/bin/env python3
"""
ğŸš€ AI Systems Performance Optimizer
ä½œæˆæ—¥: 2025-08-04
ç›®çš„: ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–
"""

import os
import sys
import json
import psutil
import logging
import asyncio
import subprocess
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/performance_optimizer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    process_count: int
    load_average: List[float]

class PerformanceOptimizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.metrics_history = []
        self.optimization_config = self.load_config()
    
    def load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        config_path = Path('config/performance_config.json')
        if config_path.exists():
            with open(config_path, 'r') as f:
                return json.load(f)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            return {
                'cpu_threshold': 80.0,
                'memory_threshold': 80.0,
                'disk_threshold': 85.0,
                'optimization_enabled': True,
                'auto_restart_threshold': 95.0
            }
    
    def collect_metrics(self) -> PerformanceMetrics:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_usage = psutil.cpu_percent(interval=1)
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_usage = memory.percent
            
            # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_usage = (disk.used / disk.total) * 100
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O
            network = psutil.net_io_counters()
            network_io = {
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv,
                'packets_sent': network.packets_sent,
                'packets_recv': network.packets_recv
            }
            
            # ãƒ—ãƒ­ã‚»ã‚¹æ•°
            process_count = len(psutil.pids())
            
            # ãƒ­ãƒ¼ãƒ‰ã‚¢ãƒ™ãƒ¬ãƒ¼ã‚¸
            load_average = psutil.getloadavg()
            
            return PerformanceMetrics(
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                disk_usage=disk_usage,
                network_io=network_io,
                process_count=process_count,
                load_average=list(load_average)
            )
        
        except Exception as e:
            logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_performance(self, metrics: PerformanceMetrics) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        analysis = {
            'status': 'healthy',
            'warnings': [],
            'recommendations': [],
            'critical_issues': []
        }
        
        # CPUåˆ†æ
        if metrics.cpu_usage > self.optimization_config['cpu_threshold']:
            analysis['warnings'].append(f"CPUä½¿ç”¨ç‡ãŒé«˜ã„: {metrics.cpu_usage:.1f}%")
            if metrics.cpu_usage > self.optimization_config['auto_restart_threshold']:
                analysis['critical_issues'].append("CPUä½¿ç”¨ç‡ãŒéå¸¸ã«é«˜ã„")
        
        # ãƒ¡ãƒ¢ãƒªåˆ†æ
        if metrics.memory_usage > self.optimization_config['memory_threshold']:
            analysis['warnings'].append(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„: {metrics.memory_usage:.1f}%")
            analysis['recommendations'].append("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤šã„ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯åˆ†æ
        if metrics.disk_usage > self.optimization_config['disk_threshold']:
            analysis['warnings'].append(f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãŒé«˜ã„: {metrics.disk_usage:.1f}%")
            analysis['recommendations'].append("ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ãã ã•ã„")
        
        # ãƒ—ãƒ­ã‚»ã‚¹æ•°åˆ†æ
        if metrics.process_count > 1000:
            analysis['warnings'].append(f"ãƒ—ãƒ­ã‚»ã‚¹æ•°ãŒå¤šã„: {metrics.process_count}")
        
        # ãƒ­ãƒ¼ãƒ‰ã‚¢ãƒ™ãƒ¬ãƒ¼ã‚¸åˆ†æ
        if metrics.load_average[0] > 10:
            analysis['warnings'].append(f"ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒé«˜ã„: {metrics.load_average[0]:.2f}")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        if analysis['critical_issues']:
            analysis['status'] = 'critical'
        elif analysis['warnings']:
            analysis['status'] = 'warning'
        
        return analysis
    
    def optimize_memory(self):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–"""
        try:
            logger.info("ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            
            # Pythonã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
            cache_dirs = [
                Path('.venv/lib/python*/site-packages/__pycache__'),
                Path('.venv/lib/python*/site-packages/*/__pycache__'),
                Path('__pycache__')
            ]
            
            for pattern in cache_dirs:
                for cache_dir in Path('.').glob(str(pattern)):
                    if cache_dir.exists():
                        import shutil
                        shutil.rmtree(cache_dir)
                        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢: {cache_dir}")
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®
            log_dir = Path('logs')
            if log_dir.exists():
                for log_file in log_dir.glob('*.log'):
                    if log_file.stat().st_size > 100 * 1024 * 1024:  # 100MB
                        subprocess.run(['gzip', str(log_file)])
                        logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®: {log_file}")
            
            logger.info("ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def optimize_disk(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯æœ€é©åŒ–"""
        try:
            logger.info("ãƒ‡ã‚£ã‚¹ã‚¯æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            temp_patterns = [
                '*.tmp',
                '*.temp',
                '*.cache',
                '*.log.old',
                '*.bak'
            ]
            
            for pattern in temp_patterns:
                for temp_file in Path('.').rglob(pattern):
                    if temp_file.exists():
                        temp_file.unlink()
                        logger.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {temp_file}")
            
            # Dockeræœ€é©åŒ–
            if self.check_docker_available():
                subprocess.run(['docker', 'system', 'prune', '-f'])
                logger.info("Dockeræœ€é©åŒ–å®Œäº†")
            
            logger.info("ãƒ‡ã‚£ã‚¹ã‚¯æœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ‡ã‚£ã‚¹ã‚¯æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def optimize_network(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–"""
        try:
            logger.info("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            
            # æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
            # ã“ã“ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£ã®æœ€é©åŒ–ã‚’å®Ÿè£…
            
            logger.info("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def check_docker_available(self) -> bool:
        """Dockeråˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            subprocess.run(['docker', '--version'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def restart_critical_services(self):
        """é‡è¦ãªã‚µãƒ¼ãƒ“ã‚¹ã®å†èµ·å‹•"""
        try:
            logger.info("é‡è¦ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’å†èµ·å‹•ä¸­...")
            
            # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
            main_process = self.find_main_process()
            if main_process:
                logger.info(f"ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•: PID {main_process.pid}")
                main_process.terminate()
                main_process.wait()
                
                # å†èµ·å‹•
                subprocess.Popen(['python', 'main_hybrid.py'])
                logger.info("ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
    
    def find_main_process(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹æ¤œç´¢"""
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if 'main_hybrid.py' in ' '.join(proc.info['cmdline'] or []):
                    return proc
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        return None
    
    def generate_report(self, metrics: PerformanceMetrics, analysis: Dict[str, Any]):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'metrics': {
                'cpu_usage': metrics.cpu_usage,
                'memory_usage': metrics.memory_usage,
                'disk_usage': metrics.disk_usage,
                'process_count': metrics.process_count,
                'load_average': metrics.load_average
            },
            'analysis': analysis,
            'optimizations_applied': []
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_dir = Path('logs/performance_reports')
        report_dir.mkdir(exist_ok=True)
        
        report_file = report_dir / f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        return report
    
    def run_optimization_cycle(self):
        """æœ€é©åŒ–ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        metrics = self.collect_metrics()
        if not metrics:
            logger.error("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        analysis = self.analyze_performance(metrics)
        
        # æœ€é©åŒ–å®Ÿè¡Œ
        optimizations_applied = []
        
        if analysis['status'] == 'critical':
            logger.warning("ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªå•é¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            self.restart_critical_services()
            optimizations_applied.append('critical_service_restart')
        
        if metrics.memory_usage > self.optimization_config['memory_threshold']:
            self.optimize_memory()
            optimizations_applied.append('memory_optimization')
        
        if metrics.disk_usage > self.optimization_config['disk_threshold']:
            self.optimize_disk()
            optimizations_applied.append('disk_optimization')
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_report(metrics, analysis)
        report['optimizations_applied'] = optimizations_applied
        
        # çµæœè¡¨ç¤º
        self.display_results(metrics, analysis, optimizations_applied)
        
        logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µã‚¤ã‚¯ãƒ«å®Œäº†")
    
    def display_results(self, metrics: PerformanceMetrics, analysis: Dict[str, Any], optimizations: List[str]):
        """çµæœè¡¨ç¤º"""
        print("\n" + "="*50)
        print("ğŸš€ AI Systems Performance Report")
        print("="*50)
        
        print(f"\nğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"  CPUä½¿ç”¨ç‡: {metrics.cpu_usage:.1f}%")
        print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {metrics.memory_usage:.1f}%")
        print(f"  ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {metrics.disk_usage:.1f}%")
        print(f"  ãƒ—ãƒ­ã‚»ã‚¹æ•°: {metrics.process_count}")
        print(f"  ãƒ­ãƒ¼ãƒ‰ã‚¢ãƒ™ãƒ¬ãƒ¼ã‚¸: {metrics.load_average[0]:.2f}")
        
        print(f"\nğŸ” åˆ†æçµæœ:")
        print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {analysis['status']}")
        
        if analysis['warnings']:
            print(f"  è­¦å‘Š:")
            for warning in analysis['warnings']:
                print(f"    âš ï¸  {warning}")
        
        if analysis['recommendations']:
            print(f"  æ¨å¥¨äº‹é …:")
            for rec in analysis['recommendations']:
                print(f"    ğŸ’¡ {rec}")
        
        if optimizations:
            print(f"\nğŸ”§ å®Ÿè¡Œã•ã‚ŒãŸæœ€é©åŒ–:")
            for opt in optimizations:
                print(f"    âœ… {opt}")
        
        print("\n" + "="*50)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    optimizer = PerformanceOptimizer()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'optimize':
            optimizer.run_optimization_cycle()
        elif command == 'monitor':
            # ç¶™ç¶šçš„ç›£è¦–ãƒ¢ãƒ¼ãƒ‰
            print("ç¶™ç¶šçš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’é–‹å§‹...")
            while True:
                optimizer.run_optimization_cycle()
                import time
                time.sleep(300)  # 5åˆ†é–“éš”
        elif command == 'report':
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ã¿
            metrics = optimizer.collect_metrics()
            if metrics:
                analysis = optimizer.analyze_performance(metrics)
                optimizer.generate_report(metrics, analysis)
                optimizer.display_results(metrics, analysis, [])
        else:
            print("ä½¿ç”¨æ–¹æ³•: python performance_optimizer.py [optimize|monitor|report]")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ€é©åŒ–å®Ÿè¡Œ
        optimizer.run_optimization_cycle()

if __name__ == '__main__':
    main() 