#!/usr/bin/env python3
"""
ğŸ¯ Learning Insights Dashboard
å­¦ç¿’åŠ¹æœã®å¯è¦–åŒ–ã¨ã‚·ã‚¹ãƒ†ãƒ å¥åº·åº¦ãƒ¬ãƒãƒ¼ãƒˆ
"""

import json
import os
import glob
from datetime import datetime
import subprocess
from collections import defaultdict, Counter

class LearningInsights:
    def __init__(self):
        self.out_dir = "out"
        self.logs_dir = "logs"
        self.scripts_dir = "scripts/quality"
        
    def analyze_learning_data(self):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        insights = {
            "timestamp": datetime.now().isoformat(),
            "learning_effectiveness": {},
            "fix_success_rates": {},
            "pattern_recognition": {},
            "system_health": {}
        }
        
        # 1. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        insights["learning_effectiveness"] = self._analyze_output_files()
        
        # 2. ä¿®æ­£æˆåŠŸç‡åˆ†æ
        insights["fix_success_rates"] = self._analyze_fix_success()
        
        # 3. ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç²¾åº¦
        insights["pattern_recognition"] = self._analyze_patterns()
        
        # 4. ã‚·ã‚¹ãƒ†ãƒ å¥åº·åº¦
        insights["system_health"] = self._check_system_health()
        
        return insights
    
    def _analyze_output_files(self):
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å­¦ç¿’åŠ¹æœã‚’åˆ†æ"""
        if not os.path.exists(self.out_dir):
            return {"status": "no_data", "files": 0}
            
        files = glob.glob(f"{self.out_dir}/*.json")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®æ¨ç§»
        recent_files = [f for f in files if self._is_recent_file(f, days=7)]
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã®è¿½è·¡
        performance_data = self._extract_performance_metrics(files)
        
        return {
            "total_output_files": len(files),
            "recent_files": len(recent_files),
            "performance_trends": performance_data,
            "active_learning": len(recent_files) > 0
        }
    
    def _analyze_fix_success(self):
        """ä¿®æ­£æˆåŠŸç‡ã®åˆ†æ"""
        success_patterns = {
            "yaml_fixes": 0,
            "context_warnings": 0,
            "bash_syntax": 0,
            "total_attempts": 0
        }
        
        # Git ã‚³ãƒŸãƒƒãƒˆãƒ­ã‚°ã‹ã‚‰ä¿®æ­£å±¥æ­´ã‚’åˆ†æ
        try:
            result = subprocess.run(
                ["git", "log", "--oneline", "--since=1 week ago", "--grep=fix"],
                capture_output=True, text=True, cwd="."
            )
            
            if result.returncode == 0:
                commits = result.stdout.strip().split('\n')
                success_patterns["total_attempts"] = len([c for c in commits if c.strip()])
                
                for commit in commits:
                    if 'yaml' in commit.lower():
                        success_patterns["yaml_fixes"] += 1
                    if 'context' in commit.lower() or 'warning' in commit.lower():
                        success_patterns["context_warnings"] += 1
                    if 'bash' in commit.lower() or 'syntax' in commit.lower():
                        success_patterns["bash_syntax"] += 1
                        
        except Exception as e:
            success_patterns["error"] = str(e)
            
        return success_patterns
    
    def _analyze_patterns(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®ç²¾åº¦åˆ†æ"""
        patterns = {"recognized_patterns": 0, "accuracy": "unknown"}
        
        # tag_rules.yaml ã®ç¢ºèª
        tag_rules_file = f"{self.scripts_dir}/tag_rules.yaml"
        if os.path.exists(tag_rules_file):
            try:
                with open(tag_rules_file, 'r') as f:
                    content = f.read()
                    patterns["recognized_patterns"] = content.count("pattern:")
                    patterns["status"] = "active"
            except:
                patterns["status"] = "error"
        
        return patterns
    
    def _check_system_health(self):
        """ã‚·ã‚¹ãƒ†ãƒ å¥åº·åº¦ãƒã‚§ãƒƒã‚¯"""
        health = {
            "overall_status": "healthy",
            "components": {},
            "last_activity": None,
            "warnings": []
        }
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç¢ºèª
        components = {
            "learning_scripts": f"{self.scripts_dir}/",
            "output_directory": self.out_dir,
            "continuous_learner": f"{self.scripts_dir}/continuous_learner.py",
            "auto_fix_generator": f"{self.scripts_dir}/auto_fix_generator.py"
        }
        
        for name, path in components.items():
            health["components"][name] = {
                "status": "ok" if os.path.exists(path) else "missing",
                "last_modified": self._get_last_modified(path) if os.path.exists(path) else None
            }
            
            if not os.path.exists(path):
                health["warnings"].append(f"{name} not found: {path}")
        
        # æœ€è¿‘ã®æ´»å‹•ç¢ºèª
        if os.path.exists(self.out_dir):
            recent_files = glob.glob(f"{self.out_dir}/*.json")
            if recent_files:
                latest_file = max(recent_files, key=os.path.getmtime)
                health["last_activity"] = self._get_last_modified(latest_file)
        
        return health
    
    def _is_recent_file(self, filepath, days=7):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ€è¿‘ã®ã‚‚ã®ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            file_time = os.path.getmtime(filepath)
            current_time = datetime.now().timestamp()
            return (current_time - file_time) < (days * 24 * 3600)
        except:
            return False
    
    def _extract_performance_metrics(self, files):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æŠ½å‡º"""
        metrics = {"pass_rates": [], "improvement_trend": "unknown"}
        
        for file in files[-10:]:  # æœ€æ–°10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            try:
                with open(file, 'r') as f:
                    data = json.load(f)
                    
                # pass_rate ã‚„shadow_pass_rate ã‚’æ¢ã™
                if isinstance(data, dict):
                    for key, value in data.items():
                        if 'pass_rate' in str(key).lower() and isinstance(value, (int, float)):
                            metrics["pass_rates"].append(float(value))
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                if 'pass_rate' in str(sub_key).lower() and isinstance(sub_value, (int, float)):
                                    metrics["pass_rates"].append(float(sub_value))
            except:
                continue
        
        # æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ
        if len(metrics["pass_rates"]) >= 2:
            recent_avg = sum(metrics["pass_rates"][-3:]) / min(3, len(metrics["pass_rates"]))
            older_avg = sum(metrics["pass_rates"][:3]) / min(3, len(metrics["pass_rates"]))
            
            if recent_avg > older_avg + 5:
                metrics["improvement_trend"] = "improving"
            elif recent_avg < older_avg - 5:
                metrics["improvement_trend"] = "declining"  
            else:
                metrics["improvement_trend"] = "stable"
        
        return metrics
    
    def _get_last_modified(self, filepath):
        """æœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’å–å¾—"""
        try:
            timestamp = os.path.getmtime(filepath)
            return datetime.fromtimestamp(timestamp).isoformat()
        except:
            return None
    
    def generate_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("ğŸ¯ Learning Insights Dashboard")
        print("=" * 50)
        
        insights = self.analyze_learning_data()
        
        # 1. å­¦ç¿’åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ“Š å­¦ç¿’åŠ¹æœåˆ†æ")
        print("-" * 30)
        learning = insights["learning_effectiveness"]
        print(f"ç·å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {learning.get('total_output_files', 0)}")
        print(f"æœ€è¿‘ã®æ´»å‹• (7æ—¥ä»¥å†…): {learning.get('recent_files', 0)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"å­¦ç¿’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹: {'âœ…' if learning.get('active_learning') else 'âŒ'}")
        
        if learning.get('performance_trends', {}).get('pass_rates'):
            rates = learning['performance_trends']['pass_rates']
            print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: å¹³å‡ {sum(rates)/len(rates):.1f}%")
            print(f"æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰: {learning['performance_trends']['improvement_trend']}")
        
        # 2. ä¿®æ­£æˆåŠŸç‡ãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ”§ ä¿®æ­£æˆåŠŸç‡åˆ†æ")
        print("-" * 30)
        fixes = insights["fix_success_rates"]
        print(f"ç·ä¿®æ­£è©¦è¡Œæ•°: {fixes.get('total_attempts', 0)}")
        print(f"YAMLä¿®æ­£: {fixes.get('yaml_fixes', 0)}å›")
        print(f"Contextè­¦å‘Šä¿®æ­£: {fixes.get('context_warnings', 0)}å›")
        print(f"Bashæ§‹æ–‡ä¿®æ­£: {fixes.get('bash_syntax', 0)}å›")
        
        if fixes.get('total_attempts', 0) > 0:
            success_rate = (fixes.get('yaml_fixes', 0) + fixes.get('context_warnings', 0) + fixes.get('bash_syntax', 0)) / fixes['total_attempts'] * 100
            print(f"å…¨ä½“æˆåŠŸç‡: {success_rate:.1f}%")
        
        # 3. ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ¯ ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜çŠ¶æ³")
        print("-" * 30)
        patterns = insights["pattern_recognition"]
        print(f"èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {patterns.get('recognized_patterns', 0)}")
        print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {patterns.get('status', 'unknown')}")
        
        # 4. ã‚·ã‚¹ãƒ†ãƒ å¥åº·åº¦ãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ’š ã‚·ã‚¹ãƒ†ãƒ å¥åº·åº¦")
        print("-" * 30)
        health = insights["system_health"]
        print(f"å…¨ä½“çŠ¶æ…‹: {health.get('overall_status', 'unknown')}")
        
        for component, status in health.get('components', {}).items():
            status_icon = "âœ…" if status['status'] == 'ok' else "âŒ"
            print(f"{component}: {status_icon}")
        
        if health.get('last_activity'):
            print(f"æœ€æ–°æ´»å‹•: {health['last_activity']}")
        
        if health.get('warnings'):
            print("\nâš ï¸  è­¦å‘Š:")
            for warning in health['warnings']:
                print(f"  - {warning}")
        
        # 5. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        print("\nğŸš€ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        print("-" * 30)
        
        recommendations = []
        
        if learning.get('recent_files', 0) == 0:
            recommendations.append("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¤ã„ - æ–°ã—ã„å®Ÿè¡Œã‚’æ¨å¥¨")
        
        if fixes.get('total_attempts', 0) < 5:
            recommendations.append("ä¿®æ­£å±¥æ­´ãŒå°‘ãªã„ - ã‚ˆã‚Šå¤šãã®ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©")
            
        if patterns.get('recognized_patterns', 0) < 10:
            recommendations.append("ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã‚’å¼·åŒ– - tag_rules.yaml ã®æ‹¡å……")
        
        if not recommendations:
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è‰¯å¥½ - Phase 2å®Ÿè£…ã®æº–å‚™å®Œäº†!")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. {rec}")
        
        # JSONå‡ºåŠ›
        output_file = "out/learning_insights.json"
        os.makedirs("out", exist_ok=True)
        with open(output_file, 'w') as f:
            json.dump(insights, f, indent=2)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ‡ãƒ¼ã‚¿: {output_file}")
        return insights

def main():
    dashboard = LearningInsights()
    dashboard.generate_report()

if __name__ == "__main__":
    main()


