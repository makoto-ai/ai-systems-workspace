#!/usr/bin/env python3
"""
Continuous Learning System - ç¶™ç¶šå­¦ç¿’ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š
- éå»ã®ä¿®æ­£åŠ¹æœã‚’è“„ç©ãƒ»åˆ†æ
- ä¿®æ­£æˆ¦ç•¥ã®è‡ªå‹•æœ€é©åŒ–
- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’ãƒ»å¿œç”¨
"""
import json
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict
import re

class ContinuousLearner:
    def __init__(self):
        self.learning_db = Path("out/learning_database.json")
        self.models_dir = Path("out/learning_models")
        self.models_dir.mkdir(exist_ok=True)
        
    def record_fix_attempt(self, tag, fix_strategy, before_metrics, after_metrics, success=True):
        """ä¿®æ­£è©¦è¡Œã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²"""
        
        fix_record = {
            'timestamp': datetime.now().isoformat(),
            'tag': tag,
            'fix_strategy': fix_strategy,
            'before_metrics': before_metrics,
            'after_metrics': after_metrics,
            'success': success,
            'improvement': self._calculate_improvement(before_metrics, after_metrics),
            'git_commit': self._get_git_commit()
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
        db = self._load_learning_db()
        db['fix_attempts'].append(fix_record)
        
        # çµ±è¨ˆæ›´æ–°
        self._update_learning_stats(db)
        
        self._save_learning_db(db)
        print(f"ğŸ“š å­¦ç¿’è¨˜éŒ²è¿½åŠ : {tag} â†’ æ”¹å–„åº¦{fix_record['improvement']:.1f}%")
        
    def predict_fix_effectiveness(self, tag, fix_strategy):
        """ä¿®æ­£åŠ¹æœã‚’äºˆæ¸¬"""
        db = self._load_learning_db()
        
        # é¡ä¼¼ä¿®æ­£ã®æˆåŠŸç‡ã‚’åˆ†æ
        similar_attempts = [
            attempt for attempt in db['fix_attempts']
            if attempt['tag'].split('.')[0] == tag.split('.')[0]  # åŒã˜ã‚«ãƒ†ã‚´ãƒª
        ]
        
        if not similar_attempts:
            return {
                'predicted_improvement': 15.0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬
                'confidence': 'LOW',
                'sample_size': 0,
                'recommendation': 'PROCEED_WITH_CAUTION'
            }
        
        # æˆåŠŸç‡è¨ˆç®—
        successful = [a for a in similar_attempts if a['success']]
        success_rate = len(successful) / len(similar_attempts)
        
        # æ”¹å–„åº¦ã®çµ±è¨ˆ
        improvements = [a['improvement'] for a in successful]
        avg_improvement = np.mean(improvements) if improvements else 0
        std_improvement = np.std(improvements) if improvements else 10
        
        # ä¿¡é ¼åº¦åˆ¤å®š
        confidence = 'HIGH' if len(similar_attempts) >= 5 else 'MEDIUM' if len(similar_attempts) >= 2 else 'LOW'
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if success_rate >= 0.8 and avg_improvement >= 10:
            recommendation = 'HIGHLY_RECOMMENDED'
        elif success_rate >= 0.6 and avg_improvement >= 5:
            recommendation = 'RECOMMENDED'
        elif success_rate >= 0.4:
            recommendation = 'PROCEED_WITH_CAUTION'
        else:
            recommendation = 'NOT_RECOMMENDED'
        
        return {
            'predicted_improvement': avg_improvement,
            'confidence': confidence,
            'success_rate': success_rate,
            'sample_size': len(similar_attempts),
            'recommendation': recommendation,
            'risk_assessment': std_improvement
        }
    
    def get_optimal_fix_strategy(self, tag):
        """ã‚¿ã‚°ã«å¯¾ã™ã‚‹æœ€é©ä¿®æ­£æˆ¦ç•¥ã‚’æ¨å¥¨"""
        db = self._load_learning_db()
        
        # ã‚¿ã‚°åˆ¥æˆåŠŸæˆ¦ç•¥ã‚’åˆ†æ
        tag_attempts = [
            attempt for attempt in db['fix_attempts']
            if attempt['tag'] == tag and attempt['success']
        ]
        
        if not tag_attempts:
            return self._get_default_strategy(tag)
        
        # æœ€ã‚‚åŠ¹æœçš„ã ã£ãŸæˆ¦ç•¥ã‚’æŠ½å‡º
        best_attempt = max(tag_attempts, key=lambda x: x['improvement'])
        
        strategy = {
            'tag': tag,
            'recommended_strategy': best_attempt['fix_strategy'],
            'expected_improvement': best_attempt['improvement'],
            'historical_success': len(tag_attempts),
            'last_success': best_attempt['timestamp'],
            'confidence_score': min(len(tag_attempts) * 0.2, 1.0)
        }
        
        print(f"ğŸ¯ æœ€é©æˆ¦ç•¥æ¨å¥¨: {tag}")
        print(f"   æˆ¦ç•¥: {strategy['recommended_strategy']['name']}")
        print(f"   æœŸå¾…æ”¹å–„: {strategy['expected_improvement']:.1f}%")
        print(f"   æˆåŠŸå®Ÿç¸¾: {strategy['historical_success']}å›")
        
        return strategy
    
    def analyze_learning_trends(self):
        """å­¦ç¿’ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        db = self._load_learning_db()
        
        if len(db['fix_attempts']) < 3:
            print("ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³: æœ€ä½3å›ã®ä¿®æ­£è©¦è¡ŒãŒå¿…è¦")
            return None
        
        # æ™‚ç³»åˆ—åˆ†æ
        attempts = sorted(db['fix_attempts'], key=lambda x: x['timestamp'])
        recent_attempts = attempts[-10:]  # ç›´è¿‘10å›
        
        # æˆåŠŸç‡ãƒˆãƒ¬ãƒ³ãƒ‰
        recent_success_rate = sum(1 for a in recent_attempts if a['success']) / len(recent_attempts)
        overall_success_rate = sum(1 for a in attempts if a['success']) / len(attempts)
        
        # æ”¹å–„åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
        recent_improvements = [a['improvement'] for a in recent_attempts if a['success']]
        overall_improvements = [a['improvement'] for a in attempts if a['success']]
        
        recent_avg_improvement = np.mean(recent_improvements) if recent_improvements else 0
        overall_avg_improvement = np.mean(overall_improvements) if overall_improvements else 0
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
        category_stats = defaultdict(list)
        for attempt in attempts:
            category = attempt['tag'].split('.')[0]
            category_stats[category].append(attempt)
        
        trend_analysis = {
            'total_attempts': len(attempts),
            'recent_success_rate': recent_success_rate,
            'overall_success_rate': overall_success_rate,
            'success_trend': 'IMPROVING' if recent_success_rate > overall_success_rate else 'DECLINING',
            'recent_avg_improvement': recent_avg_improvement,
            'overall_avg_improvement': overall_avg_improvement,
            'improvement_trend': 'IMPROVING' if recent_avg_improvement > overall_avg_improvement else 'DECLINING',
            'category_performance': {}
        }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        for category, cat_attempts in category_stats.items():
            successful = [a for a in cat_attempts if a['success']]
            success_rate = len(successful) / len(cat_attempts)
            avg_improvement = np.mean([a['improvement'] for a in successful]) if successful else 0
            
            trend_analysis['category_performance'][category] = {
                'attempts': len(cat_attempts),
                'success_rate': success_rate,
                'avg_improvement': avg_improvement
            }
        
        self._report_learning_trends(trend_analysis)
        return trend_analysis
    
    def _calculate_improvement(self, before, after):
        """æ”¹å–„åº¦ã‚’è¨ˆç®—"""
        if 'pass_rate' in before and 'pass_rate' in after:
            return after['pass_rate'] - before['pass_rate']
        return 0
    
    def _get_git_commit(self):
        """ç¾åœ¨ã®Gitã‚³ãƒŸãƒƒãƒˆå–å¾—"""
        import subprocess
        try:
            result = subprocess.run(['git', 'rev-parse', '--short', 'HEAD'], 
                                  capture_output=True, text=True)
            return result.stdout.strip()
        except:
            return "unknown"
    
    def _load_learning_db(self):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒ¼ãƒ‰"""
        if not self.learning_db.exists():
            return {
                'fix_attempts': [],
                'learning_stats': {
                    'total_attempts': 0,
                    'successful_attempts': 0,
                    'avg_improvement': 0,
                    'last_updated': datetime.now().isoformat()
                }
            }
        
        with open(self.learning_db, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _save_learning_db(self, db):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        with open(self.learning_db, 'w', encoding='utf-8') as f:
            json.dump(db, f, ensure_ascii=False, indent=2)
    
    def _update_learning_stats(self, db):
        """å­¦ç¿’çµ±è¨ˆæ›´æ–°"""
        attempts = db['fix_attempts']
        successful = [a for a in attempts if a['success']]
        
        db['learning_stats'] = {
            'total_attempts': len(attempts),
            'successful_attempts': len(successful),
            'success_rate': len(successful) / len(attempts) if attempts else 0,
            'avg_improvement': np.mean([a['improvement'] for a in successful]) if successful else 0,
            'last_updated': datetime.now().isoformat()
        }
    
    def _get_default_strategy(self, tag):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿®æ­£æˆ¦ç•¥"""
        strategies = {
            'TOKENIZE.hyphen_longdash': {
                'name': 'hyphen_normalization',
                'description': 'ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ€ãƒƒã‚·ãƒ¥çµ±ä¸€æ­£è¦åŒ–',
                'expected_improvement': 15.0
            },
            'PUNCT.brackets_mismatch': {
                'name': 'bracket_normalization',
                'description': 'æ‹¬å¼§çµ±ä¸€æ­£è¦åŒ–',
                'expected_improvement': 12.0
            },
            'NUM.tolerance_small': {
                'name': 'numerical_tolerance_adjustment',
                'description': 'æ•°å€¤è¨±å®¹ç¯„å›²èª¿æ•´',
                'expected_improvement': 20.0
            }
        }
        
        return strategies.get(tag, {
            'name': 'generic_normalization',
            'description': 'æ±ç”¨æ­£è¦åŒ–',
            'expected_improvement': 10.0
        })
    
    def _report_learning_trends(self, trends):
        """å­¦ç¿’ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆ"""
        print("\n" + "="*60)
        print("ğŸ§  ç¶™ç¶šå­¦ç¿’ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
        print("="*60)
        
        print(f"ç·ä¿®æ­£è©¦è¡Œ: {trends['total_attempts']}å›")
        print(f"å…¨ä½“æˆåŠŸç‡: {trends['overall_success_rate']:.1%}")
        print(f"ç›´è¿‘æˆåŠŸç‡: {trends['recent_success_rate']:.1%} ({trends['success_trend']})")
        print(f"å¹³å‡æ”¹å–„åº¦: {trends['overall_avg_improvement']:.1f}% â†’ {trends['recent_avg_improvement']:.1f}% ({trends['improvement_trend']})")
        
        print("\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        for category, stats in trends['category_performance'].items():
            print(f"  {category}: {stats['success_rate']:.1%} ({stats['attempts']}å›) å¹³å‡æ”¹å–„{stats['avg_improvement']:.1f}%")
        
        print("="*60)

def main():
    learner = ContinuousLearner()
    learner.analyze_learning_trends()

if __name__ == "__main__":
    main()
