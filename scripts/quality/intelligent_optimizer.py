#!/usr/bin/env python3
"""
ğŸ§  Phase 4: AIãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³
===================================

Phase 1-3ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆåˆ†æã—ã€å•é¡Œã®é‡è¦åº¦ãƒ»å½±éŸ¿åº¦ã‚’è‡ªå‹•ç®—å‡ºã€
ä¿®æ­£åŠ¹æœã‚’äºˆæ¸¬ã—ã¦å„ªå…ˆé †ä½ä»˜ã‘ã™ã‚‹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 

ä¸»è¦æ©Ÿèƒ½:
- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµ±åˆåˆ†æ
- å•é¡Œé‡è¦åº¦AIç®—å‡º
- ä¿®æ­£åŠ¹æœäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
- å„ªå…ˆé †ä½ä»˜ã‘æœ€é©åŒ–
- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨ç”Ÿæˆ
"""

import os
import sys
import json
import statistics
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import re
import math


@dataclass
class QualityIssue:
    """å“è³ªå•é¡Œãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    id: str
    file_path: str
    issue_type: str
    severity: str
    frequency: int
    last_seen: datetime
    impact_score: float
    fix_difficulty: float
    business_impact: float
    technical_debt: float
    predicted_fix_time: int  # minutes


@dataclass  
class OptimizationRecommendation:
    """æœ€é©åŒ–æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    priority_rank: int
    issue: QualityIssue
    action: str
    expected_improvement: float
    effort_estimate: str
    success_probability: float
    roi_score: float
    detailed_steps: List[str]
    prerequisites: List[str]


class DataIntegrationEngine:
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.base_dir = Path(".")
        self.data_sources = [
            "out/learning_insights.json",      # Phase 1
            "out/system_health.json",          # Phase 1
            "out/issue_predictions.json",      # Phase 2
            "out/preventive_fixes.json",       # Phase 2
            "out/realtime_quality.json",       # Phase 3
            "out/feedback_history.json",       # Phase 3
            "out/gate_learning.json",          # Phase 3
            "out/auto_guard_learning.json",    # Phase 3
        ]
        
    def load_integrated_data(self) -> Dict[str, Any]:
        """å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’çµ±åˆèª­ã¿è¾¼ã¿"""
        integrated_data = {
            "phase1_insights": {},
            "phase1_health": {},
            "phase2_predictions": {},
            "phase2_fixes": {},
            "phase3_realtime": {},
            "phase3_feedback": [],
            "phase3_gates": {},
            "phase3_guards": [],
            "last_updated": datetime.now().isoformat()
        }
        
        # Phase 1 ãƒ‡ãƒ¼ã‚¿
        integrated_data["phase1_insights"] = self._load_json("out/learning_insights.json")
        integrated_data["phase1_health"] = self._load_json("out/system_health.json")
        
        # Phase 2 ãƒ‡ãƒ¼ã‚¿
        integrated_data["phase2_predictions"] = self._load_json("out/issue_predictions.json")
        integrated_data["phase2_fixes"] = self._load_json("out/preventive_fixes.json")
        
        # Phase 3 ãƒ‡ãƒ¼ã‚¿
        integrated_data["phase3_realtime"] = self._load_json("out/realtime_quality.json")
        integrated_data["phase3_feedback"] = self._load_jsonl("out/feedback_history.json")
        integrated_data["phase3_gates"] = self._load_json("out/gate_learning.json")
        integrated_data["phase3_guards"] = self._load_jsonl("out/auto_guard_learning.json")
        
        return integrated_data
    
    def _load_json(self, filepath: str) -> Dict[str, Any]:
        """JSON ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(filepath) as f:
                return json.load(f)
        except:
            return {}
    
    def _load_jsonl(self, filepath: str) -> List[Dict[str, Any]]:
        """JSONL ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            data = []
            with open(filepath) as f:
                for line in f:
                    if line.strip():
                        data.append(json.loads(line))
            return data
        except:
            return []


class IssueAnalysisEngine:
    """å•é¡Œåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, integrated_data: Dict[str, Any]):
        self.data = integrated_data
        self.issue_patterns = self._load_issue_patterns()
        
    def _load_issue_patterns(self) -> Dict[str, Any]:
        """æ—¢å­˜ã®å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª­ã¿è¾¼ã¿"""
        patterns = {
            "yaml_issues": {
                "trailing_spaces": {"severity": 3, "fix_difficulty": 1, "frequency_weight": 1.2},
                "indentation": {"severity": 4, "fix_difficulty": 2, "frequency_weight": 1.1},
                "syntax_error": {"severity": 5, "fix_difficulty": 3, "frequency_weight": 1.5}
            },
            "python_issues": {
                "missing_docstring": {"severity": 2, "fix_difficulty": 2, "frequency_weight": 0.8},
                "long_function": {"severity": 3, "fix_difficulty": 4, "frequency_weight": 1.0},
                "complex_logic": {"severity": 4, "fix_difficulty": 5, "frequency_weight": 1.3}
            },
            "security_issues": {
                "exposed_secrets": {"severity": 5, "fix_difficulty": 2, "frequency_weight": 2.0},
                "unsafe_permissions": {"severity": 4, "fix_difficulty": 3, "frequency_weight": 1.7}
            }
        }
        return patterns
    
    def analyze_all_issues(self) -> List[QualityIssue]:
        """å…¨å•é¡Œã®çµ±åˆåˆ†æ"""
        issues = []
        
        # Phase 2 äºˆæ¸¬å•é¡Œ
        if "predictions" in self.data["phase2_predictions"]:
            for pred in self.data["phase2_predictions"]["predictions"]:
                issue = self._create_issue_from_prediction(pred)
                if issue:
                    issues.append(issue)
        
        # Phase 3 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å•é¡Œ
        for feedback in self.data["phase3_feedback"]:
            if feedback.get("level") in ["warning", "error"]:
                issue = self._create_issue_from_feedback(feedback)
                if issue:
                    issues.append(issue)
        
        # Phase 3 ã‚¬ãƒ¼ãƒ‰å•é¡Œ
        for guard in self.data["phase3_guards"]:
            if not guard.get("success", True):
                issue = self._create_issue_from_guard(guard)
                if issue:
                    issues.append(issue)
        
        # é‡è¤‡é™¤å»ãƒ»çµ±åˆ
        issues = self._deduplicate_issues(issues)
        
        return issues
    
    def _create_issue_from_prediction(self, pred: Dict) -> Optional[QualityIssue]:
        """äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•é¡Œã‚’ç”Ÿæˆ"""
        try:
            return QualityIssue(
                id=f"pred_{hash(str(pred))}",
                file_path=pred.get("file", "unknown"),
                issue_type="predicted",
                severity=pred.get("risk_level", "medium"),
                frequency=1,
                last_seen=datetime.now(),
                impact_score=self._calculate_impact_score(pred),
                fix_difficulty=self._estimate_fix_difficulty(pred),
                business_impact=self._calculate_business_impact(pred),
                technical_debt=self._calculate_technical_debt(pred),
                predicted_fix_time=self._estimate_fix_time(pred)
            )
        except:
            return None
    
    def _create_issue_from_feedback(self, feedback: Dict) -> Optional[QualityIssue]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰å•é¡Œã‚’ç”Ÿæˆ"""
        try:
            return QualityIssue(
                id=f"feedback_{hash(str(feedback))}",
                file_path=feedback.get("file", "unknown"),
                issue_type="quality_feedback",
                severity=feedback.get("level", "warning"),
                frequency=1,
                last_seen=datetime.fromisoformat(feedback["timestamp"]),
                impact_score=1.0 - feedback.get("score", 0.5),
                fix_difficulty=2.0 if feedback.get("level") == "error" else 1.5,
                business_impact=self._calculate_business_impact(feedback),
                technical_debt=1.0 - feedback.get("score", 0.5),
                predicted_fix_time=15 if feedback.get("level") == "error" else 10
            )
        except:
            return None
    
    def _create_issue_from_guard(self, guard: Dict) -> Optional[QualityIssue]:
        """ã‚¬ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰ç”Ÿæˆ"""
        try:
            return QualityIssue(
                id=f"guard_{hash(str(guard))}",
                file_path=guard.get("file", "unknown"),
                issue_type="auto_guard",
                severity=guard.get("severity", "medium"),
                frequency=1,
                last_seen=datetime.fromisoformat(guard["timestamp"]),
                impact_score=2.0 if guard.get("severity") == "critical" else 1.0,
                fix_difficulty=3.0 if guard.get("action") == "emergency_rollback" else 2.0,
                business_impact=self._calculate_business_impact(guard),
                technical_debt=2.0 if not guard.get("success") else 0.5,
                predicted_fix_time=30 if guard.get("severity") == "critical" else 20
            )
        except:
            return None
    
    def _deduplicate_issues(self, issues: List[QualityIssue]) -> List[QualityIssue]:
        """é‡è¤‡å•é¡Œã®é™¤å»ãƒ»çµ±åˆ"""
        file_issues = {}
        
        for issue in issues:
            key = f"{issue.file_path}:{issue.issue_type}"
            if key in file_issues:
                # é »åº¦ã‚’å¢—ã‚„ã—ã€æœ€æ–°ã®æƒ…å ±ã§æ›´æ–°
                existing = file_issues[key]
                existing.frequency += 1
                if issue.last_seen > existing.last_seen:
                    existing.last_seen = issue.last_seen
                    existing.severity = issue.severity
                # å½±éŸ¿åº¦ã¯å¹³å‡åŒ–
                existing.impact_score = (existing.impact_score + issue.impact_score) / 2
            else:
                file_issues[key] = issue
        
        return list(file_issues.values())
    
    def _calculate_impact_score(self, data: Dict) -> float:
        """å½±éŸ¿åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        base_score = 1.0
        
        # ãƒ•ã‚¡ã‚¤ãƒ«é‡è¦åº¦
        file_path = data.get("file", "")
        if "critical" in file_path or ".github/workflows" in file_path:
            base_score *= 1.5
        elif "tests/" in file_path:
            base_score *= 1.2
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
        risk = data.get("risk_level", data.get("severity", "medium"))
        if risk == "critical":
            base_score *= 2.0
        elif risk == "high":
            base_score *= 1.5
        elif risk == "medium":
            base_score *= 1.0
        else:
            base_score *= 0.7
        
        return min(5.0, base_score)
    
    def _estimate_fix_difficulty(self, data: Dict) -> float:
        """ä¿®æ­£é›£æ˜“åº¦æ¨å®š"""
        difficulty = 2.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        issue_type = data.get("issue_type", data.get("action", ""))
        
        if "syntax" in issue_type or "yaml" in issue_type:
            difficulty = 1.5
        elif "security" in issue_type or "rollback" in issue_type:
            difficulty = 4.0
        elif "complex" in issue_type or "architecture" in issue_type:
            difficulty = 5.0
        
        return difficulty
    
    def _calculate_business_impact(self, data: Dict) -> float:
        """ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿åº¦è¨ˆç®—"""
        impact = 1.0
        
        file_path = data.get("file", "")
        
        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
        if any(critical in file_path for critical in [
            ".github/workflows", "deploy", "production", "main", "master"
        ]):
            impact = 3.0
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«
        elif any(important in file_path for important in [
            "api", "service", "core", "src"
        ]):
            impact = 2.0
        # ãƒ†ã‚¹ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        elif any(low in file_path for low in [
            "test", "doc", "example", "demo"
        ]):
            impact = 0.5
        
        return impact
    
    def _calculate_technical_debt(self, data: Dict) -> float:
        """æŠ€è¡“çš„è² å‚µè¨ˆç®—"""
        debt = 1.0
        
        # ä¿®æ­£ã®ç·Šæ€¥åº¦ãƒ»è¤‡é›‘åº¦ã‹ã‚‰æ¨å®š
        severity = data.get("severity", "medium")
        if severity == "critical":
            debt = 3.0
        elif severity == "high":
            debt = 2.0
        elif severity == "low":
            debt = 0.5
        
        return debt
    
    def _estimate_fix_time(self, data: Dict) -> int:
        """ä¿®æ­£æ™‚é–“æ¨å®šï¼ˆåˆ†ï¼‰"""
        base_time = 15
        
        difficulty = self._estimate_fix_difficulty(data)
        severity = data.get("severity", "medium")
        
        multiplier = 1.0
        if severity == "critical":
            multiplier = 2.0
        elif severity == "high":
            multiplier = 1.5
        
        return int(base_time * difficulty * multiplier)


class OptimizationEngine:
    """æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.success_rates = {
            "yaml_fixes": 0.9,
            "python_fixes": 0.8,
            "security_fixes": 0.95,
            "documentation": 0.7,
            "refactoring": 0.6
        }
    
    def generate_recommendations(self, issues: List[QualityIssue]) -> List[OptimizationRecommendation]:
        """æœ€é©åŒ–æ¨å¥¨ç”Ÿæˆ"""
        recommendations = []
        
        # å„å•é¡Œã‚’åˆ†æã—ã¦æ¨å¥¨ã‚’ç”Ÿæˆ
        for issue in issues:
            rec = self._create_recommendation(issue)
            if rec:
                recommendations.append(rec)
        
        # ROIã§ã‚½ãƒ¼ãƒˆï¼ˆåŠ¹æœ/å·¥æ•°ã®æœ€å¤§åŒ–ï¼‰
        recommendations.sort(key=lambda x: x.roi_score, reverse=True)
        
        # å„ªå…ˆé †ä½ä»˜ã‘
        for i, rec in enumerate(recommendations, 1):
            rec.priority_rank = i
        
        return recommendations[:20]  # ä¸Šä½20å€‹ã¾ã§
    
    def _create_recommendation(self, issue: QualityIssue) -> Optional[OptimizationRecommendation]:
        """å€‹åˆ¥æ¨å¥¨ä½œæˆ"""
        try:
            action = self._determine_action(issue)
            expected_improvement = self._calculate_expected_improvement(issue)
            effort_estimate = self._categorize_effort(issue.predicted_fix_time)
            success_probability = self._estimate_success_probability(issue)
            roi_score = self._calculate_roi(expected_improvement, issue.predicted_fix_time, success_probability)
            
            return OptimizationRecommendation(
                priority_rank=0,  # å¾Œã§è¨­å®š
                issue=issue,
                action=action,
                expected_improvement=expected_improvement,
                effort_estimate=effort_estimate,
                success_probability=success_probability,
                roi_score=roi_score,
                detailed_steps=self._generate_detailed_steps(issue),
                prerequisites=self._determine_prerequisites(issue)
            )
        except:
            return None
    
    def _determine_action(self, issue: QualityIssue) -> str:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        if issue.issue_type == "predicted":
            return f"äºˆé˜²çš„ä¿®æ­£: {issue.severity} ãƒ¬ãƒ™ãƒ«å•é¡Œã®è§£æ±º"
        elif issue.issue_type == "quality_feedback":
            return f"å“è³ªæ”¹å–„: ã‚¹ã‚³ã‚¢ {(1-issue.impact_score):.2f} ã‹ã‚‰å‘ä¸Š"
        elif issue.issue_type == "auto_guard":
            return f"ã‚¬ãƒ¼ãƒ‰ä¿®æ­£: {issue.severity} å•é¡Œã®è§£æ±º"
        else:
            return f"å“è³ªå‘ä¸Š: {issue.file_path} ã®æ”¹å–„"
    
    def _calculate_expected_improvement(self, issue: QualityIssue) -> float:
        """æœŸå¾…æ”¹å–„åŠ¹æœè¨ˆç®—"""
        base_improvement = issue.impact_score * issue.business_impact * (issue.frequency / 2.0)
        
        # æŠ€è¡“çš„è² å‚µè»½æ¸›åŠ¹æœ
        debt_reduction = issue.technical_debt * 0.3
        
        # å…¨ä½“çš„ãªå“è³ªå‘ä¸ŠåŠ¹æœ
        quality_boost = min(1.0, base_improvement + debt_reduction)
        
        return quality_boost
    
    def _categorize_effort(self, minutes: int) -> str:
        """å·¥æ•°ã‚«ãƒ†ã‚´ãƒªåŒ–"""
        if minutes <= 15:
            return "ç°¡å˜ (15åˆ†ä»¥å†…)"
        elif minutes <= 60:
            return "æ¨™æº– (1æ™‚é–“ä»¥å†…)"
        elif minutes <= 240:
            return "ä¸­ç¨‹åº¦ (åŠæ—¥ä»¥å†…)"
        else:
            return "å¤§è¦æ¨¡ (1æ—¥ä»¥ä¸Š)"
    
    def _estimate_success_probability(self, issue: QualityIssue) -> float:
        """æˆåŠŸç¢ºç‡æ¨å®š"""
        base_probability = 0.8
        
        # é›£æ˜“åº¦ã«ã‚ˆã‚‹èª¿æ•´
        difficulty_factor = max(0.3, 1.0 - (issue.fix_difficulty - 1) * 0.15)
        
        # å•é¡Œã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹èª¿æ•´
        type_factor = 1.0
        if issue.issue_type == "predicted":
            type_factor = 0.9  # äºˆæ¸¬ãªã®ã§ã‚„ã‚„ä¸ç¢ºå®Ÿ
        elif issue.issue_type == "auto_guard":
            type_factor = 0.95  # è‡ªå‹•ã‚¬ãƒ¼ãƒ‰ãŒæ¤œå‡ºæ¸ˆã¿ãªã®ã§ç¢ºå®Ÿ
        
        return base_probability * difficulty_factor * type_factor
    
    def _calculate_roi(self, improvement: float, time_minutes: int, success_prob: float) -> float:
        """ROI è¨ˆç®—"""
        # åŠ¹æœã‚’æ™‚é–“ã§å‰²ã£ã¦ã€æˆåŠŸç¢ºç‡ã‚’æ›ã‘ã‚‹
        roi = (improvement * success_prob) / (time_minutes / 60.0)  # æ™‚é–“å˜ä½
        return roi
    
    def _generate_detailed_steps(self, issue: QualityIssue) -> List[str]:
        """è©³ç´°ã‚¹ãƒ†ãƒƒãƒ—ç”Ÿæˆ"""
        steps = []
        
        if "yaml" in issue.file_path:
            steps = [
                "1. yamllint ã§ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ",
                "2. è‡ªå‹•ä¿®æ­£å¯èƒ½ãªé …ç›®ã‚’ scripts/quality/yaml_auto_fixer.py ã§ä¿®æ­£",
                "3. æ‰‹å‹•ä¿®æ­£ãŒå¿…è¦ãªé …ç›®ã‚’ã‚¨ãƒ‡ã‚£ã‚¿ã§ä¿®æ­£",
                "4. ä¿®æ­£å¾Œã«å†åº¦ yamllint ã§ç¢ºèª"
            ]
        elif ".py" in issue.file_path:
            steps = [
                "1. Python ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯",
                "2. docstring ã®è¿½åŠ ãƒ»æ”¹å–„",
                "3. ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦ã®è»½æ¸›",
                "4. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã§å‹•ä½œç¢ºèª"
            ]
        else:
            steps = [
                "1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’ç¢ºèª",
                "2. å•é¡Œç®‡æ‰€ã®ç‰¹å®šãƒ»åˆ†æ",
                "3. ä¿®æ­£è¨ˆç”»ã®ç­–å®š",
                "4. ä¿®æ­£å®Ÿè¡Œãƒ»ãƒ†ã‚¹ãƒˆ",
                "5. å“è³ªå‘ä¸ŠåŠ¹æœã®ç¢ºèª"
            ]
        
        return steps
    
    def _determine_prerequisites(self, issue: QualityIssue) -> List[str]:
        """å‰ææ¡ä»¶æ±ºå®š"""
        prerequisites = []
        
        if issue.fix_difficulty >= 3:
            prerequisites.append("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ")
        
        if issue.business_impact >= 2:
            prerequisites.append("ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã§ã®äº‹å‰ãƒ†ã‚¹ãƒˆ")
        
        if issue.issue_type == "auto_guard" and issue.severity == "critical":
            prerequisites.append("ç·Šæ€¥å¯¾å¿œãƒãƒ¼ãƒ ã®æº–å‚™")
        
        if "security" in issue.issue_type:
            prerequisites.append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å®Ÿæ–½")
        
        return prerequisites if prerequisites else ["ç‰¹ã«ãªã—"]


class IntelligentOptimizerEngine:
    """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.data_engine = DataIntegrationEngine()
        self.optimization_engine = OptimizationEngine()
        self.last_analysis = None
    
    def analyze_and_optimize(self) -> Dict[str, Any]:
        """åˆ†æãƒ»æœ€é©åŒ–å®Ÿè¡Œ"""
        print("ğŸ§  ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆå“è³ªæœ€é©åŒ–åˆ†æé–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        integrated_data = self.data_engine.load_integrated_data()
        print(f"ğŸ“Š {len(self.data_engine.data_sources)} ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’çµ±åˆ")
        
        # å•é¡Œåˆ†æ
        analysis_engine = IssueAnalysisEngine(integrated_data)
        issues = analysis_engine.analyze_all_issues()
        print(f"ğŸ” {len(issues)} å€‹ã®å“è³ªå•é¡Œã‚’æ¤œå‡ºãƒ»åˆ†æ")
        
        # æœ€é©åŒ–æ¨å¥¨ç”Ÿæˆ
        recommendations = self.optimization_engine.generate_recommendations(issues)
        print(f"ğŸ’¡ {len(recommendations)} å€‹ã®æœ€é©åŒ–æ¨å¥¨ã‚’ç”Ÿæˆ")
        
        # çµæœçµ±åˆ
        result = {
            "analysis_timestamp": datetime.now().isoformat(),
            "total_issues": len(issues),
            "total_recommendations": len(recommendations),
            "data_sources_analyzed": len(self.data_engine.data_sources),
            "top_recommendations": [self._rec_to_dict(rec) for rec in recommendations[:10]],
            "summary_statistics": self._calculate_summary_stats(issues, recommendations),
            "next_actions": self._generate_next_actions(recommendations[:5])
        }
        
        # çµæœä¿å­˜
        self._save_results(result)
        
        self.last_analysis = result
        return result
    
    def _rec_to_dict(self, rec: OptimizationRecommendation) -> Dict[str, Any]:
        """æ¨å¥¨ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "priority": rec.priority_rank,
            "file": rec.issue.file_path,
            "issue_type": rec.issue.issue_type,
            "severity": rec.issue.severity,
            "action": rec.action,
            "expected_improvement": round(rec.expected_improvement, 3),
            "effort": rec.effort_estimate,
            "success_probability": round(rec.success_probability, 3),
            "roi_score": round(rec.roi_score, 3),
            "detailed_steps": rec.detailed_steps,
            "prerequisites": rec.prerequisites
        }
    
    def _calculate_summary_stats(self, issues: List[QualityIssue], recommendations: List[OptimizationRecommendation]) -> Dict[str, Any]:
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼è¨ˆç®—"""
        if not recommendations:
            return {"total_improvement": 0, "average_roi": 0, "effort_distribution": {}}
        
        total_improvement = sum(rec.expected_improvement for rec in recommendations)
        average_roi = sum(rec.roi_score for rec in recommendations) / len(recommendations)
        
        effort_dist = {}
        for rec in recommendations:
            effort_dist[rec.effort_estimate] = effort_dist.get(rec.effort_estimate, 0) + 1
        
        severity_dist = {}
        for issue in issues:
            severity_dist[issue.severity] = severity_dist.get(issue.severity, 0) + 1
        
        return {
            "total_expected_improvement": round(total_improvement, 3),
            "average_roi": round(average_roi, 3),
            "effort_distribution": effort_dist,
            "severity_distribution": severity_dist,
            "high_impact_issues": len([i for i in issues if i.business_impact >= 2]),
            "quick_wins": len([r for r in recommendations if "ç°¡å˜" in r.effort_estimate and r.roi_score >= 1.0])
        }
    
    def _generate_next_actions(self, top_recs: List[OptimizationRecommendation]) -> List[str]:
        """æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        if not top_recs:
            return ["å“è³ªåˆ†æãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Phase 1-3ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¦ãã ã•ã„ã€‚"]
        
        actions = []
        
        # æœ€å„ªå…ˆé …ç›®
        if top_recs[0].roi_score >= 2.0:
            actions.append(f"ğŸš€ æœ€å„ªå…ˆ: {top_recs[0].action} (ROI: {top_recs[0].roi_score:.1f})")
        else:
            actions.append(f"âš¡ æ¨å¥¨: {top_recs[0].action}")
        
        # ã‚¯ã‚¤ãƒƒã‚¯ã‚¦ã‚£ãƒ³
        quick_wins = [r for r in top_recs if "ç°¡å˜" in r.effort_estimate]
        if quick_wins:
            actions.append(f"ğŸ’¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¦ã‚£ãƒ³: {len(quick_wins)}å€‹ã®ç°¡å˜ä¿®æ­£ã‹ã‚‰é–‹å§‹")
        
        # é«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
        high_impact = [r for r in top_recs if r.expected_improvement >= 2.0]
        if high_impact:
            actions.append(f"ğŸ¯ é«˜å½±éŸ¿: {len(high_impact)}å€‹ã®é«˜åŠ¹æœä¿®æ­£ã‚’è¨ˆç”»")
        
        return actions[:5]
    
    def _save_results(self, result: Dict[str, Any]):
        """çµæœä¿å­˜"""
        try:
            os.makedirs("out", exist_ok=True)
            with open("out/intelligent_optimization.json", "w") as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_results(self):
        """çµæœè¡¨ç¤º"""
        if not self.last_analysis:
            print("âŒ åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚analyze_and_optimize() ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        result = self.last_analysis
        
        print("\nğŸ§  ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆå“è³ªæœ€é©åŒ–åˆ†æçµæœ")
        print("=" * 50)
        
        print(f"ğŸ“Š ç·åˆçµ±è¨ˆ:")
        print(f"   æ¤œå‡ºå•é¡Œæ•°: {result['total_issues']}")
        print(f"   æ¨å¥¨é …ç›®æ•°: {result['total_recommendations']}")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {result['data_sources_analyzed']}")
        
        stats = result['summary_statistics']
        print(f"\nğŸ’ åŠ¹æœäºˆæ¸¬:")
        print(f"   æœŸå¾…æ”¹å–„åŠ¹æœ: {stats['total_expected_improvement']:.2f}")
        print(f"   å¹³å‡ROI: {stats['average_roi']:.2f}")
        print(f"   ã‚¯ã‚¤ãƒƒã‚¯ã‚¦ã‚£ãƒ³: {stats.get('quick_wins', 0)}å€‹")
        print(f"   é«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ: {stats.get('high_impact_issues', 0)}å€‹")
        
        print(f"\nğŸš€ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        for action in result['next_actions']:
            print(f"   â€¢ {action}")
        
        print(f"\nğŸ† ãƒˆãƒƒãƒ—5æ¨å¥¨é …ç›®:")
        for i, rec in enumerate(result['top_recommendations'][:5], 1):
            print(f"   {i}. {rec['action']}")
            print(f"      ãƒ•ã‚¡ã‚¤ãƒ«: {rec['file']}")
            print(f"      åŠ¹æœ: {rec['expected_improvement']:.2f}, å·¥æ•°: {rec['effort']}, ROI: {rec['roi_score']:.2f}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ğŸ§  Intelligent Quality Optimizer")
    parser.add_argument("--analyze", action="store_true", help="Run analysis and optimization")
    parser.add_argument("--display", action="store_true", help="Display last analysis results")
    parser.add_argument("--top", type=int, default=10, help="Show top N recommendations")
    
    args = parser.parse_args()
    
    optimizer = IntelligentOptimizerEngine()
    
    if args.analyze:
        result = optimizer.analyze_and_optimize()
        optimizer.display_results()
        
    elif args.display:
        # ä¿å­˜ã•ã‚ŒãŸçµæœã‚’èª­ã¿è¾¼ã¿è¡¨ç¤º
        try:
            with open("out/intelligent_optimization.json") as f:
                result = json.load(f)
                optimizer.last_analysis = result
                optimizer.display_results()
        except:
            print("âŒ ä¿å­˜ã•ã‚ŒãŸåˆ†æçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚--analyze ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    else:
        print("âŒ --analyze ã¾ãŸã¯ --display ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        parser.print_help()


if __name__ == "__main__":
    main()
