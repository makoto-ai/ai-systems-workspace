#!/usr/bin/env python3
"""
âš¡ Phase 5: å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚¨ãƒ³ã‚¸ãƒ³
===============================

å“è³ªå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®å‹•çš„æœ€é©é…åˆ†ã‚·ã‚¹ãƒ†ãƒ 
ã‚·ã‚¹ãƒ†ãƒ è² è·ãƒ»äºˆæ¸¬éœ€è¦ãƒ»ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸè‡ªå‹•ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

ä¸»è¦æ©Ÿèƒ½:
- ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
- ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰éœ€è¦äºˆæ¸¬  
- å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
- è² è·åˆ†æ•£ãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
- ã‚³ã‚¹ãƒˆåŠ¹ç‡æœ€é©åŒ–
"""

import os
import sys
import json
import psutil
import threading
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import statistics
import queue
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
import math


class ResourceType(Enum):
    """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—"""
    CPU = "cpu"
    MEMORY = "memory"
    DISK_IO = "disk_io"
    NETWORK_IO = "network_io"
    PROCESS_SLOTS = "process_slots"


class WorkloadPriority(Enum):
    """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å„ªå…ˆåº¦"""
    CRITICAL = 1    # SLAé•åå¯¾å¿œ
    HIGH = 2       # Phase 4 AIåˆ†æ
    MEDIUM = 3     # Phase 3 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ 
    LOW = 4       # Phase 1-2 ãƒãƒƒãƒå‡¦ç†


@dataclass
class SystemResources:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±"""
    timestamp: datetime
    cpu_percent: float
    cpu_cores: int
    memory_percent: float
    memory_total_gb: float
    memory_available_gb: float
    disk_io_read_mb: float
    disk_io_write_mb: float
    network_io_sent_mb: float
    network_io_recv_mb: float
    active_processes: int
    load_average: Tuple[float, float, float]  # 1, 5, 15 min


@dataclass
class QualityWorkload:
    """å“è³ªå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰"""
    workload_id: str
    workload_type: str  # "sla_monitoring", "autonomous_fix", "ai_analysis", etc.
    priority: WorkloadPriority
    estimated_cpu_usage: float
    estimated_memory_mb: float
    estimated_duration_seconds: int
    required_resources: Dict[ResourceType, float]
    dependencies: List[str]
    scheduled_at: Optional[datetime]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    resource_allocation: Dict[str, Any]


@dataclass
class ResourceAllocation:
    """ãƒªã‚½ãƒ¼ã‚¹é…åˆ†çµæœ"""
    allocation_id: str
    workload_id: str
    allocated_resources: Dict[ResourceType, float]
    allocation_efficiency: float
    estimated_completion_time: datetime
    cost_estimate: float
    allocation_strategy: str
    constraints: List[str]


class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
    
    def __init__(self, monitoring_interval: int = 30):
        self.monitoring_interval = monitoring_interval
        self.monitoring_active = False
        self.resource_history = []
        self.max_history_size = 100
        
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring_active = True
        monitoring_thread = threading.Thread(target=self._monitoring_loop)
        monitoring_thread.daemon = True
        monitoring_thread.start()
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–é–‹å§‹")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring_active = False
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring_active:
            try:
                resources = self.collect_system_resources()
                self.resource_history.append(resources)
                
                # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
                if len(self.resource_history) > self.max_history_size:
                    self.resource_history = self.resource_history[-self.max_history_size:]
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                print(f"ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(self.monitoring_interval)
    
    def collect_system_resources(self) -> SystemResources:
        """ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹åé›†"""
        try:
            # CPUæƒ…å ±
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_cores = psutil.cpu_count()
            
            # ãƒ¡ãƒ¢ãƒªæƒ…å ±
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_total_gb = memory.total / (1024**3)
            memory_available_gb = memory.available / (1024**3)
            
            # ãƒ‡ã‚£ã‚¹ã‚¯I/O
            disk_io = psutil.disk_io_counters()
            disk_read_mb = disk_io.read_bytes / (1024**2) if disk_io else 0
            disk_write_mb = disk_io.write_bytes / (1024**2) if disk_io else 0
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O
            net_io = psutil.net_io_counters()
            net_sent_mb = net_io.bytes_sent / (1024**2) if net_io else 0
            net_recv_mb = net_io.bytes_recv / (1024**2) if net_io else 0
            
            # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±
            active_processes = len(psutil.pids())
            
            # ãƒ­ãƒ¼ãƒ‰ã‚¢ãƒ™ãƒ¬ãƒ¼ã‚¸ï¼ˆUnixç³»ã®ã¿ï¼‰
            try:
                load_avg = os.getloadavg()
            except AttributeError:
                load_avg = (cpu_percent/100 * cpu_cores, 0.0, 0.0)  # Fallback for Windows
            
            return SystemResources(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                cpu_cores=cpu_cores,
                memory_percent=memory_percent,
                memory_total_gb=memory_total_gb,
                memory_available_gb=memory_available_gb,
                disk_io_read_mb=disk_read_mb,
                disk_io_write_mb=disk_write_mb,
                network_io_sent_mb=net_sent_mb,
                network_io_recv_mb=net_recv_mb,
                active_processes=active_processes,
                load_average=load_avg
            )
            
        except Exception as e:
            print(f"ãƒªã‚½ãƒ¼ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return SystemResources(
                timestamp=datetime.now(),
                cpu_percent=50.0,
                cpu_cores=4,
                memory_percent=60.0,
                memory_total_gb=8.0,
                memory_available_gb=3.2,
                disk_io_read_mb=100.0,
                disk_io_write_mb=50.0,
                network_io_sent_mb=10.0,
                network_io_recv_mb=15.0,
                active_processes=100,
                load_average=(1.5, 1.2, 1.0)
            )
    
    def get_resource_trend(self, resource_type: str, window_minutes: int = 30) -> Dict[str, float]:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨å‚¾å‘åˆ†æ"""
        if len(self.resource_history) < 2:
            return {"trend": 0.0, "volatility": 0.0, "current": 0.0}
        
        # æŒ‡å®šæ™‚é–“çª“å†…ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        cutoff_time = datetime.now() - timedelta(minutes=window_minutes)
        recent_data = [r for r in self.resource_history if r.timestamp > cutoff_time]
        
        if not recent_data:
            recent_data = self.resource_history[-10:]  # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿
        
        # ãƒªã‚½ãƒ¼ã‚¹å€¤æŠ½å‡º
        if resource_type == "cpu":
            values = [r.cpu_percent for r in recent_data]
        elif resource_type == "memory":
            values = [r.memory_percent for r in recent_data]
        elif resource_type == "disk_io":
            values = [r.disk_io_read_mb + r.disk_io_write_mb for r in recent_data]
        elif resource_type == "network_io":
            values = [r.network_io_sent_mb + r.network_io_recv_mb for r in recent_data]
        else:
            values = [0.0] * len(recent_data)
        
        if len(values) < 2:
            return {"trend": 0.0, "volatility": 0.0, "current": values[0] if values else 0.0}
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—ï¼ˆç·šå½¢å›å¸°ã®å‚¾ãï¼‰
        n = len(values)
        x_vals = list(range(n))
        x_mean = statistics.mean(x_vals)
        y_mean = statistics.mean(values)
        
        numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_vals, values))
        denominator = sum((x - x_mean) ** 2 for x in x_vals)
        
        trend = numerator / denominator if denominator != 0 else 0.0
        volatility = statistics.stdev(values) if len(values) > 1 else 0.0
        
        return {
            "trend": trend,
            "volatility": volatility,
            "current": values[-1],
            "avg": statistics.mean(values),
            "min": min(values),
            "max": max(values)
        }


class WorkloadPredictor:
    """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.workload_patterns = self._load_workload_patterns()
        self.prediction_horizon_hours = 2
    
    def _load_workload_patterns(self) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        return {
            "sla_monitoring": {
                "frequency_minutes": 15,
                "cpu_usage": 5.0,
                "memory_mb": 50,
                "duration_seconds": 30,
                "peak_hours": [9, 10, 11, 14, 15, 16]
            },
            "autonomous_fix": {
                "frequency_minutes": 60,
                "cpu_usage": 25.0,
                "memory_mb": 200,
                "duration_seconds": 300,
                "peak_hours": [10, 11, 15, 16]
            },
            "ai_analysis": {
                "frequency_minutes": 120,
                "cpu_usage": 60.0,
                "memory_mb": 800,
                "duration_seconds": 600,
                "peak_hours": [9, 13, 17]
            },
            "realtime_monitoring": {
                "frequency_minutes": 5,
                "cpu_usage": 10.0,
                "memory_mb": 100,
                "duration_seconds": 60,
                "peak_hours": [8, 9, 10, 11, 13, 14, 15, 16, 17]
            }
        }
    
    def predict_workload_demand(self, hours_ahead: int = 2) -> List[QualityWorkload]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰éœ€è¦äºˆæ¸¬"""
        predicted_workloads = []
        current_time = datetime.now()
        
        for workload_type, pattern in self.workload_patterns.items():
            frequency_minutes = pattern["frequency_minutes"]
            
            # äºˆæ¸¬æœŸé–“å†…ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆ
            time_cursor = current_time
            end_time = current_time + timedelta(hours=hours_ahead)
            
            workload_counter = 0
            while time_cursor <= end_time:
                # ãƒ”ãƒ¼ã‚¯æ™‚é–“ã§ã®é »åº¦èª¿æ•´
                hour = time_cursor.hour
                frequency_multiplier = 1.5 if hour in pattern["peak_hours"] else 1.0
                
                adjusted_frequency = frequency_minutes / frequency_multiplier
                
                workload = QualityWorkload(
                    workload_id=f"{workload_type}_{int(time_cursor.timestamp())}_{workload_counter}",
                    workload_type=workload_type,
                    priority=self._determine_workload_priority(workload_type),
                    estimated_cpu_usage=pattern["cpu_usage"] * frequency_multiplier,
                    estimated_memory_mb=pattern["memory_mb"],
                    estimated_duration_seconds=pattern["duration_seconds"],
                    required_resources=self._calculate_required_resources(pattern, frequency_multiplier),
                    dependencies=[],
                    scheduled_at=time_cursor,
                    started_at=None,
                    completed_at=None,
                    resource_allocation={}
                )
                predicted_workloads.append(workload)
                
                time_cursor += timedelta(minutes=adjusted_frequency)
                workload_counter += 1
        
        return sorted(predicted_workloads, key=lambda w: w.scheduled_at)
    
    def _determine_workload_priority(self, workload_type: str) -> WorkloadPriority:
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å„ªå…ˆåº¦æ±ºå®š"""
        priority_map = {
            "sla_monitoring": WorkloadPriority.CRITICAL,
            "autonomous_fix": WorkloadPriority.HIGH,
            "ai_analysis": WorkloadPriority.HIGH,
            "realtime_monitoring": WorkloadPriority.MEDIUM,
            "batch_analysis": WorkloadPriority.LOW
        }
        return priority_map.get(workload_type, WorkloadPriority.MEDIUM)
    
    def _calculate_required_resources(self, pattern: Dict, multiplier: float) -> Dict[ResourceType, float]:
        """å¿…è¦ãƒªã‚½ãƒ¼ã‚¹è¨ˆç®—"""
        return {
            ResourceType.CPU: pattern["cpu_usage"] * multiplier / 100.0,  # CPUä½¿ç”¨ç‡ã‚’0-1ã«æ­£è¦åŒ–
            ResourceType.MEMORY: pattern["memory_mb"],
            ResourceType.PROCESS_SLOTS: 1,
            ResourceType.DISK_IO: 10.0 * multiplier,  # MB/s
            ResourceType.NETWORK_IO: 5.0 * multiplier  # MB/s
        }


class ResourceOptimizer:
    """ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, monitor: SystemMonitor):
        self.monitor = monitor
        self.optimization_strategies = ["greedy", "load_balanced", "cost_optimized"]
    
    def optimize_allocation(self, workloads: List[QualityWorkload], current_resources: SystemResources) -> List[ResourceAllocation]:
        """ãƒªã‚½ãƒ¼ã‚¹é…åˆ†æœ€é©åŒ–"""
        allocations = []
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        sorted_workloads = sorted(workloads, key=lambda w: (w.priority.value, w.scheduled_at))
        
        # åˆ©ç”¨å¯èƒ½ãƒªã‚½ãƒ¼ã‚¹è¨ˆç®—
        available_resources = self._calculate_available_resources(current_resources)
        
        for workload in sorted_workloads:
            allocation = self._allocate_resources(workload, available_resources, current_resources)
            
            if allocation:
                allocations.append(allocation)
                # é…åˆ†å¾Œã®ãƒªã‚½ãƒ¼ã‚¹æ›´æ–°
                self._update_available_resources(available_resources, allocation)
        
        return allocations
    
    def _calculate_available_resources(self, current_resources: SystemResources) -> Dict[ResourceType, float]:
        """åˆ©ç”¨å¯èƒ½ãƒªã‚½ãƒ¼ã‚¹è¨ˆç®—"""
        # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³è€ƒæ…®
        cpu_margin = 0.8  # 80%ã¾ã§ä½¿ç”¨å¯
        memory_margin = 0.85  # 85%ã¾ã§ä½¿ç”¨å¯
        
        return {
            ResourceType.CPU: max(0, (100 - current_resources.cpu_percent) * cpu_margin / 100),
            ResourceType.MEMORY: current_resources.memory_available_gb * 1024 * memory_margin,  # MB
            ResourceType.PROCESS_SLOTS: max(0, 50 - current_resources.active_processes // 10),  # ç°¡æ˜“è¨ˆç®—
            ResourceType.DISK_IO: 100.0,  # MB/s ã®ä»®å®šå€¤
            ResourceType.NETWORK_IO: 50.0  # MB/s ã®ä»®å®šå€¤
        }
    
    def _allocate_resources(self, workload: QualityWorkload, available_resources: Dict[ResourceType, float], 
                           current_resources: SystemResources) -> Optional[ResourceAllocation]:
        """å€‹åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒªã‚½ãƒ¼ã‚¹é…åˆ†"""
        allocated = {}
        allocation_efficiency = 1.0
        
        # å„ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®é…åˆ†ãƒã‚§ãƒƒã‚¯
        for resource_type, required in workload.required_resources.items():
            available = available_resources.get(resource_type, 0)
            
            if available >= required:
                allocated[resource_type] = required
            else:
                # ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®å ´åˆã®å¯¾å¿œæˆ¦ç•¥
                if workload.priority in [WorkloadPriority.CRITICAL, WorkloadPriority.HIGH]:
                    # é«˜å„ªå…ˆåº¦ã¯åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™ä½¿ç”¨
                    allocated[resource_type] = available
                    allocation_efficiency *= (available / required) if required > 0 else 1.0
                else:
                    # ä½å„ªå…ˆåº¦ã¯ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³æ™‚ã«ã‚¹ã‚­ãƒƒãƒ—
                    return None
        
        # åŠ¹ç‡æ€§ã®æœ€å°å€¤ä¿è¨¼
        allocation_efficiency = max(0.1, allocation_efficiency)  # æœ€ä½10%ã®åŠ¹ç‡ã¯ä¿è¨¼
        
        if allocation_efficiency < 0.5 and workload.priority not in [WorkloadPriority.CRITICAL]:
            # åŠ¹ç‡æ€§ãŒä½ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆCriticalä»¥å¤–ï¼‰
            return None
        
        # ã‚³ã‚¹ãƒˆæ¨å®š
        cost_estimate = self._estimate_cost(allocated, workload.estimated_duration_seconds)
        
        # å®Œäº†äºˆå®šæ™‚åˆ»è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        duration_factor = max(1.0, 1.0 / allocation_efficiency)
        estimated_completion = datetime.now() + timedelta(seconds=workload.estimated_duration_seconds * duration_factor)
        
        return ResourceAllocation(
            allocation_id=f"alloc_{workload.workload_id}",
            workload_id=workload.workload_id,
            allocated_resources=allocated,
            allocation_efficiency=allocation_efficiency,
            estimated_completion_time=estimated_completion,
            cost_estimate=cost_estimate,
            allocation_strategy="priority_based",
            constraints=self._identify_constraints(allocated, available_resources)
        )
    
    def _update_available_resources(self, available_resources: Dict[ResourceType, float], allocation: ResourceAllocation):
        """é…åˆ†å¾Œã®åˆ©ç”¨å¯èƒ½ãƒªã‚½ãƒ¼ã‚¹æ›´æ–°"""
        for resource_type, allocated_amount in allocation.allocated_resources.items():
            current = available_resources.get(resource_type, 0)
            available_resources[resource_type] = max(0, current - allocated_amount)
    
    def _estimate_cost(self, allocated_resources: Dict[ResourceType, float], duration_seconds: int) -> float:
        """ã‚³ã‚¹ãƒˆæ¨å®š"""
        # ç°¡æ˜“çš„ãªã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
        cost_per_cpu_hour = 0.05  # $0.05 per CPU% hour
        cost_per_gb_hour = 0.01   # $0.01 per GB hour
        
        cpu_cost = allocated_resources.get(ResourceType.CPU, 0) * cost_per_cpu_hour * (duration_seconds / 3600)
        memory_cost = allocated_resources.get(ResourceType.MEMORY, 0) / 1024 * cost_per_gb_hour * (duration_seconds / 3600)
        
        return cpu_cost + memory_cost
    
    def _identify_constraints(self, allocated: Dict[ResourceType, float], available: Dict[ResourceType, float]) -> List[str]:
        """åˆ¶ç´„è­˜åˆ¥"""
        constraints = []
        
        for resource_type in ResourceType:
            allocated_amount = allocated.get(resource_type, 0)
            available_amount = available.get(resource_type, 0)
            
            if allocated_amount > available_amount * 0.8:
                constraints.append(f"{resource_type.value}_limited")
        
        return constraints


class WorkloadScheduler:
    """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self, max_concurrent_workloads: int = 5):
        self.max_concurrent_workloads = max_concurrent_workloads
        self.active_workloads = {}
        self.workload_queue = queue.PriorityQueue()
        self.scheduler_active = False
        
    def start_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹"""
        self.scheduler_active = True
        scheduler_thread = threading.Thread(target=self._scheduler_loop)
        scheduler_thread.daemon = True
        scheduler_thread.start()
        print("ğŸ“… ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
    
    def stop_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢"""
        self.scheduler_active = False
        print("ğŸ“… ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢")
    
    def schedule_workload(self, workload: QualityWorkload, allocation: ResourceAllocation):
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç™»éŒ²"""
        priority_value = workload.priority.value
        scheduled_time = workload.scheduled_at or datetime.now()
        
        # å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼é …ç›®ä½œæˆ (priority, scheduled_time, workload, allocation)
        self.workload_queue.put((priority_value, scheduled_time, workload, allocation))
    
    def _scheduler_loop(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ«ãƒ¼ãƒ—"""
        while self.scheduler_active:
            try:
                current_time = datetime.now()
                
                # å®Œäº†ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self._cleanup_completed_workloads()
                
                # æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å®Ÿè¡Œãƒã‚§ãƒƒã‚¯
                if len(self.active_workloads) < self.max_concurrent_workloads:
                    if not self.workload_queue.empty():
                        priority, scheduled_time, workload, allocation = self.workload_queue.get()
                        
                        if scheduled_time <= current_time:
                            self._execute_workload(workload, allocation)
                        else:
                            # ã¾ã å®Ÿè¡Œæ™‚åˆ»ã§ã¯ãªã„ã®ã§æˆ»ã™
                            self.workload_queue.put((priority, scheduled_time, workload, allocation))
                
                time.sleep(10)  # 10ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
                
            except Exception as e:
                print(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(10)
    
    def _execute_workload(self, workload: QualityWorkload, allocation: ResourceAllocation):
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        print(f"ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œé–‹å§‹: {workload.workload_type}")
        
        workload.started_at = datetime.now()
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå®Ÿè¡Œ
        execution_result = self._run_workload_by_type(workload.workload_type)
        
        # å®Ÿè¡Œçµæœè¨˜éŒ²
        self.active_workloads[workload.workload_id] = {
            "workload": workload,
            "allocation": allocation,
            "started_at": workload.started_at,
            "execution_result": execution_result
        }
    
    def _run_workload_by_type(self, workload_type: str) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¥å®Ÿè¡Œ"""
        try:
            if workload_type == "sla_monitoring":
                result = subprocess.run(
                    ["python", "scripts/quality/sla_management_system.py", "--monitor"],
                    capture_output=True, text=True, timeout=60
                )
                return {"status": "success" if result.returncode == 0 else "failed", "output": result.stdout}
                
            elif workload_type == "autonomous_fix":
                result = subprocess.run(
                    ["python", "scripts/quality/autonomous_fix_engine.py", "--run"],
                    capture_output=True, text=True, timeout=300
                )
                return {"status": "success" if result.returncode == 0 else "failed", "output": result.stdout}
                
            elif workload_type == "ai_analysis":
                result = subprocess.run(
                    ["python", "scripts/quality/intelligent_optimizer.py", "--analyze"],
                    capture_output=True, text=True, timeout=600
                )
                return {"status": "success" if result.returncode == 0 else "failed", "output": result.stdout}
                
            elif workload_type == "realtime_monitoring":
                result = subprocess.run(
                    ["python", "scripts/quality/realtime_monitor.py", "--test"],
                    capture_output=True, text=True, timeout=120
                )
                return {"status": "success" if result.returncode == 0 else "failed", "output": result.stdout}
                
            else:
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå®Ÿè¡Œ
                time.sleep(2)  # å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                return {"status": "simulated", "output": f"Simulated execution of {workload_type}"}
                
        except subprocess.TimeoutExpired:
            return {"status": "timeout", "output": f"Workload {workload_type} timed out"}
        except Exception as e:
            return {"status": "error", "output": str(e)}
    
    def _cleanup_completed_workloads(self):
        """å®Œäº†ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        completed_ids = []
        current_time = datetime.now()
        
        for workload_id, workload_info in self.active_workloads.items():
            workload = workload_info["workload"]
            started_at = workload_info["started_at"]
            
            # æ¨å®šå®Œäº†æ™‚é–“ã‚’éãã¦ã„ã‚Œã°å®Œäº†ã¨ã¿ãªã™
            if started_at and (current_time - started_at).total_seconds() > workload.estimated_duration_seconds:
                workload.completed_at = current_time
                completed_ids.append(workload_id)
                print(f"âœ… ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å®Œäº†: {workload.workload_type}")
        
        # å®Œäº†ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’å‰Šé™¤
        for workload_id in completed_ids:
            del self.active_workloads[workload_id]


class DynamicResourceAllocator:
    """å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚¨ãƒ³ã‚¸ãƒ³ ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.monitor = SystemMonitor(monitoring_interval=30)
        self.predictor = WorkloadPredictor()
        self.optimizer = ResourceOptimizer(self.monitor)
        self.scheduler = WorkloadScheduler(max_concurrent_workloads=3)
        self.allocation_history = []
        
    def start_dynamic_allocation(self) -> Dict[str, Any]:
        """å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†é–‹å§‹"""
        print("âš¡ å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹...")
        
        # ç›£è¦–ãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°é–‹å§‹
        self.monitor.start_monitoring()
        self.scheduler.start_scheduler()
        
        # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—
        current_resources = self.monitor.collect_system_resources()
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰éœ€è¦äºˆæ¸¬
        predicted_workloads = self.predictor.predict_workload_demand(hours_ahead=2)
        print(f"ğŸ“ˆ äºˆæ¸¬ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰æ•°: {len(predicted_workloads)}")
        
        # ãƒªã‚½ãƒ¼ã‚¹é…åˆ†æœ€é©åŒ–
        allocations = self.optimizer.optimize_allocation(predicted_workloads, current_resources)
        print(f"âš¡ æœ€é©åŒ–é…åˆ†æ•°: {len(allocations)}")
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
        scheduled_count = 0
        for allocation in allocations:
            # å¯¾å¿œã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’æ¤œç´¢
            workload = next((w for w in predicted_workloads if w.workload_id == allocation.workload_id), None)
            if workload:
                self.scheduler.schedule_workload(workload, allocation)
                scheduled_count += 1
        
        print(f"ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç™»éŒ²æ•°: {scheduled_count}")
        
        # å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼ä½œæˆ
        summary = {
            "execution_timestamp": datetime.now().isoformat(),
            "system_resources": {
                "cpu_percent": current_resources.cpu_percent,
                "memory_percent": current_resources.memory_percent,
                "memory_available_gb": current_resources.memory_available_gb,
                "active_processes": current_resources.active_processes
            },
            "workload_prediction": {
                "total_workloads": len(predicted_workloads),
                "workload_types": list(set(w.workload_type for w in predicted_workloads)),
                "priority_distribution": self._analyze_priority_distribution(predicted_workloads)
            },
            "resource_allocation": {
                "total_allocations": len(allocations),
                "scheduled_workloads": scheduled_count,
                "avg_allocation_efficiency": statistics.mean([a.allocation_efficiency for a in allocations]) if allocations else 0,
                "total_estimated_cost": sum(a.cost_estimate for a in allocations)
            },
            "optimization_metrics": self._calculate_optimization_metrics(allocations, current_resources)
        }
        
        # çµæœä¿å­˜
        self._save_allocation_results(summary, allocations)
        
        print("âœ… å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
        return summary
    
    def stop_dynamic_allocation(self):
        """å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åœæ­¢"""
        print("âš¡ å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢...")
        self.monitor.stop_monitoring()
        self.scheduler.stop_scheduler()
        print("âœ… å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åœæ­¢å®Œäº†")
    
    def get_allocation_status(self) -> Dict[str, Any]:
        """é…åˆ†çŠ¶æ…‹å–å¾—"""
        current_resources = self.monitor.collect_system_resources()
        
        status = {
            "timestamp": datetime.now().isoformat(),
            "system_status": {
                "cpu_percent": current_resources.cpu_percent,
                "memory_percent": current_resources.memory_percent,
                "load_average": current_resources.load_average,
                "active_processes": current_resources.active_processes
            },
            "active_workloads": len(self.scheduler.active_workloads),
            "queue_size": self.scheduler.workload_queue.qsize(),
            "resource_trends": {
                "cpu": self.monitor.get_resource_trend("cpu"),
                "memory": self.monitor.get_resource_trend("memory")
            },
            "allocation_efficiency": self._calculate_current_efficiency()
        }
        
        return status
    
    def _analyze_priority_distribution(self, workloads: List[QualityWorkload]) -> Dict[str, int]:
        """å„ªå…ˆåº¦åˆ†å¸ƒåˆ†æ"""
        distribution = {}
        for workload in workloads:
            priority = workload.priority.name
            distribution[priority] = distribution.get(priority, 0) + 1
        return distribution
    
    def _calculate_optimization_metrics(self, allocations: List[ResourceAllocation], resources: SystemResources) -> Dict[str, float]:
        """æœ€é©åŒ–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        if not allocations:
            return {}
        
        return {
            "resource_utilization_score": self._calculate_utilization_score(allocations, resources),
            "cost_efficiency_score": self._calculate_cost_efficiency(allocations),
            "priority_satisfaction_score": self._calculate_priority_satisfaction(allocations)
        }
    
    def _calculate_utilization_score(self, allocations: List[ResourceAllocation], resources: SystemResources) -> float:
        """ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨åŠ¹ç‡ã‚¹ã‚³ã‚¢"""
        total_cpu_allocated = sum(a.allocated_resources.get(ResourceType.CPU, 0) for a in allocations)
        total_memory_allocated = sum(a.allocated_resources.get(ResourceType.MEMORY, 0) for a in allocations)
        
        cpu_efficiency = min(1.0, total_cpu_allocated / (resources.cpu_cores * 0.8))  # 80%ã‚’æœ€å¤§ã¨ã™ã‚‹
        memory_efficiency = min(1.0, total_memory_allocated / (resources.memory_total_gb * 1024 * 0.8))
        
        return (cpu_efficiency + memory_efficiency) / 2
    
    def _calculate_cost_efficiency(self, allocations: List[ResourceAllocation]) -> float:
        """ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚¹ã‚³ã‚¢"""
        if not allocations:
            return 0.0
        
        avg_efficiency = statistics.mean([a.allocation_efficiency for a in allocations])
        avg_cost = statistics.mean([a.cost_estimate for a in allocations])
        
        # åŠ¹ç‡ãŒé«˜ãã€ã‚³ã‚¹ãƒˆãŒä½ã„ã»ã©è‰¯ã„ã‚¹ã‚³ã‚¢
        return avg_efficiency / max(0.01, avg_cost)
    
    def _calculate_priority_satisfaction(self, allocations: List[ResourceAllocation]) -> float:
        """å„ªå…ˆåº¦æº€è¶³åº¦ã‚¹ã‚³ã‚¢"""
        if not allocations:
            return 0.0
        
        # é«˜å„ªå…ˆåº¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãŒååˆ†ãªãƒªã‚½ãƒ¼ã‚¹ã‚’å¾—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡
        high_priority_efficiency = []
        for allocation in allocations:
            if allocation.allocation_efficiency >= 0.8:  # 80%ä»¥ä¸Šã®åŠ¹ç‡
                high_priority_efficiency.append(allocation.allocation_efficiency)
        
        return statistics.mean(high_priority_efficiency) if high_priority_efficiency else 0.5
    
    def _calculate_current_efficiency(self) -> float:
        """ç¾åœ¨ã®é…åˆ†åŠ¹ç‡è¨ˆç®—"""
        if not self.scheduler.active_workloads:
            return 0.0
        
        efficiencies = []
        for workload_info in self.scheduler.active_workloads.values():
            allocation = workload_info.get("allocation")
            if allocation:
                efficiencies.append(allocation.allocation_efficiency)
        
        return statistics.mean(efficiencies) if efficiencies else 0.0
    
    def _save_allocation_results(self, summary: Dict[str, Any], allocations: List[ResourceAllocation]):
        """é…åˆ†çµæœä¿å­˜"""
        try:
            os.makedirs("out", exist_ok=True)
            
            # ã‚µãƒãƒªãƒ¼ä¿å­˜
            with open("out/dynamic_allocation_summary.json", "w") as f:
                json.dump(summary, f, indent=2)
            
            # è©³ç´°é…åˆ†çµæœä¿å­˜
            allocation_details = []
            for allocation in allocations:
                detail = asdict(allocation)
                detail["estimated_completion_time"] = allocation.estimated_completion_time.isoformat()
                # ResourceType enum ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                detail["allocated_resources"] = {k.value if hasattr(k, 'value') else str(k): v 
                                                for k, v in allocation.allocated_resources.items()}
                allocation_details.append(detail)
            
            with open("out/resource_allocations.json", "w") as f:
                json.dump(allocation_details, f, indent=2)
                
        except Exception as e:
            print(f"çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_allocation_status(self, summary: Dict[str, Any]):
        """é…åˆ†çŠ¶æ…‹è¡¨ç¤º"""
        print("\nâš¡ å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œçµæœ")
        print("=" * 50)
        
        resources = summary["system_resources"]
        print(f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹:")
        print(f"   CPUä½¿ç”¨ç‡: {resources['cpu_percent']:.1f}%")
        print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {resources['memory_percent']:.1f}%")
        print(f"   åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {resources['memory_available_gb']:.1f}GB")
        print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ã‚»ã‚¹: {resources['active_processes']}")
        
        prediction = summary["workload_prediction"]
        print(f"\nğŸ“ˆ ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰äºˆæ¸¬:")
        print(f"   äºˆæ¸¬ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰æ•°: {prediction['total_workloads']}")
        print(f"   ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: {len(prediction['workload_types'])}")
        
        allocation = summary["resource_allocation"]
        print(f"\nâš¡ ãƒªã‚½ãƒ¼ã‚¹é…åˆ†:")
        print(f"   é…åˆ†æˆåŠŸæ•°: {allocation['total_allocations']}")
        print(f"   ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç™»éŒ²æ•°: {allocation['scheduled_workloads']}")
        print(f"   å¹³å‡é…åˆ†åŠ¹ç‡: {allocation['avg_allocation_efficiency']:.3f}")
        print(f"   æ¨å®šç·ã‚³ã‚¹ãƒˆ: ${allocation['total_estimated_cost']:.4f}")
        
        if summary.get("optimization_metrics"):
            metrics = summary["optimization_metrics"]
            print(f"\nğŸ“Š æœ€é©åŒ–ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
            print(f"   ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨åŠ¹ç‡: {metrics.get('resource_utilization_score', 0):.3f}")
            print(f"   ã‚³ã‚¹ãƒˆåŠ¹ç‡: {metrics.get('cost_efficiency_score', 0):.3f}")
            print(f"   å„ªå…ˆåº¦æº€è¶³åº¦: {metrics.get('priority_satisfaction_score', 0):.3f}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="âš¡ Dynamic Resource Allocator")
    parser.add_argument("--start", action="store_true", help="Start dynamic allocation")
    parser.add_argument("--status", action="store_true", help="Show allocation status")
    parser.add_argument("--stop", action="store_true", help="Stop dynamic allocation")
    
    args = parser.parse_args()
    
    allocator = DynamicResourceAllocator()
    
    if args.stop:
        allocator.stop_dynamic_allocation()
    elif args.status:
        status = allocator.get_allocation_status()
        print("\nâš¡ å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†çŠ¶æ…‹")
        print("=" * 30)
        print(f"CPUä½¿ç”¨ç‡: {status['system_status']['cpu_percent']:.1f}%")
        print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {status['system_status']['memory_percent']:.1f}%")
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰: {status['active_workloads']}")
        print(f"ã‚­ãƒ¥ãƒ¼å¾…æ©Ÿæ•°: {status['queue_size']}")
        print(f"ç¾åœ¨ã®é…åˆ†åŠ¹ç‡: {status['allocation_efficiency']:.3f}")
    elif args.start:
        summary = allocator.start_dynamic_allocation()
        allocator.display_allocation_status(summary)
        
        print("\nğŸ”„ å‹•çš„é…åˆ†ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚åœæ­¢ã™ã‚‹ã«ã¯ --stop ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: çŸ­æœŸå®Ÿè¡Œ
        summary = allocator.start_dynamic_allocation()
        allocator.display_allocation_status(summary)
        
        # çŸ­æ™‚é–“å®Ÿè¡Œå¾Œåœæ­¢
        print("\nâ±ï¸ 30ç§’é–“ã®å‹•çš„é…åˆ†å®Ÿè¡Œ...")
        time.sleep(30)
        allocator.stop_dynamic_allocation()


if __name__ == "__main__":
    main()
