"""
Academic Paper Research Assistant - Integrated Search Version
è«–æ–‡ãƒªã‚µãƒ¼ãƒæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  - çµ±åˆæ¤œç´¢ç‰ˆ
"""

import time
from core.paper_model import Paper
from services.advanced_filter_engine import get_filter_engine, SearchFilters
from services.recommendation_engine import get_recommendation_engine
from services.search_history_db import get_search_history_db
from services.obsidian_paper_saver import ObsidianPaperSaver
from services.safe_rate_limited_search_service import (
    get_safe_rate_limited_search_service,
)
import asyncio
import logging
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from typing import List
import click
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))


console = Console()
logger = logging.getLogger(__name__)


@click.command()
@click.argument("query", type=str)
@click.option("--max-results", "-n", default=10, help="æœ€å¤§æ¤œç´¢çµæœæ•°")
@click.option(
    "--output-format",
    "-f",
    default="table",
    type=click.Choice(["table", "chatgpt"]),
    help="å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
)
@click.option("--verbose", "-v", is_flag=True, help="è©³ç´°å‡ºåŠ›")
@click.option("--save-obsidian", is_flag=True, help="æ¤œç´¢çµæœã‚’Obsidianã«è‡ªå‹•ä¿å­˜")
@click.option("--no-history", is_flag=True, help="å±¥æ­´ã‚’è¨˜éŒ²ã—ãªã„")
@click.option(
    "--with-recommendations",
    is_flag=True,
    help="é–¢é€£è«–æ–‡æ¨è–¦ã‚’ç”Ÿæˆï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰",
)
@click.option("--year-from", type=int, help="é–‹å§‹å¹´åº¦ï¼ˆä¾‹: 2020ï¼‰")
@click.option("--year-to", type=int, help="çµ‚äº†å¹´åº¦ï¼ˆä¾‹: 2025ï¼‰")
@click.option("--min-citations", type=int, help="æœ€å°å¼•ç”¨æ•°")
@click.option("--authors", help="è‘—è€…åï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
@click.option("--journals", help="ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
@click.option("--require-doi", is_flag=True, help="DOIå¿…é ˆ")
@click.option("--require-abstract", is_flag=True, help="æ¦‚è¦å¿…é ˆ")
def search_papers_integrated(
    query: str,
    max_results: int,
    output_format: str,
    verbose: bool,
    save_obsidian: bool,
    no_history: bool,
    with_recommendations: bool,
    year_from: int,
    year_to: int,
    min_citations: int,
    authors: str,
    journals: str,
    require_doi: bool,
    require_abstract: bool,
):
    """
    çµ±åˆè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 

    3ã¤ã®APIï¼ˆOpenAlexã€CrossRefã€Semantic Scholarï¼‰ã‹ã‚‰
    è«–æ–‡ã‚’æ¤œç´¢ã—ã¦ã€é‡è¤‡é™¤å»ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ãŸçµæœã‚’æä¾›ã—ã¾ã™ã€‚

    å¯¾è±¡åˆ†é‡: å–¶æ¥­ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãƒ»å¿ƒç†å­¦ãƒ»çµ„ç¹”è¡Œå‹•ãƒ»ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—
    """
    console.print(
        Panel.fit(
            "ğŸ¯ Academic Paper Research Assistant\nçµ±åˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  (3 APIs - ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Œå…¨å¯¾å¿œ)",
            style="bold blue",
        )
    )

    console.print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
    console.print(f"ğŸ“Š æœ€å¤§çµæœæ•°: {max_results}")
    console.print(f"ğŸ“„ å‡ºåŠ›å½¢å¼: {output_format}")

    # ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š
    filters = SearchFilters(
        year_from=year_from,
        year_to=year_to,
        min_citations=min_citations,
        authors=authors.split(",") if authors else None,
        journals=journals.split(",") if journals else None,
        require_doi=require_doi,
        require_abstract=require_abstract,
    )

    # ãƒ•ã‚£ãƒ«ã‚¿æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
    has_filters = any(
        [
            year_from,
            year_to,
            min_citations,
            authors,
            journals,
            require_doi,
            require_abstract,
        ]
    )
    if has_filters:
        filter_summary = get_filter_engine().create_filter_summary(filters)
        console.print(f"ğŸ”§ é©ç”¨ãƒ•ã‚£ãƒ«ã‚¿: {filter_summary}")

    if verbose:
        logging.basicConfig(level=logging.INFO)

    # çµ±åˆæ¤œç´¢å®Ÿè¡Œ + å±¥æ­´è¨˜éŒ²
    search_service = get_safe_rate_limited_search_service()

    # å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    start_time = time.time()
    papers = asyncio.run(
        search_service.search_papers(
            query, max_results * 2 if has_filters else max_results
        )
    )  # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨æ™‚ã¯å¤šã‚ã«å–å¾—
    search_time = time.time() - start_time

    if verbose:
        console.print(
            f"âœ… çµ±åˆæ¤œç´¢å®Œäº†: {len(papers)}ä»¶å–å¾— (æ¤œç´¢æ™‚é–“: {search_time:.2f}ç§’)"
        )

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    if has_filters and papers:
        filter_engine = get_filter_engine()
        filter_start_time = time.time()
        original_count = len(papers)
        papers = filter_engine.apply_filters(papers, filters)
        filter_time = time.time() - filter_start_time

        if verbose:
            console.print(
                f"ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {original_count}ä»¶ â†’ {
                    len(papers)}ä»¶ (ãƒ•ã‚£ãƒ«ã‚¿æ™‚é–“: {
                    filter_time:.2f}ç§’)"
            )

        # çµæœæ•°èª¿æ•´
        papers = papers[:max_results]

    execution_time = time.time() - start_time

    # é–¢é€£è«–æ–‡æ¨è–¦ç”Ÿæˆ
    recommendations = []
    if with_recommendations and papers:
        try:
            if verbose:
                console.print("ğŸ” é–¢é€£è«–æ–‡æ¨è–¦ã‚’ç”Ÿæˆä¸­...")

            recommendation_engine = get_recommendation_engine()
            rec_start_time = time.time()
            recommendations = asyncio.run(
                recommendation_engine.generate_recommendations(
                    source_papers=papers, max_recommendations=5, expand_search=True
                )
            )
            rec_time = time.time() - rec_start_time

            if verbose:
                console.print(
                    f"âœ… æ¨è–¦ç”Ÿæˆå®Œäº†: {
                        len(recommendations)}ä»¶ (æ¨è–¦æ™‚é–“: {
                        rec_time:.2f}ç§’)"
                )

        except Exception as e:
            logger.error(f"æ¨è–¦ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            if verbose:
                console.print("âš ï¸ æ¨è–¦ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æ¤œç´¢ã¯æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    # å±¥æ­´è¨˜éŒ²
    if not no_history:
        try:
            history_db = get_search_history_db()
            api_usage = {
                "openalex": len([p for p in papers if p.source_api == "openalex"]),
                "crossref": len([p for p in papers if p.source_api == "crossref"]),
                "semantic_scholar": len(
                    [p for p in papers if p.source_api == "semantic_scholar"]
                ),
            }

            history_id = history_db.record_search(
                query=query,
                search_type="integrated",
                max_results=max_results,
                output_format=output_format,
                results=papers,
                execution_time=execution_time,
                api_calls=api_usage,
                saved_to_obsidian=save_obsidian,
            )

            if verbose:
                console.print(f"ğŸ“Š æ¤œç´¢å±¥æ­´è¨˜éŒ²å®Œäº†: ID={history_id}")

        except Exception as e:
            logger.error(f"å±¥æ­´è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            if verbose:
                console.print("âš ï¸ å±¥æ­´è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æ¤œç´¢ã¯æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    # çµæœå‡ºåŠ›
    if output_format == "table":
        _display_table(papers, save_obsidian, query, recommendations)
    elif output_format == "chatgpt":
        _display_chatgpt_format(papers, recommendations)


def _display_table(
    papers: List[Paper],
    save_obsidian: bool = False,
    query: str = "",
    recommendations: List = None,
):
    """è¡¨å½¢å¼ã§çµæœã‚’è¡¨ç¤º"""
    if not papers:
        console.print("âŒ æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    table = Table(
        title="ğŸ“š çµ±åˆæ¤œç´¢çµæœ", show_header=True, header_style="bold magenta"
    )
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", style="cyan", width=40)
    table.add_column("è‘—è€…", style="green", width=20)
    table.add_column("å¹´", justify="center", width=8)
    table.add_column("å¼•ç”¨æ•°", justify="right", width=10)
    table.add_column("API", justify="center", width=15)
    table.add_column("ã‚¹ã‚³ã‚¢", justify="right", width=8)

    for paper in papers:
        # è‘—è€…åã‚’çµåˆ
        author_names = [author.name for author in paper.authors[:2]]
        if len(paper.authors) > 2:
            author_names.append(f"ä»–{len(paper.authors) - 2}å")
        authors_str = ", ".join(author_names)

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’çŸ­ç¸®
        title = paper.title[:60] + "..." if len(paper.title) > 60 else paper.title

        # ã‚¹ã‚³ã‚¢è¡¨ç¤º
        score_str = f"{paper.total_score:.1f}" if paper.total_score else "N/A"

        table.add_row(
            title,
            authors_str,
            str(paper.publication_year) if paper.publication_year else "N/A",
            str(paper.citation_count) if paper.citation_count else "0",
            paper.source_api.title(),
            score_str,
        )

    console.print(table)

    # Obsidianè‡ªå‹•ä¿å­˜
    if save_obsidian:
        try:
            obsidian_saver = ObsidianPaperSaver()
            saved_path = obsidian_saver.save_search_results(
                papers=papers,
                search_query=query,
                domain="general_research",  # çµ±åˆæ¤œç´¢ã§ã¯æ±ç”¨ãƒ‰ãƒ¡ã‚¤ãƒ³
                thinking_mode="general",
                metadata={"total_found": len(papers), "final_results": len(papers)},
            )
            console.print("\nğŸ“š [bold green]Obsidianä¿å­˜å®Œäº†![/bold green]")
            console.print("ğŸ“ ä¿å­˜å…ˆ: " + saved_path.name)
        except Exception as e:
            console.print("\nâŒ [bold red]Obsidianä¿å­˜ã‚¨ãƒ©ãƒ¼:[/bold red] " + str(e))

    console.print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    console.print("ã“ã®çµæœã‚’ChatGPTã‚„Claudeã«æŠ•ã’ã¦è¦ç´„ãƒ»åŸç¨¿åŒ–ã—ã¦ãã ã•ã„")
    console.print("--output-format chatgpt ã§ç›´æ¥ã‚³ãƒ”ãƒšç”¨ã®å½¢å¼ã‚’å–å¾—ã§ãã¾ã™")
    console.print("--save-obsidian ã§Obsidianã«è‡ªå‹•ä¿å­˜ã§ãã¾ã™")

    # é–¢é€£è«–æ–‡æ¨è–¦è¡¨ç¤º
    if recommendations:
        _display_recommendations(recommendations)

    console.print("\nğŸ“Š å±¥æ­´ç®¡ç†:")
    console.print("[bold cyan]python3 main_history.py list[/bold cyan] - æ¤œç´¢å±¥æ­´ä¸€è¦§")
    console.print("[bold cyan]python3 main_history.py stats[/bold cyan] - æ¤œç´¢çµ±è¨ˆ")
    console.print(
        "[bold cyan]python3 main_history.py performance[/bold cyan] - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"
    )


def _display_recommendations(recommendations: List) -> None:
    """é–¢é€£è«–æ–‡æ¨è–¦ã‚’è¡¨ç¤º"""
    if not recommendations:
        return

    console.print("\n" + "=" * 60)
    console.print("ğŸ”— é–¢é€£è«–æ–‡æ¨è–¦", style="bold magenta")
    console.print("=" * 60)

    rec_table = Table(title="ğŸ“š ã‚ãªãŸã«ãŠã™ã™ã‚ã®é–¢é€£è«–æ–‡")
    rec_table.add_column("é †ä½", style="cyan", width=6)
    rec_table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", style="green", width=35)
    rec_table.add_column("è‘—è€…", style="blue", width=20)
    rec_table.add_column("å¹´", style="yellow", width=6)
    rec_table.add_column("é¡ä¼¼åº¦", style="red", width=8)
    rec_table.add_column("æ¨è–¦ç†ç”±", style="magenta", width=20)

    for i, (paper, similarity, reason) in enumerate(recommendations, 1):
        # è‘—è€…åã®çŸ­ç¸®
        author_names = []
        if paper.authors:
            for author in paper.authors[:2]:  # æœ€åˆã®2åã®ã¿
                if author.name:
                    author_names.append(author.name)
        author_text = ", ".join(author_names)
        if len(paper.authors) > 2:
            author_text += f", ä»–{len(paper.authors) - 2}å"

        # ã‚¿ã‚¤ãƒˆãƒ«ã®çŸ­ç¸®
        title_text = paper.title[:33] + "..." if len(paper.title) > 33 else paper.title

        rec_table.add_row(
            str(i),
            title_text,
            author_text,
            str(paper.publication_year) if paper.publication_year else "N/A",
            f"{similarity:.2f}",
            reason[:18] + "..." if len(reason) > 18 else reason,
        )

    console.print(rec_table)
    console.print(f"\nğŸ’¡ æ¨è–¦è«–æ–‡æ•°: {len(recommendations)}ä»¶")
    console.print("ğŸ’¡ ã“ã‚Œã‚‰ã®è«–æ–‡ã¯æ¤œç´¢çµæœã¨é–¢é€£æ€§ãŒé«˜ã„è«–æ–‡ã§ã™")


def _display_chatgpt_format(papers: List[Paper], recommendations: List = None):
    """ChatGPT/ClaudeæŠ•å…¥ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¡¨ç¤º"""
    console.print("\n" + "=" * 60)
    console.print("ChatGPT/ClaudeæŠ•å…¥ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚³ãƒ”ãƒšå¯èƒ½ï¼‰")
    console.print("=" * 60 + "\n")

    for i, paper in enumerate(papers, 1):
        print(f"{i}. ## ğŸ“„ {paper.title}")
        print()

        # è‘—è€…æƒ…å ±
        author_names = [author.name for author in paper.authors]
        print(f"**è‘—è€…**: {', '.join(author_names)}")

        # åŸºæœ¬æƒ…å ±
        if paper.publication_year:
            print(f"**ç™ºè¡¨å¹´**: {paper.publication_year}")
        if paper.citation_count:
            print(f"**å¼•ç”¨æ•°**: {paper.citation_count}")
        if paper.doi:
            print(f"**DOI**: {paper.doi}")
        if paper.url:
            print(f"**URL**: {paper.url}")

        print()

        # æ¦‚è¦
        if paper.abstract:
            print("**æ¦‚è¦**:")
            print(paper.abstract)
            print()
        else:
            print("**æ¦‚è¦**: æ¦‚è¦ãªã—")
            print()

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        if paper.institutions:
            inst_names = [inst.name for inst in paper.institutions[:2]]
            print(f"**æ‰€å±æ©Ÿé–¢**: {', '.join(inst_names)}")

        if paper.journal:
            print(f"**ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«**: {paper.journal}")

        print(f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: {paper.source_api.title()}")

        if paper.total_score:
            print(f"**ç·åˆã‚¹ã‚³ã‚¢**: {paper.total_score:.2f}")

        print()

    # æ¨è–¦è«–æ–‡ã‚’ChatGPTå½¢å¼ã«å«ã‚ã‚‹
    if recommendations:
        print("\n" + "=" * 50)
        print("ğŸ”— é–¢é€£è«–æ–‡æ¨è–¦")
        print("=" * 50)

        for i, (paper, similarity, reason) in enumerate(recommendations, 1):
            print(f"\n## æ¨è–¦è«–æ–‡ {i}: {paper.title}")

            if paper.authors:
                author_names = [author.name for author in paper.authors if author.name]
                print(f"ğŸ“ è‘—è€…: {', '.join(author_names[:3])}")
                if len(author_names) > 3:
                    print(f"   ä»–{len(author_names) - 3}å")

            if paper.publication_year:
                print(f"ğŸ“… ç™ºè¡Œå¹´: {paper.publication_year}")

            if paper.citation_count:
                print(f"ğŸ“Š å¼•ç”¨æ•°: {paper.citation_count}")

            print(f"ğŸ¯ é¡ä¼¼åº¦: {similarity:.2f}")
            print(f"ğŸ’¡ æ¨è–¦ç†ç”±: {reason}")

            if paper.abstract:
                abstract_preview = (
                    paper.abstract[:200] + "..."
                    if len(paper.abstract) > 200
                    else paper.abstract
                )
                print(f"ğŸ“„ æ¦‚è¦: {abstract_preview}")

            if paper.doi:
                print(f"ğŸ”— DOI: {paper.doi}")
            elif paper.url:
                print(f"ğŸ”— URL: {paper.url}")

        print("\nğŸ’¡ ã“ã‚Œã‚‰ã®æ¨è–¦è«–æ–‡ã¯ã€æ¤œç´¢çµæœã¨é«˜ã„é–¢é€£æ€§ã‚’æŒã¤è«–æ–‡ã§ã™ã€‚")
        print("ğŸ’¡ ç ”ç©¶ã®å¹…ã‚’åºƒã’ã‚‹ãŸã‚ã«ã€ãœã²ã”æ´»ç”¨ãã ã•ã„ã€‚")

    print("\n" + "=" * 60)
    print("ğŸ“ æŒ‡ç¤ºä¾‹:")
    print("ã€Œä¸Šè¨˜ã®è«–æ–‡æƒ…å ±ã‚’åŸºã«ã€å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Šã«é–¢ã™ã‚‹åŸç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€")
    print()
    console.print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    console.print("ã“ã®çµæœã‚’ChatGPTã‚„Claudeã«æŠ•ã’ã¦è¦ç´„ãƒ»åŸç¨¿åŒ–ã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    search_papers_integrated()
