"""
Academic Paper Research Assistant - Specialized Search for Sales & Management Psychology
è«–æ–‡ãƒªã‚µãƒ¼ãƒæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  - å–¶æ¥­ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦ç‰¹åŒ–ç‰ˆ
"""

import time
from core.paper_model import Paper
from services.advanced_filter_engine import get_filter_engine, SearchFilters
from services.recommendation_engine import get_recommendation_engine
from services.search_history_db import get_search_history_db
from services.obsidian_paper_saver import ObsidianPaperSaver
from services.specialized_search_service import get_specialized_search_service
import asyncio
import logging
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from typing import List
import click
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))


console = Console()
logger = logging.getLogger(__name__)


@click.command()
@click.argument('query', type=str)
@click.option('--domain', '-d', default='sales_psychology',
              type=click.Choice(['sales_psychology',
                                 'management_psychology',
                                 'behavioral_economics',
                                 'universal_psychology']),
              help='å°‚é–€åˆ†é‡é¸æŠ')
@click.option('--thinking-mode', '-t', default='thesis',
              type=click.Choice(
                  ['thesis', 'antithesis', 'synthesis', 'meta_analysis']),
              help='ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰')
@click.option('--max-results', '-n', default=8, help='æœ€å¤§æ¤œç´¢çµæœæ•°')
@click.option('--output-format', '-f', default='specialized',
              type=click.Choice(['specialized', 'table', 'chatgpt']),
              help='å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ')
@click.option('--verbose', '-v', is_flag=True, help='è©³ç´°å‡ºåŠ›')
@click.option('--save-obsidian', is_flag=True, help='æ¤œç´¢çµæœã‚’Obsidianã«è‡ªå‹•ä¿å­˜')
@click.option('--no-history', is_flag=True, help='å±¥æ­´ã‚’è¨˜éŒ²ã—ãªã„')
@click.option('--with-recommendations', is_flag=True,
              help='é–¢é€£è«–æ–‡æ¨è–¦ã‚’ç”Ÿæˆï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰')
@click.option('--year-from', type=int, help='é–‹å§‹å¹´åº¦ï¼ˆä¾‹: 2020ï¼‰')
@click.option('--min-citations', type=int, help='æœ€å°å¼•ç”¨æ•°')
@click.option('--require-abstract', is_flag=True, help='æ¦‚è¦å¿…é ˆ')
def specialized_search(query: str, domain: str, thinking_mode: str, max_results: int, output_format: str, verbose: bool,
                       save_obsidian: bool, no_history: bool, with_recommendations: bool, year_from: int, min_citations: int, require_abstract: bool):
    """
    å–¶æ¥­ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦ç‰¹åŒ–æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 

    ğŸ¯ åˆ†é‡ç‰¹åŒ–:
    - sales_psychology: å–¶æ¥­å¿ƒç†å­¦ãƒ»è¡Œå‹•çµŒæ¸ˆå­¦ãƒ»ç¥çµŒç§‘å­¦
    - management_psychology: ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ãƒ»ãƒãƒ¼ãƒ ãƒ»å‹•æ©Ÿã¥ã‘
    - behavioral_economics: æ„æ€æ±ºå®šãƒ»ç¤¾ä¼šå¿ƒç†ãƒ»å¸‚å ´è¡Œå‹•
    - universal_psychology: èªçŸ¥ãƒ»æ€§æ ¼ãƒ»ç¤¾ä¼šå¿ƒç†å­¦

    ğŸ§  ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰:
    - thesis: ä¸»æµç†è«–ãƒ»ç¢ºç«‹ã•ã‚ŒãŸç ”ç©¶ï¼ˆå¼•ç”¨æ•°é‡è¦–ï¼‰
    - antithesis: æ‰¹åˆ¤ãƒ»åè¨¼ãƒ»é™ç•Œç ”ç©¶ï¼ˆé–¢é€£æ€§é‡è¦–ï¼‰
    - synthesis: çµ±åˆãƒ»ç™ºå±•ãƒ»å¿œç”¨ç ”ç©¶ï¼ˆç·åˆè©•ä¾¡ï¼‰
    - meta_analysis: ãƒ¡ã‚¿åˆ†æãƒ»ç³»çµ±çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼é‡è¦–
    """

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    domain_names = {
        'sales_psychology': 'å–¶æ¥­å¿ƒç†å­¦',
        'management_psychology': 'ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦',
        'behavioral_economics': 'è¡Œå‹•çµŒæ¸ˆå­¦',
        'universal_psychology': 'æ±ç”¨å¿ƒç†å­¦'
    }

    mode_names = {
        'thesis': 'ãƒ†ãƒ¼ã‚¼ï¼ˆä¸»æµç†è«–ï¼‰',
        'antithesis': 'ã‚¢ãƒ³ãƒãƒ†ãƒ¼ã‚¼ï¼ˆæ‰¹åˆ¤ç ”ç©¶ï¼‰',
        'synthesis': 'ã‚¸ãƒ³ãƒ†ãƒ¼ã‚¼ï¼ˆçµ±åˆç†è«–ï¼‰',
        'meta_analysis': 'ãƒ¡ã‚¿åˆ†æé‡è¦–'
    }

    header_text = f"ğŸ¯ {domain_names[domain]} Ã— ğŸ§  {mode_names[thinking_mode]}"
    console.print(Panel.fit(header_text, style="bold blue"))

    console.print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
    console.print(f"ğŸ“Š æœ€å¤§çµæœæ•°: {max_results}")
    console.print(f"ğŸ“„ å‡ºåŠ›å½¢å¼: {output_format}")

    # ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š
    filters = SearchFilters(
        year_from=year_from,
        min_citations=min_citations,
        require_abstract=require_abstract
    )

    # ãƒ•ã‚£ãƒ«ã‚¿æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
    has_filters = any([year_from, min_citations, require_abstract])
    if has_filters:
        filter_summary = get_filter_engine().create_filter_summary(filters)
        console.print(f"ğŸ”§ é©ç”¨ãƒ•ã‚£ãƒ«ã‚¿: {filter_summary}")

    if verbose:
        logging.basicConfig(level=logging.INFO)

    # ç‰¹åŒ–æ¤œç´¢å®Ÿè¡Œ + å±¥æ­´è¨˜éŒ²
    search_service = get_specialized_search_service()

    # å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    start_time = time.time()
    papers, metadata = asyncio.run(search_service.specialized_search(
        query, domain, thinking_mode, max_results * 2 if has_filters else max_results
    ))
    search_time = time.time() - start_time

    if verbose:
        console.print(
            f"âœ… ç‰¹åŒ–æ¤œç´¢å®Œäº†: {
                metadata['filtering_stats']} (æ¤œç´¢æ™‚é–“: {
                search_time:.2f}ç§’)")

    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    if has_filters and papers:
        filter_engine = get_filter_engine()
        filter_start_time = time.time()
        original_count = len(papers)
        papers = filter_engine.apply_filters(papers, filters)
        filter_time = time.time() - filter_start_time

        if verbose:
            console.print(
                f"ğŸ”§ è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {original_count}ä»¶ â†’ {
                    len(papers)}ä»¶ (ãƒ•ã‚£ãƒ«ã‚¿æ™‚é–“: {
                    filter_time:.2f}ç§’)")

        # çµæœæ•°èª¿æ•´
        papers = papers[:max_results]

    execution_time = time.time() - start_time

    # é–¢é€£è«–æ–‡æ¨è–¦ç”Ÿæˆ
    recommendations = []
    if with_recommendations and papers:
        try:
            if verbose:
                console.print("ğŸ” é–¢é€£è«–æ–‡æ¨è–¦ã‚’ç”Ÿæˆä¸­...")

            recommendation_engine = get_recommendation_engine()
            rec_start_time = time.time()
            recommendations = asyncio.run(
                recommendation_engine.generate_recommendations(
                    source_papers=papers,
                    max_recommendations=5,
                    expand_search=True
                )
            )
            rec_time = time.time() - rec_start_time

            if verbose:
                console.print(
                    f"âœ… æ¨è–¦ç”Ÿæˆå®Œäº†: {
                        len(recommendations)}ä»¶ (æ¨è–¦æ™‚é–“: {
                        rec_time:.2f}ç§’)")

        except Exception as e:
            logger.error(f"æ¨è–¦ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            if verbose:
                console.print(f"âš ï¸ æ¨è–¦ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æ¤œç´¢ã¯æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    # å±¥æ­´è¨˜éŒ²
    if not no_history:
        try:
            history_db = get_search_history_db()
            api_usage = {
                "openalex": len([p for p in papers if p.source_api == "openalex"]),
                "crossref": len([p for p in papers if p.source_api == "crossref"]),
                "semantic_scholar": len([p for p in papers if p.source_api == "semantic_scholar"])
            }

            history_id = history_db.record_search(
                query=query,
                search_type="specialized",
                max_results=max_results,
                output_format=output_format,
                results=papers,
                execution_time=execution_time,
                domain=domain,
                thinking_mode=thinking_mode,
                api_calls=api_usage,
                saved_to_obsidian=save_obsidian
            )

            if verbose:
                console.print(f"ğŸ“Š æ¤œç´¢å±¥æ­´è¨˜éŒ²å®Œäº†: ID={history_id}")

        except Exception as e:
            logger.error(f"å±¥æ­´è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            if verbose:
                console.print(f"âš ï¸ å±¥æ­´è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æ¤œç´¢ã¯æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    # çµæœå‡ºåŠ›
    if output_format == 'specialized':
        _display_specialized_format(papers, metadata, recommendations)
    elif output_format == 'table':
        _display_table(papers, recommendations)
    elif output_format == 'chatgpt':
        _display_chatgpt_format(papers, metadata, recommendations)

    # Obsidianè‡ªå‹•ä¿å­˜
    if save_obsidian:
        try:
            obsidian_saver = ObsidianPaperSaver()
            saved_path = obsidian_saver.save_search_results(
                papers=papers,
                search_query=query,
                domain=domain,
                thinking_mode=thinking_mode,
                metadata=metadata['filtering_stats']
            )
            console.print(f"\nğŸ“š [bold green]Obsidianä¿å­˜å®Œäº†![/bold green]")
            console.print(f"ğŸ“ ä¿å­˜å…ˆ: {saved_path.name}")
        except Exception as e:
            console.print(f"\nâŒ [bold red]Obsidianä¿å­˜ã‚¨ãƒ©ãƒ¼:[/bold red] {e}")


def _display_specialized_format(
        papers: List[Paper], metadata: dict, recommendations: List = None):
    """ç‰¹åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§çµæœã‚’è¡¨ç¤º"""
    if not papers:
        console.print("âŒ æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    console.print("\nğŸ“Š [bold cyan]æ¤œç´¢çµ±è¨ˆ[/bold cyan]")
    stats = metadata['filtering_stats']
    console.print(f"  â€¢ ç·æ¤œç´¢æ•°: {stats['total_found']}ä»¶")
    console.print(f"  â€¢ ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {stats['after_filtering']}ä»¶")
    console.print(f"  â€¢ æœ€çµ‚çµæœ: {stats['final_results']}ä»¶")

    # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    table = Table(
        title="ğŸ¯ ç‰¹åŒ–æ¤œç´¢çµæœ",
        show_header=True,
        header_style="bold magenta")
    table.add_column("ãƒ©ãƒ³ã‚¯", justify="center", width=6)
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", style="cyan", width=35)
    table.add_column("è‘—è€…", style="green", width=18)
    table.add_column("å¹´", justify="center", width=6)
    table.add_column("å¼•ç”¨æ•°", justify="right", width=8)
    table.add_column("ç‰¹åŒ–ã‚¹ã‚³ã‚¢", justify="right", width=10)
    table.add_column("ç¨®åˆ¥", justify="center", width=12)

    for i, paper in enumerate(papers, 1):
        # è‘—è€…åã‚’çµåˆ
        author_names = [author.name for author in paper.authors[:2]]
        if len(paper.authors) > 2:
            author_names.append(f"ä»–{len(paper.authors) - 2}å")
        authors_str = ", ".join(author_names)

        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’çŸ­ç¸®
        title = paper.title[:50] + \
            "..." if len(paper.title) > 50 else paper.title

        # ç‰¹åŒ–ã‚¹ã‚³ã‚¢
        spec_score = getattr(paper, 'specialized_score', 0)
        score_str = f"{spec_score:.1f}" if spec_score else "N/A"

        # è«–æ–‡ç¨®åˆ¥åˆ¤å®š
        paper_type = _determine_paper_type(paper)

        # ãƒ©ãƒ³ã‚¯è‰²åˆ†ã‘
        rank_style = "bold red" if i <= 3 else "bold yellow" if i <= 5 else "dim"

        table.add_row(
            f"[{rank_style}]{i}[/{rank_style}]",
            title,
            authors_str,
            str(paper.publication_year) if paper.publication_year else "N/A",
            str(paper.citation_count) if paper.citation_count else "0",
            score_str,
            paper_type
        )

    console.print(table)

    # ä½¿ç”¨æ–¹æ³•
    console.print("\nğŸ’¡ [bold green]æ´»ç”¨æ–¹æ³•[/bold green]")
    console.print("  â€¢ ChatGPTå½¢å¼: --output-format chatgpt")
    console.print("  â€¢ æ‰¹åˆ¤çš„è¦–ç‚¹: --thinking-mode antithesis")
    console.print("  â€¢ çµ±åˆç†è«–: --thinking-mode synthesis")
    console.print("  â€¢ ãƒ¡ã‚¿åˆ†æ: --thinking-mode meta_analysis")

    # æ¨è–¦è«–æ–‡è¡¨ç¤º
    if recommendations:
        _display_recommendations_specialized(recommendations)

    console.print("\nğŸ“Š [bold green]å±¥æ­´ç®¡ç†[/bold green]:")
    console.print(
        "  â€¢ [bold cyan]python3 main_history.py list[/bold cyan] - æ¤œç´¢å±¥æ­´ä¸€è¦§")
    console.print(
        "  â€¢ [bold cyan]python3 main_history.py stats[/bold cyan] - æ¤œç´¢çµ±è¨ˆ")
    console.print(
        "  â€¢ [bold cyan]python3 main_history.py performance[/bold cyan] - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")


def _display_recommendations_specialized(recommendations: List) -> None:
    """ç‰¹åŒ–æ¤œç´¢å‘ã‘æ¨è–¦è¡¨ç¤º"""
    if not recommendations:
        return

    console.print("\n" + "=" * 60)
    console.print("ğŸ”— é–¢é€£è«–æ–‡æ¨è–¦", style="bold magenta")
    console.print("=" * 60)

    rec_table = Table(title="ğŸ“š ç‰¹åŒ–æ¤œç´¢ã«åŸºã¥ãé–¢é€£è«–æ–‡æ¨è–¦")
    rec_table.add_column("é †ä½", style="cyan", width=6)
    rec_table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", style="green", width=35)
    rec_table.add_column("è‘—è€…", style="blue", width=20)
    rec_table.add_column("å¹´", style="yellow", width=6)
    rec_table.add_column("é¡ä¼¼åº¦", style="red", width=8)
    rec_table.add_column("æ¨è–¦ç†ç”±", style="magenta", width=20)

    for i, (paper, similarity, reason) in enumerate(recommendations, 1):
        # è‘—è€…åã®çŸ­ç¸®
        author_names = []
        if paper.authors:
            for author in paper.authors[:2]:  # æœ€åˆã®2åã®ã¿
                if author.name:
                    author_names.append(author.name)
        author_text = ", ".join(author_names)
        if len(paper.authors) > 2:
            author_text += f", ä»–{len(paper.authors) - 2}å"

        # ã‚¿ã‚¤ãƒˆãƒ«ã®çŸ­ç¸®
        title_text = paper.title[:33] + \
            "..." if len(paper.title) > 33 else paper.title

        rec_table.add_row(
            str(i),
            title_text,
            author_text,
            str(paper.publication_year) if paper.publication_year else "N/A",
            f"{similarity:.2f}",
            reason[:18] + "..." if len(reason) > 18 else reason
        )

    console.print(rec_table)
    console.print(f"\nğŸ’¡ æ¨è–¦è«–æ–‡æ•°: {len(recommendations)}ä»¶")
    console.print("ğŸ’¡ ç‰¹åŒ–æ¤œç´¢çµæœã«åŸºã¥ã„ã¦ã€ã•ã‚‰ã«é–¢é€£æ€§ã®é«˜ã„è«–æ–‡ã‚’æ¨è–¦ã—ã¦ã„ã¾ã™")


def _determine_paper_type(paper: Paper) -> str:
    """è«–æ–‡ç¨®åˆ¥ã‚’åˆ¤å®š"""
    text = f"{paper.title} {paper.abstract or ''}".lower()

    if any(term in text for term in ["meta-analysis", "systematic review"]):
        return "ğŸ“Š ãƒ¡ã‚¿åˆ†æ"
    elif any(term in text for term in ["review", "survey"]):
        return "ğŸ“š ãƒ¬ãƒ“ãƒ¥ãƒ¼"
    elif any(term in text for term in ["experiment", "experimental"]):
        return "ğŸ§ª å®Ÿé¨“ç ”ç©¶"
    elif any(term in text for term in ["case study", "qualitative"]):
        return "ğŸ“ äº‹ä¾‹ç ”ç©¶"
    elif any(term in text for term in ["theory", "model", "framework"]):
        return "ğŸ—ï¸ ç†è«–ç ”ç©¶"
    else:
        return "ğŸ“„ å®Ÿè¨¼ç ”ç©¶"


def _display_table(papers: List[Paper], recommendations: List = None):
    """é€šå¸¸ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼"""
    table = Table(
        title="ğŸ“š æ¤œç´¢çµæœ",
        show_header=True,
        header_style="bold magenta")
    table.add_column("ã‚¿ã‚¤ãƒˆãƒ«", style="cyan", width=40)
    table.add_column("è‘—è€…", style="green", width=20)
    table.add_column("å¹´", justify="center", width=8)
    table.add_column("å¼•ç”¨æ•°", justify="right", width=10)
    table.add_column("API", justify="center", width=15)

    for paper in papers:
        author_names = [author.name for author in paper.authors[:2]]
        if len(paper.authors) > 2:
            author_names.append(f"ä»–{len(paper.authors) - 2}å")
        authors_str = ", ".join(author_names)

        title = paper.title[:60] + \
            "..." if len(paper.title) > 60 else paper.title

        table.add_row(
            title,
            authors_str,
            str(paper.publication_year) if paper.publication_year else "N/A",
            str(paper.citation_count) if paper.citation_count else "0",
            paper.source_api.title()
        )

    console.print(table)


def _display_chatgpt_format(
        papers: List[Paper], metadata: dict, recommendations: List = None):
    """ChatGPT/ClaudeæŠ•å…¥ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    domain_names = {
        'sales_psychology': 'å–¶æ¥­å¿ƒç†å­¦',
        'management_psychology': 'ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦',
        'behavioral_economics': 'è¡Œå‹•çµŒæ¸ˆå­¦',
        'universal_psychology': 'æ±ç”¨å¿ƒç†å­¦'
    }

    mode_names = {
        'thesis': 'ãƒ†ãƒ¼ã‚¼ï¼ˆä¸»æµç†è«–ï¼‰',
        'antithesis': 'ã‚¢ãƒ³ãƒãƒ†ãƒ¼ã‚¼ï¼ˆæ‰¹åˆ¤ç ”ç©¶ï¼‰',
        'synthesis': 'ã‚¸ãƒ³ãƒ†ãƒ¼ã‚¼ï¼ˆçµ±åˆç†è«–ï¼‰',
        'meta_analysis': 'ãƒ¡ã‚¿åˆ†æé‡è¦–'
    }

    print("\n" + "=" * 70)
    print("ğŸ¯ å–¶æ¥­ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦ç‰¹åŒ–æ¤œç´¢çµæœï¼ˆChatGPT/ClaudeæŠ•å…¥ç”¨ï¼‰")
    print("=" * 70)
    print(
        f"ğŸ“Š æ¤œç´¢è¨­å®š: {domain_names[metadata['domain']]} Ã— {mode_names[metadata['thinking_mode']]}")
    print(f"ğŸ” å…ƒã‚¯ã‚¨ãƒª: {metadata['original_query']}")
    print(f"ğŸ“ˆ çµæœ: {metadata['filtering_stats']['final_results']}ä»¶")
    print("=" * 70 + "\n")

    for i, paper in enumerate(papers, 1):
        print(f"{i}. ## ğŸ“„ {paper.title}")
        print()

        # åŸºæœ¬æƒ…å ±
        author_names = [author.name for author in paper.authors]
        print(f"**è‘—è€…**: {', '.join(author_names)}")

        if paper.publication_year:
            print(f"**ç™ºè¡¨å¹´**: {paper.publication_year}")
        if paper.citation_count:
            print(f"**å¼•ç”¨æ•°**: {paper.citation_count}")
        if paper.doi:
            print(f"**DOI**: {paper.doi}")

        # ç‰¹åŒ–æƒ…å ±
        paper_type = _determine_paper_type(paper)
        print(f"**è«–æ–‡ç¨®åˆ¥**: {paper_type}")

        spec_score = getattr(paper, 'specialized_score', 0)
        if spec_score:
            print(f"**ç‰¹åŒ–ã‚¹ã‚³ã‚¢**: {spec_score:.2f}")

        print()

        # æ¦‚è¦
        if paper.abstract:
            print("**æ¦‚è¦**:")
            print(paper.abstract)
        else:
            print("**æ¦‚è¦**: æ¦‚è¦ãªã—")

        print()

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        if paper.journal:
            print(f"**ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«**: {paper.journal}")

        print(f"**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: {paper.source_api.title()}")
        print()

    print("=" * 70)
    print("ğŸ“ [åˆ†ææŒ‡ç¤ºä¾‹]")
    print("ã€Œä¸Šè¨˜ã®è«–æ–‡ã‚’åŸºã«ã€å–¶æ¥­åŠ¹ç‡å‘ä¸Šã®ãŸã‚ã®å¿ƒç†å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’")
    print("ã€€ãƒ†ãƒ¼ã‚¼ãƒ»ã‚¢ãƒ³ãƒãƒ†ãƒ¼ã‚¼ãƒ»ã‚¸ãƒ³ãƒ†ãƒ¼ã‚¼ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ã€")
    print()
    print("ğŸ’¡ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°æ´»ç”¨:")
    print("  â€¢ ä¸»æµç†è«–ã®ç¢ºèª â†’ --thinking-mode thesis")
    print("  â€¢ æ‰¹åˆ¤çš„æ¤œè¨¼ â†’ --thinking-mode antithesis")
    print("  â€¢ çµ±åˆçš„ç†è§£ â†’ --thinking-mode synthesis")


if __name__ == "__main__":
    specialized_search()
