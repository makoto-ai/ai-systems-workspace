#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“ åŸç¨¿äº‹å®Ÿç¢ºèªãƒ»æ·»å‰Šã‚·ã‚¹ãƒ†ãƒ 
YouTubeåŸç¨¿ã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºã¨ä¿¡é ¼æ€§å‘ä¸Š

Features:
- åŸç¨¿ã‹ã‚‰ä¸»å¼µãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»ç ”ç©¶åã‚’è‡ªå‹•æŠ½å‡º
- è«–æ–‡æ¤œç´¢ã«ã‚ˆã‚‹äº‹å®Ÿç¢ºèª
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡º
- ä»£æ›¿ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ¤œç´¢
- æ–‡ä½“ä¿æŒãƒªãƒ©ã‚¤ã‚¿ãƒ¼
"""

import re
import json
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import datetime
from dataclasses import dataclass
import asyncio

from services.safe_rate_limited_search_service import get_safe_rate_limited_search_service
from services.obsidian_paper_saver import ObsidianPaperSaver


@dataclass
class ExtractedClaim:
    """æŠ½å‡ºã•ã‚ŒãŸä¸»å¼µ"""
    claim_type: str  # "ç ”ç©¶çµæœ", "çµ±è¨ˆ", "å®šç¾©", "ä¸»å¼µ"
    content: str
    researcher_name: Optional[str] = None
    publication_year: Optional[str] = None
    statistic_value: Optional[str] = None
    confidence_level: str = "medium"  # high, medium, low


@dataclass
class FactCheckResult:
    """äº‹å®Ÿç¢ºèªçµæœ"""
    original_claim: ExtractedClaim
    is_hallucination: bool
    evidence_papers: List[Any]
    alternative_evidence: List[Any]
    verification_score: float  # 0-1
    recommendation: str


class ManuscriptFactChecker:
    """åŸç¨¿äº‹å®Ÿç¢ºèªã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.search_service = get_safe_rate_limited_search_service()
        self.obsidian_saver = ObsidianPaperSaver()
        
        # ç ”ç©¶è€…åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ—¥æœ¬èªï¼‰
        self.researcher_patterns = [
            r'([A-Za-z]+(?:\s+[A-Za-z]+)*?)(?:ã•ã‚“|æ°|åšå£«|æ•™æˆ|ç ”ç©¶è€…)?(?:é”|ã‚‰|ç­‰)?ã®',
            r'([A-Za-z]+(?:\s+[A-Za-z]+)*?)(?:ã«ã‚ˆã‚‹|ã®)(?:ç ”ç©¶|è«–æ–‡|èª¿æŸ»)',
            r'([A-Za-z]+(?:\s+[A-Za-z]+)*?)(?:ã¨|&|ãŠã‚ˆã³)([A-Za-z]+(?:\s+[A-Za-z]+)*?)(?:ã®|ã«ã‚ˆã‚‹)',
        ]
        
        # å¹´ä»£ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.year_patterns = [
            r'(\d{4})å¹´',
            r'(\d{4})ã®ç ”ç©¶',
            r'(\d{4})å¹´ã®',
        ]
        
        # çµ±è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
        self.statistic_patterns = [
            r'(\d+(?:\.\d+)?(?:ã€œ|ï½|-)?\d*(?:\.\d+)?)(?:%|ï¼…|ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ)',
            r'(\d+(?:\.\d+)?(?:å€|å›|ä»¶|äºº|ç¤¾))',
            r'ç´„?(\d+(?:\.\d+)?(?:ã€œ|ï½|-)?\d*(?:\.\d+)?)(?:%|ï¼…|ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ)',
        ]
        
        # ä¸»å¼µãƒ‘ã‚¿ãƒ¼ãƒ³
        self.claim_patterns = [
            r'([^ã€‚]*?)(?:ã“ã¨ãŒ|ã¨ã„ã†|ãã†ã§ã™|ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™|ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸ)',
            r'([^ã€‚]*?)(?:ã‚’ç¤ºã—ã¦ã„ã¾ã™|ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸ|ã“ã¨ãŒåˆ¤æ˜)',
            r'([^ã€‚]*?)(?:ç ”ç©¶ã§ã¯|èª¿æŸ»ã§ã¯|ã«ã‚ˆã‚‹ã¨)',
        ]

    def extract_claims_from_manuscript(self, manuscript: str) -> List[ExtractedClaim]:
        """åŸç¨¿ã‹ã‚‰ä¸»å¼µã‚’æŠ½å‡º"""
        claims = []
        sentences = self._split_into_sentences(manuscript)
        
        for sentence in sentences:
            # ç ”ç©¶è€…åã‚’æŠ½å‡º
            researchers = self._extract_researchers(sentence)
            
            # å¹´ä»£ã‚’æŠ½å‡º
            years = self._extract_years(sentence)
            
            # çµ±è¨ˆã‚’æŠ½å‡º
            statistics = self._extract_statistics(sentence)
            
            # ä¸»å¼µã‚’æŠ½å‡º
            claim_content = self._extract_claim_content(sentence)
            
            if claim_content or researchers or statistics:
                claim = ExtractedClaim(
                    claim_type=self._determine_claim_type(sentence),
                    content=sentence,
                    researcher_name=researchers[0] if researchers else None,
                    publication_year=years[0] if years else None,
                    statistic_value=statistics[0] if statistics else None,
                    confidence_level=self._assess_confidence(sentence)
                )
                claims.append(claim)
        
        return claims

    def fact_check_claims(self, claims: List[ExtractedClaim]) -> List[FactCheckResult]:
        """ä¸»å¼µã®äº‹å®Ÿç¢ºèª"""
        results = []
        
        for claim in claims:
            # è«–æ–‡æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
            search_queries = self._generate_search_queries(claim)
            
            # å„ã‚¯ã‚¨ãƒªã§æ¤œç´¢
            all_evidence = []
            for query in search_queries:
                try:
                    papers = asyncio.run(
                        self.search_service.search_papers(query, max_results=5)
                    )
                    all_evidence.extend(papers)
                except Exception as e:
                    print(f"âš ï¸ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
            is_hallucination = self._detect_hallucination(claim, all_evidence)
            
            # ä»£æ›¿ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ¤œç´¢
            alternative_evidence = []
            if is_hallucination or len(all_evidence) < 2:
                alternative_evidence = self._search_alternative_evidence(claim)
            
            # æ¤œè¨¼ã‚¹ã‚³ã‚¢è¨ˆç®—
            verification_score = self._calculate_verification_score(claim, all_evidence)
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendation = self._generate_recommendation(claim, all_evidence, is_hallucination)
            
            result = FactCheckResult(
                original_claim=claim,
                is_hallucination=is_hallucination,
                evidence_papers=all_evidence,
                alternative_evidence=alternative_evidence,
                verification_score=verification_score,
                recommendation=recommendation
            )
            results.append(result)
        
        return results

    def generate_corrected_manuscript(self, 
                                    original_manuscript: str,
                                    fact_check_results: List[FactCheckResult]) -> str:
        """ä¿®æ­£ç‰ˆåŸç¨¿ã‚’ç”Ÿæˆ"""
        corrected_manuscript = original_manuscript
        
        # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç®‡æ‰€ã‚’ä¿®æ­£
        for result in fact_check_results:
            if result.is_hallucination:
                # ä»£æ›¿ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã§ç½®ãæ›ãˆ
                replacement = self._create_evidence_based_replacement(result)
                corrected_manuscript = self._replace_maintaining_style(
                    corrected_manuscript,
                    result.original_claim.content,
                    replacement
                )
            elif result.verification_score < 0.5:
                # ä¿¡é ¼æ€§ã‚’å¼·åŒ–
                enhancement = self._enhance_credibility(result)
                corrected_manuscript = self._enhance_text_maintaining_style(
                    corrected_manuscript,
                    result.original_claim.content,
                    enhancement
                )
        
        # YouTubeæœ€é©åŒ–
        corrected_manuscript = self._optimize_for_youtube(corrected_manuscript)
        
        return corrected_manuscript

    def _split_into_sentences(self, text: str) -> List[str]:
        """æ–‡ç« ã‚’æ–‡å˜ä½ã«åˆ†å‰²"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        return [s.strip() for s in sentences if s.strip()]

    def _extract_researchers(self, sentence: str) -> List[str]:
        """ç ”ç©¶è€…åã‚’æŠ½å‡º"""
        print(f"ğŸ” ç ”ç©¶è€…åæŠ½å‡ºé–‹å§‹: {sentence}")
        researchers = []
        
        for i, pattern in enumerate(self.researcher_patterns):
            matches = re.findall(pattern, sentence)
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}: {matches}")
            
            if matches:
                if isinstance(matches[0], tuple):
                    for match in matches:
                        for name in match:
                            if name and name.strip():
                                researchers.append(name.strip())
                else:
                    for match in matches:
                        if match and match.strip():
                            researchers.append(match.strip())
        
        unique_researchers = list(set(researchers))
        print(f"ğŸ” æœ€çµ‚ç ”ç©¶è€…å: {unique_researchers}")
        return unique_researchers
    def _extract_years(self, sentence: str) -> List[str]:
        """å¹´ä»£ã‚’æŠ½å‡º"""
        years = []
        for pattern in self.year_patterns:
            matches = re.findall(pattern, sentence)
            years.extend(matches)
        return list(set(years))

    def _extract_statistics(self, sentence: str) -> List[str]:
        """çµ±è¨ˆå€¤ã‚’æŠ½å‡º"""
        statistics = []
        for pattern in self.statistic_patterns:
            matches = re.findall(pattern, sentence)
            statistics.extend(matches)
        return list(set(statistics))

    def _extract_claim_content(self, sentence: str) -> str:
        """ä¸»å¼µå†…å®¹ã‚’æŠ½å‡º"""
        for pattern in self.claim_patterns:
            match = re.search(pattern, sentence)
            if match:
                return match.group(1).strip()
        return sentence

    def _determine_claim_type(self, sentence: str) -> str:
        """ä¸»å¼µã®ç¨®é¡ã‚’åˆ¤å®š"""
        if re.search(r'ç ”ç©¶|è«–æ–‡|èª¿æŸ»', sentence):
            return "ç ”ç©¶çµæœ"
        elif re.search(r'%|ï¼…|ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ|å€|å›', sentence):
            return "çµ±è¨ˆ"
        elif re.search(r'ã¨ã¯|ã¨ã„ã†|å®šç¾©', sentence):
            return "å®šç¾©"
        else:
            return "ä¸»å¼µ"

    def _assess_confidence(self, sentence: str) -> str:
        """ä¿¡é ¼åº¦ã‚’è©•ä¾¡"""
        high_confidence_markers = ['ç ”ç©¶ã«ã‚ˆã‚‹ã¨', 'è«–æ–‡ã§ã¯', 'ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ã¨', 'èª¿æŸ»çµæœ']
        medium_confidence_markers = ['ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™', 'ãã†ã§ã™', 'ã¨ã•ã‚Œã¦ã„ã¾ã™']
        low_confidence_markers = ['ã‚‰ã—ã„', 'ã®ã‚ˆã†ã§ã™', 'æ€ã„ã¾ã™', 'æ„Ÿã˜ã¾ã™']
        
        for marker in high_confidence_markers:
            if marker in sentence:
                return "high"
        for marker in medium_confidence_markers:
            if marker in sentence:
                return "medium"
        for marker in low_confidence_markers:
            if marker in sentence:
                return "low"
        return "medium"

    def _generate_search_queries(self, claim: ExtractedClaim) -> List[str]:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        queries = []
        
        # ç ”ç©¶è€…åãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒª
        if claim.researcher_name and claim.publication_year:
            queries.append(f"{claim.researcher_name} {claim.publication_year}")
        
        # å†…å®¹ãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒª
        if "å–¶æ¥­" in claim.content:
            queries.append("sales performance personality traits")
        if "å¤–å‘æ€§" in claim.content:
            queries.append("extroversion sales performance")
        if "èª å®Ÿæ€§" in claim.content:
            queries.append("conscientiousness job performance")
        if "éºä¼" in claim.content or "ï¼…" in claim.content:
            queries.append("personality heritability genetics")
        
        # ä¸€èˆ¬çš„ãªã‚¯ã‚¨ãƒª
        keywords = re.findall(r'[A-Za-z]+', claim.content)
        if keywords:
            queries.append(" ".join(keywords[:3]))
        
        return list(set(queries))

    def _detect_hallucination(self, claim: ExtractedClaim, evidence: List[Any]) -> bool:
        """ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º"""
        if not evidence:
            return True
        
        # ç ”ç©¶è€…åã®ç¢ºèª
        if claim.researcher_name:
            found_researcher = False
            for paper in evidence:
                if hasattr(paper, 'authors') and paper.authors:
                    for author in paper.authors:
                        if claim.researcher_name.lower() in author.name.lower():
                            found_researcher = True
                            break
            if not found_researcher:
                return True
        
        # å¹´ä»£ã®ç¢ºèª
        if claim.publication_year:
            found_year = False
            for paper in evidence:
                if hasattr(paper, 'publication_year') and paper.publication_year:
                    if abs(int(paper.publication_year) - int(claim.publication_year)) <= 2:
                        found_year = True
                        break
            if not found_year:
                return True
        
        return False

    def _search_alternative_evidence(self, claim: ExtractedClaim) -> List[Any]:
        """ä»£æ›¿ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’æ¤œç´¢"""
        alternative_queries = []
        
        if "å–¶æ¥­" in claim.content:
            alternative_queries.extend([
                "sales personality Big Five performance",
                "extroversion conscientiousness sales success",
                "personality traits job performance meta-analysis"
            ])
        
        if "éºä¼" in claim.content:
            alternative_queries.extend([
                "personality heritability twin studies",
                "Big Five genetics behavioral genetics"
            ])
        
        all_alternatives = []
        for query in alternative_queries:
            try:
                papers = asyncio.run(
                    self.search_service.search_papers(query, max_results=3)
                )
                all_alternatives.extend(papers)
            except Exception as e:
                print(f"âš ï¸ ä»£æ›¿æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        return all_alternatives

    def _calculate_verification_score(self, claim: ExtractedClaim, evidence: List[Any]) -> float:
        """æ¤œè¨¼ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not evidence:
            return 0.0
        
        score = 0.0
        total_citations = sum(getattr(paper, 'citation_count', 0) or 0 for paper in evidence)
        
        # å¼•ç”¨æ•°ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        if total_citations > 1000:
            score += 0.4
        elif total_citations > 100:
            score += 0.3
        elif total_citations > 10:
            score += 0.2
        
        # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•°ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        if len(evidence) >= 3:
            score += 0.3
        elif len(evidence) >= 2:
            score += 0.2
        elif len(evidence) >= 1:
            score += 0.1
        
        # å¹´ä»£ã®æ–°ã—ã•
        recent_papers = [p for p in evidence if hasattr(p, 'publication_year') 
                        and p.publication_year and int(p.publication_year) >= 2010]
        if recent_papers:
            score += 0.3
        
        return min(score, 1.0)

    def _generate_recommendation(self, claim: ExtractedClaim, evidence: List[Any], is_hallucination: bool) -> str:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        if is_hallucination:
            return "ä»£æ›¿ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã§å®Œå…¨ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã‚’æ¨å¥¨"
        elif len(evidence) == 0:
            return "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸è¶³ - å‰Šé™¤ã¾ãŸã¯ä»£æ›¿è¡¨ç¾ã‚’æ¨å¥¨"
        elif len(evidence) < 2:
            return "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è£œå¼·ã‚’æ¨å¥¨"
        else:
            return "ä¿¡é ¼æ€§ååˆ† - å¼•ç”¨æƒ…å ±ã®è¿½åŠ ã‚’æ¨å¥¨"

    def _create_evidence_based_replacement(self, result: FactCheckResult) -> str:
        """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã®ç½®æ›æ–‡ã‚’ä½œæˆ"""
        if not result.alternative_evidence:
            return "ã€è¦æ¤œè¨¼ã€‘" + result.original_claim.content
        
        best_paper = max(result.alternative_evidence, 
                        key=lambda p: getattr(p, 'citation_count', 0) or 0)
        
        # ç ”ç©¶è€…åã‚’æŠ½å‡º
        author_name = "ç ”ç©¶è€…"
        if hasattr(best_paper, 'authors') and best_paper.authors:
            author_name = best_paper.authors[0].name.split()[-1]  # å§“ã‚’å–å¾—
        
        # å¹´ä»£ã‚’æŠ½å‡º
        year = "æœ€è¿‘"
        if hasattr(best_paper, 'publication_year') and best_paper.publication_year:
            year = f"{best_paper.publication_year}å¹´"
        
        # å¼•ç”¨æ•°æƒ…å ±
        citation_info = ""
        if hasattr(best_paper, 'citation_count') and best_paper.citation_count:
            if best_paper.citation_count > 1000:
                citation_info = f"ï¼ˆ{best_paper.citation_count:,}å›ä»¥ä¸Šå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹æ¨©å¨çš„ç ”ç©¶ï¼‰"
        
        # å…ƒã®ä¸»å¼µã®æ ¸å¿ƒçš„ãªå†…å®¹ã‚’æŠ½å‡º
        original_content = result.original_claim.content
        
        # ä¸»å¼µã®ä¸»è¦éƒ¨åˆ†ã‚’ä¿æŒ
        core_claim = self._extract_core_claim(original_content)
        
        # èªå°¾ã‚‚ä¿æŒ
        ending = self._extract_ending(original_content)
        
        replacement = f"{author_name}ã®{year}ã®ç ”ç©¶{citation_info}ã«ã‚ˆã‚‹ã¨ã€{core_claim}{ending}"
        return replacement

    def _extract_core_claim(self, text: str) -> str:
        """æ–‡ç« ã‹ã‚‰æ ¸å¿ƒçš„ãªä¸»å¼µã‚’æŠ½å‡º"""
        # ç ”ç©¶è€…åã¨å¹´ä»£ã‚’é™¤å»
        cleaned = re.sub(r'[A-Za-z]+(?:\s+[A-Za-z]+)*?(?:ã•ã‚“|æ°|åšå£«|æ•™æˆ|ç ”ç©¶è€…)?(?:é”|ã‚‰|ç­‰)?ã®', '', text)
        cleaned = re.sub(r'\d{4}å¹´ã®ç ”ç©¶ã«ã‚ˆã‚‹ã¨ã€?', '', cleaned)
        cleaned = re.sub(r'ã«ã‚ˆã‚‹ã¨ã€?', '', cleaned)
        
        # èªå°¾ã‚’é™¤å»
        cleaned = re.sub(r'(?:ãã†ã§ã™|ã§ã™|ã¾ã™|ã§ã‚ã‚‹|ã |ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™)$', '', cleaned)
        
        # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
        cleaned = cleaned.strip()
        
        return cleaned

    def _extract_ending(self, text: str) -> str:
        """æ–‡ç« ã‹ã‚‰èªå°¾ã‚’æŠ½å‡º"""
        ending_match = re.search(r'(ãã†ã§ã™|ã§ã™|ã¾ã™|ã§ã‚ã‚‹|ã |ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™)$', text)
        if ending_match:
            return ending_match.group(1)
        return "ãã†ã§ã™"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    def _replace_maintaining_style(self, text: str, original: str, replacement: str) -> str:
        """æ–‡ä½“ã‚’ç¶­æŒã—ãªãŒã‚‰ç½®æ›"""
        return text.replace(original, replacement)

    def _enhance_credibility(self, result: FactCheckResult) -> str:
        """ä¿¡é ¼æ€§å¼·åŒ–æƒ…å ±ã‚’ç”Ÿæˆ"""
        if not result.evidence_papers:
            return ""
        
        best_paper = max(result.evidence_papers, 
                        key=lambda p: getattr(p, 'citation_count', 0) or 0)
        
        enhancement = ""
        if hasattr(best_paper, 'citation_count') and best_paper.citation_count:
            if best_paper.citation_count > 1000:
                enhancement = f"ï¼ˆ{best_paper.citation_count:,}å›å¼•ç”¨ã®æ¨©å¨çš„ç ”ç©¶ï¼‰"
            elif best_paper.citation_count > 100:
                enhancement = f"ï¼ˆ{best_paper.citation_count}å›å¼•ç”¨ï¼‰"
        
        return enhancement

    def _enhance_text_maintaining_style(self, text: str, original: str, enhancement: str) -> str:
        """æ–‡ä½“ã‚’ç¶­æŒã—ãªãŒã‚‰æƒ…å ±ã‚’å¼·åŒ–"""
        if not enhancement:
            return text
        
        # æ–‡ã®çµ‚ã‚ã‚Šã«æŒ¿å…¥
        enhanced = original + enhancement
        return text.replace(original, enhanced)

    def _optimize_for_youtube(self, text: str) -> str:
        """YouTubeæœ€é©åŒ–"""
        # è¦–è´è€…ã®é–¢å¿ƒã‚’å¼•ãè¡¨ç¾ã«å¤‰æ›
        optimizations = {
            r'ç ”ç©¶ã«ã‚ˆã‚‹ã¨': 'ãªã‚“ã¨ã€æ¨©å¨çš„ãªç ”ç©¶ã«ã‚ˆã‚‹ã¨',
            r'ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸ': 'ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã‚“ã§ã™',
            r'ç¤ºã—ã¦ã„ã¾ã™': 'å®Ÿè¨¼ã•ã‚Œã¦ã„ã‚‹ã‚“ã§ã™',
            r'é‡è¦ãªã®ãŒ': 'ç‰¹ã«é‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒ',
            r'å•é¡Œã¯': 'ã“ã“ã§é‡è¦ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œã¯',
        }
        
        optimized_text = text
        for pattern, replacement in optimizations.items():
            optimized_text = re.sub(pattern, replacement, optimized_text)
        
        return optimized_text

    def run_full_fact_check(self, manuscript: str) -> Dict[str, Any]:
        """å®Œå…¨ãªäº‹å®Ÿç¢ºèªãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        print("ğŸ” åŸç¨¿äº‹å®Ÿç¢ºèªã‚’é–‹å§‹...")
        
        # 1. ä¸»å¼µæŠ½å‡º
        print("ğŸ“ ä¸»å¼µã‚’æŠ½å‡ºä¸­...")
        claims = self.extract_claims_from_manuscript(manuscript)
        print(f"âœ… {len(claims)}å€‹ã®ä¸»å¼µã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        
        # 2. äº‹å®Ÿç¢ºèª
        print("ğŸ” äº‹å®Ÿç¢ºèªã‚’å®Ÿè¡Œä¸­...")
        fact_check_results = self.fact_check_claims(claims)
        
        # 3. ä¿®æ­£ç‰ˆç”Ÿæˆ
        print("âœï¸ ä¿®æ­£ç‰ˆåŸç¨¿ã‚’ç”Ÿæˆä¸­...")
        corrected_manuscript = self.generate_corrected_manuscript(manuscript, fact_check_results)
        
        # 4. çµæœã‚’Obsidianã«ä¿å­˜
        self._save_results_to_obsidian(manuscript, fact_check_results, corrected_manuscript)
        
        # 5. çµæœã‚µãƒãƒªãƒ¼
        hallucination_count = sum(1 for r in fact_check_results if r.is_hallucination)
        low_confidence_count = sum(1 for r in fact_check_results if r.verification_score < 0.5)
        
        return {
            "original_manuscript": manuscript,
            "corrected_manuscript": corrected_manuscript,
            "total_claims": len(claims),
            "hallucination_count": hallucination_count,
            "low_confidence_count": low_confidence_count,
            "fact_check_results": fact_check_results,
            "improvement_summary": self._generate_improvement_summary(fact_check_results)
        }

    def _save_results_to_obsidian(self, original: str, results: List[FactCheckResult], corrected: str):
        """çµæœã‚’Obsidianã«ä¿å­˜"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        content = f"""# åŸç¨¿äº‹å®Ÿç¢ºèªçµæœ - {timestamp}

## ğŸ“ å…ƒã®åŸç¨¿
{original}

## âœ… ä¿®æ­£ç‰ˆåŸç¨¿
{corrected}

## ğŸ” äº‹å®Ÿç¢ºèªè©³ç´°
"""
        
        for i, result in enumerate(results, 1):
            content += f"""
### {i}. ä¸»å¼µåˆ†æ
- **å…ƒã®ä¸»å¼µ**: {result.original_claim.content}
- **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³**: {'âŒ ã‚ã‚Š' if result.is_hallucination else 'âœ… ãªã—'}
- **æ¤œè¨¼ã‚¹ã‚³ã‚¢**: {result.verification_score:.2f}
- **æ¨å¥¨äº‹é …**: {result.recommendation}
- **ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•°**: {len(result.evidence_papers)}å€‹

"""

        filename = f"åŸç¨¿äº‹å®Ÿç¢ºèª_{timestamp}.md"
        file_path = self.obsidian_saver.vault_path / "fact-check-reports" / filename
        file_path.parent.mkdir(exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"ğŸ“ çµæœã‚’Obsidianã«ä¿å­˜: {filename}")

    def _generate_improvement_summary(self, results: List[FactCheckResult]) -> str:
        """æ”¹å–„ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        hallucinations = [r for r in results if r.is_hallucination]
        low_confidence = [r for r in results if r.verification_score < 0.5]
        
        summary = f"""
ğŸ¯ åŸç¨¿æ”¹å–„ã‚µãƒãƒªãƒ¼:
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ä¿®æ­£: {len(hallucinations)}ç®‡æ‰€
- ä¿¡é ¼æ€§å¼·åŒ–: {len(low_confidence)}ç®‡æ‰€
- å…¨ä½“çš„ãªä¿¡é ¼æ€§å‘ä¸Šåº¦: {(1 - len(hallucinations) / max(len(results), 1)) * 100:.0f}%
"""
        return summary