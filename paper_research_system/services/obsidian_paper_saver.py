#!/usr/bin/env python3
"""
è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ å°‚ç”¨Obsidianè‡ªå‹•ä¿å­˜æ©Ÿèƒ½ï¼ˆæ—¥æœ¬èªåŒ–å¯¾å¿œç‰ˆï¼‰
æ¤œç´¢çµæœã‚’è‡ªå‹•çš„ã«Obsidianã«ä¿å­˜ãƒ»åˆ†é¡
ã‚«ã‚¿ã‚«ãƒŠãµã‚ŠãŒãªãƒ»æ—¥æœ¬èªç¿»è¨³ãƒ»ã‚ã‹ã‚Šã‚„ã™ã„ãƒ•ã‚¡ã‚¤ãƒ«åå¯¾å¿œ
"""

from ..core.paper_model import Paper
import datetime
from pathlib import Path
from typing import Dict, List
import sys
import re
import requests
import json

# ç›¸å¯¾ãƒ‘ã‚¹ã®è§£æ±º
# Package-relative imports are used; no sys.path modification necessary


class ObsidianPaperSaver:
    """è«–æ–‡æ¤œç´¢çµæœã‚’Obsidianã«è‡ªå‹•ä¿å­˜ã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆæ—¥æœ¬èªåŒ–å¯¾å¿œï¼‰"""

    def __init__(self, obsidian_vault_path: str = None):
        # æ—¥æœ¬èªåŒ–æ©Ÿèƒ½ã®åˆæœŸåŒ–
        self._init_japanese_support()

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Obsidianãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆvoice-roleplay-systemã®docs/obsidian-knowledgeï¼‰
        if obsidian_vault_path is None:
            # paper_research_systemã‹ã‚‰ç›¸å¯¾çš„ã«vault_pathã‚’è¨­å®š
            current_dir = Path(__file__).parent.parent
            obsidian_vault_path = current_dir.parent / "docs" / "obsidian-knowledge"

        self.vault_path = Path(obsidian_vault_path)
        self.vault_path.mkdir(parents=True, exist_ok=True)

        # è«–æ–‡å°‚ç”¨ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ 
        self.folders = {
            "research-papers": self.vault_path / "research-papers",
            "sales-psychology": self.vault_path
            / "research-papers"
            / "sales-psychology",
            "management-psychology": self.vault_path
            / "research-papers"
            / "management-psychology",
            "behavioral-economics": self.vault_path
            / "research-papers"
            / "behavioral-economics",
            "general-psychology": self.vault_path
            / "research-papers"
            / "general-psychology",
            "search-sessions": self.vault_path / "research-papers" / "search-sessions",
        }

        # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        for folder in self.folders.values():
            folder.mkdir(parents=True, exist_ok=True)

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.domain_mapping = {
            "sales_psychology": "sales-psychology",
            "management_psychology": "management-psychology",
            "behavioral_economics": "behavioral-economics",
            "general_human_psychology": "general-psychology",
        }

        # æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã‚¿ã‚°
        self.thinking_mode_tags = {
            "thesis": "ãƒ†ãƒ¼ã‚¼",
            "antithesis": "ã‚¢ãƒ³ãƒãƒ†ãƒ¼ã‚¼",
            "synthesis": "ã‚¸ãƒ³ãƒ†ãƒ¼ã‚¼",
            "meta_analysis": "ãƒ¡ã‚¿åˆ†æ",
        }

    def _init_japanese_support(self):
        """æ—¥æœ¬èªåŒ–ã‚µãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®åˆæœŸåŒ–"""
        # è‹±èªåâ†’ã‚«ã‚¿ã‚«ãƒŠå¤‰æ›è¾æ›¸ï¼ˆä¸€èˆ¬çš„ãªç ”ç©¶è€…åï¼‰
        self.name_katakana_dict = {
            "John": "ã‚¸ãƒ§ãƒ³",
            "Jane": "ã‚¸ã‚§ãƒ¼ãƒ³",
            "Michael": "ãƒã‚¤ã‚±ãƒ«",
            "David": "ãƒ‡ãƒ´ã‚£ãƒƒãƒ‰",
            "Robert": "ãƒ­ãƒãƒ¼ãƒˆ",
            "William": "ã‚¦ã‚£ãƒªã‚¢ãƒ ",
            "Richard": "ãƒªãƒãƒ£ãƒ¼ãƒ‰",
            "Thomas": "ãƒˆãƒ¼ãƒã‚¹",
            "Christopher": "ã‚¯ãƒªã‚¹ãƒˆãƒ•ã‚¡ãƒ¼",
            "Daniel": "ãƒ€ãƒ‹ã‚¨ãƒ«",
            "Matthew": "ãƒã‚·ãƒ¥ãƒ¼",
            "Anthony": "ã‚¢ãƒ³ã‚½ãƒ‹ãƒ¼",
            "Mark": "ãƒãƒ¼ã‚¯",
            "Donald": "ãƒ‰ãƒŠãƒ«ãƒ‰",
            "Steven": "ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ³",
            "Paul": "ãƒãƒ¼ãƒ«",
            "Andrew": "ã‚¢ãƒ³ãƒ‰ãƒªãƒ¥ãƒ¼",
            "Joshua": "ã‚¸ãƒ§ã‚·ãƒ¥ã‚¢",
            "Kenneth": "ã‚±ãƒã‚¹",
            "Kevin": "ã‚±ãƒ“ãƒ³",
            "Brian": "ãƒ–ãƒ©ã‚¤ã‚¢ãƒ³",
            "George": "ã‚¸ãƒ§ãƒ¼ã‚¸",
            "Edward": "ã‚¨ãƒ‰ãƒ¯ãƒ¼ãƒ‰",
            "Ronald": "ãƒ­ãƒŠãƒ«ãƒ‰",
            "Timothy": "ãƒ†ã‚£ãƒ¢ã‚·ãƒ¼",
            "Jason": "ã‚¸ã‚§ã‚¤ã‚½ãƒ³",
            "Jeffrey": "ã‚¸ã‚§ãƒ•ãƒªãƒ¼",
            "Ryan": "ãƒ©ã‚¤ã‚¢ãƒ³",
            "Jacob": "ã‚¸ã‚§ã‚¤ã‚³ãƒ–",
            "Gary": "ã‚²ã‚¢ãƒªãƒ¼",
            "Nicholas": "ãƒ‹ã‚³ãƒ©ã‚¹",
            "Eric": "ã‚¨ãƒªãƒƒã‚¯",
            "Jonathan": "ã‚¸ãƒ§ãƒŠã‚µãƒ³",
            "Stephen": "ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ³",
            "Larry": "ãƒ©ãƒªãƒ¼",
            "Justin": "ã‚¸ãƒ£ã‚¹ãƒ†ã‚£ãƒ³",
            "Scott": "ã‚¹ã‚³ãƒƒãƒˆ",
            "Brandon": "ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ³",
            "Benjamin": "ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³",
            "Samuel": "ã‚µãƒŸãƒ¥ã‚¨ãƒ«",
            "Frank": "ãƒ•ãƒ©ãƒ³ã‚¯",
            "Gregory": "ã‚°ãƒ¬ã‚´ãƒªãƒ¼",
            "Raymond": "ãƒ¬ã‚¤ãƒ¢ãƒ³ãƒ‰",
            "Alexander": "ã‚¢ãƒ¬ã‚¯ã‚µãƒ³ãƒ€ãƒ¼",
            "Patrick": "ãƒ‘ãƒˆãƒªãƒƒã‚¯",
            "Jack": "ã‚¸ãƒ£ãƒƒã‚¯",
            "Dennis": "ãƒ‡ãƒ‹ã‚¹",
            "Jerry": "ã‚¸ã‚§ãƒªãƒ¼",
            "Mary": "ãƒ¡ã‚¢ãƒªãƒ¼",
            "Patricia": "ãƒ‘ãƒˆãƒªã‚·ã‚¢",
            "Jennifer": "ã‚¸ã‚§ãƒ‹ãƒ•ã‚¡ãƒ¼",
            "Linda": "ãƒªãƒ³ãƒ€",
            "Elizabeth": "ã‚¨ãƒªã‚¶ãƒ™ã‚¹",
            "Barbara": "ãƒãƒ¼ãƒãƒ©",
            "Susan": "ã‚¹ãƒ¼ã‚¶ãƒ³",
            "Jessica": "ã‚¸ã‚§ã‚·ã‚«",
            "Sarah": "ã‚µãƒ©",
            "Karen": "ã‚«ãƒ¬ãƒ³",
            "Nancy": "ãƒŠãƒ³ã‚·ãƒ¼",
            "Lisa": "ãƒªã‚µ",
            "Betty": "ãƒ™ãƒ†ã‚£",
            "Helen": "ãƒ˜ãƒ¬ãƒ³",
            "Sandra": "ã‚µãƒ³ãƒ‰ãƒ©",
            "Donna": "ãƒ‰ãƒŠ",
            "Carol": "ã‚­ãƒ£ãƒ­ãƒ«",
            "Ruth": "ãƒ«ãƒ¼ã‚¹",
            "Sharon": "ã‚·ãƒ£ãƒ­ãƒ³",
            "Michelle": "ãƒŸã‚·ã‚§ãƒ«",
            "Laura": "ãƒ­ãƒ¼ãƒ©",
            "Sarah": "ã‚µãƒ©",
            "Kimberly": "ã‚­ãƒ³ãƒãƒªãƒ¼",
            "Deborah": "ãƒ‡ãƒœãƒ©",
            "Dorothy": "ãƒ‰ãƒ­ã‚·ãƒ¼",
            "Amy": "ã‚¨ã‚¤ãƒŸãƒ¼",
            "Angela": "ã‚¢ãƒ³ã‚¸ã‚§ãƒ©",
            "Ashley": "ã‚¢ã‚·ãƒ¥ãƒªãƒ¼",
            "Brenda": "ãƒ–ãƒ¬ãƒ³ãƒ€",
            "Emma": "ã‚¨ãƒ",
            "Olivia": "ã‚ªãƒªãƒ“ã‚¢",
            "Cynthia": "ã‚·ãƒ³ã‚·ã‚¢",
        }

        # å­¦è¡“ç”¨èªç¿»è¨³è¾æ›¸
        self.academic_translation_dict = {
            "Abstract": "è¦ç´„",
            "Introduction": "åºè«–",
            "Methods": "æ‰‹æ³•",
            "Results": "çµæœ",
            "Discussion": "è€ƒå¯Ÿ",
            "Conclusion": "çµè«–",
            "References": "å‚è€ƒæ–‡çŒ®",
            "Keywords": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            "Background": "èƒŒæ™¯",
            "Methodology": "æ–¹æ³•è«–",
            "Analysis": "åˆ†æ",
            "Findings": "çŸ¥è¦‹",
            "Implications": "ç¤ºå”†",
            "Limitations": "é™ç•Œ",
            "Future work": "ä»Šå¾Œã®èª²é¡Œ",
            "Data": "ãƒ‡ãƒ¼ã‚¿",
            "Statistics": "çµ±è¨ˆ",
            "Survey": "èª¿æŸ»",
            "Study": "ç ”ç©¶",
            "Research": "ç ”ç©¶",
            "Business": "ãƒ“ã‚¸ãƒã‚¹",
            "Management": "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ",
            "Psychology": "å¿ƒç†å­¦",
            "Economics": "çµŒæ¸ˆå­¦",
            "Marketing": "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°",
            "Sales": "å–¶æ¥­",
            "Leadership": "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—",
            "Organization": "çµ„ç¹”",
            "Strategy": "æˆ¦ç•¥",
            "Performance": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
            "Success": "æˆåŠŸ",
            "Failure": "å¤±æ•—",
            "Growth": "æˆé•·",
            "Development": "ç™ºå±•",
            "Innovation": "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³",
            "Entrepreneurship": "èµ·æ¥­å®¶ç²¾ç¥",
            "Startup": "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—",
            "Enterprise": "ä¼æ¥­",
        }

        # æ¤œç´¢ã‚¯ã‚¨ãƒªâ†’æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›è¾æ›¸
        self.query_japanese_dict = {
            "business failure": "äº‹æ¥­å¤±æ•—çµ±è¨ˆ",
            "startup survival": "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç”Ÿå­˜ç‡",
            "entrepreneur development": "èµ·æ¥­å®¶ç™ºå±•æ®µéš",
            "small business": "ä¸­å°ä¼æ¥­ç ”ç©¶",
            "success timeline": "æˆåŠŸã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
            "leadership coaching": "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã‚³ãƒ¼ãƒãƒ³ã‚°",
            "sales psychology": "å–¶æ¥­å¿ƒç†å­¦",
            "management": "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆç ”ç©¶",
            "innovation": "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶",
            "growth strategy": "æˆé•·æˆ¦ç•¥",
            "business model": "ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«",
            "organizational behavior": "çµ„ç¹”è¡Œå‹•",
            "performance management": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†",
        }

    def _convert_name_to_katakana(self, name: str) -> str:
        """è‹±èªåã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›"""
        if not name:
            return name

        # ãƒ•ãƒ«ãƒãƒ¼ãƒ ã‚’åˆ†å‰²
        name_parts = name.strip().split()
        katakana_parts = []

        for part in name_parts:
            # è¾æ›¸ã«ã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            if part in self.name_katakana_dict:
                katakana_parts.append(f"{part}ï¼ˆ{self.name_katakana_dict[part]}ï¼‰")
            else:
                # è¾æ›¸ã«ãªã„å ´åˆã¯ç°¡æ˜“çš„ãªå¤‰æ›ã‚’è©¦è¡Œ
                katakana = self._simple_katakana_conversion(part)
                if katakana:
                    katakana_parts.append(f"{part}ï¼ˆ{katakana}ï¼‰")
                else:
                    katakana_parts.append(part)

        return " ".join(katakana_parts)

    def _simple_katakana_conversion(self, name: str) -> str:
        """ç°¡æ˜“çš„ãªã‚«ã‚¿ã‚«ãƒŠå¤‰æ›ï¼ˆåŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if not name or len(name) < 2:
            return ""

        # åŸºæœ¬çš„ãªéŸ³ç´ å¤‰æ›ãƒ«ãƒ¼ãƒ«
        conversion_rules = {
            "ch": "ãƒ",
            "sh": "ã‚·",
            "th": "ã‚¹",
            "ph": "ãƒ•",
            "a": "ã‚¢",
            "e": "ã‚¨",
            "i": "ã‚¤",
            "o": "ã‚ª",
            "u": "ã‚¦",
            "ka": "ã‚«",
            "ke": "ã‚±",
            "ki": "ã‚­",
            "ko": "ã‚³",
            "ku": "ã‚¯",
            "sa": "ã‚µ",
            "se": "ã‚»",
            "si": "ã‚·",
            "so": "ã‚½",
            "su": "ã‚¹",
            "ta": "ã‚¿",
            "te": "ãƒ†",
            "ti": "ãƒ",
            "to": "ãƒˆ",
            "tu": "ãƒ„",
            "na": "ãƒŠ",
            "ne": "ãƒ",
            "ni": "ãƒ‹",
            "no": "ãƒ",
            "nu": "ãƒŒ",
            "ha": "ãƒ",
            "he": "ãƒ˜",
            "hi": "ãƒ’",
            "ho": "ãƒ›",
            "hu": "ãƒ•",
            "ma": "ãƒ",
            "me": "ãƒ¡",
            "mi": "ãƒŸ",
            "mo": "ãƒ¢",
            "mu": "ãƒ ",
            "ya": "ãƒ¤",
            "ye": "ã‚¤ã‚§",
            "yi": "ã‚¤",
            "yo": "ãƒ¨",
            "yu": "ãƒ¦",
            "ra": "ãƒ©",
            "re": "ãƒ¬",
            "ri": "ãƒª",
            "ro": "ãƒ­",
            "ru": "ãƒ«",
            "wa": "ãƒ¯",
            "we": "ã‚¦ã‚§",
            "wi": "ã‚¦ã‚£",
            "wo": "ã‚¦ã‚©",
            "wu": "ã‚¦",
        }

        name_lower = name.lower()

        # æ—¢çŸ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ç°¡æ˜“å¤‰æ›ã‚’è©¦è¡Œï¼ˆé™å®šçš„ï¼‰
        if name_lower.endswith("son"):
            return "ã‚½ãƒ³"
        elif name_lower.endswith("man"):
            return "ãƒãƒ³"
        elif name_lower.endswith("er"):
            return "ãƒ¼"

        return ""  # å¤‰æ›ã§ããªã„å ´åˆã¯ç©ºæ–‡å­—

    def _translate_abstract_to_japanese(self, abstract: str) -> str:
        """è‹±èªè¦ç´„ã‚’æ—¥æœ¬èªã«ç¿»è¨³"""
        if not abstract:
            return abstract

        # æœ€åˆã«è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®éƒ¨åˆ†ç¿»è¨³ã‚’è©¦è¡Œ
        japanese_abstract = abstract
        for english_term, japanese_term in self.academic_translation_dict.items():
            japanese_abstract = re.sub(
                r"\b" + re.escape(english_term) + r"\b",
                japanese_term,
                japanese_abstract,
                flags=re.IGNORECASE,
            )

        # ç°¡æ˜“çš„ãªç¿»è¨³å‡¦ç†ã‚’è¿½åŠ ï¼ˆåŸºæœ¬çš„ãªæ–‡æ§‹é€ ã®èªè­˜ï¼‰
        if "This study" in abstract:
            japanese_abstract = japanese_abstract.replace("This study", "æœ¬ç ”ç©¶ã¯")
        if "The results" in abstract:
            japanese_abstract = japanese_abstract.replace("The results", "çµæœã¨ã—ã¦")
        if "We found" in abstract:
            japanese_abstract = japanese_abstract.replace("We found", "æˆ‘ã€…ã¯ç™ºè¦‹ã—ãŸ")
        if "Our findings" in abstract:
            japanese_abstract = japanese_abstract.replace("Our findings", "æˆ‘ã€…ã®çŸ¥è¦‹")

        return f"ã€æ—¥æœ¬èªç¿»è¨³ã€‘{japanese_abstract}\n\nã€åŸæ–‡ã€‘{abstract}"

    def _generate_japanese_filename(self, search_query: str) -> str:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‹ã‚‰æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
        # ã¾ãšã€æ—¢çŸ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        query_lower = search_query.lower()

        for english_pattern, japanese_title in self.query_japanese_dict.items():
            if english_pattern in query_lower:
                return japanese_title

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã—ãªã„å ´åˆã¯ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¿»è¨³ã‚’è©¦è¡Œ
        japanese_keywords = []
        words = re.split(r"[^\w]+", search_query.lower())

        for word in words:
            if word in self.academic_translation_dict:
                japanese_keywords.append(self.academic_translation_dict[word])
            elif len(word) > 2:  # çŸ­ã™ãã‚‹å˜èªã¯é™¤å¤–
                japanese_keywords.append(word)

        if japanese_keywords:
            return "_".join(
                japanese_keywords[:3]
            )  # æœ€å¤§3å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç‰¹æ®Šæ–‡å­—å›é¿ï¼‰

        return "è«–æ–‡æ¤œç´¢çµæœ"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    def save_search_results(
        self,
        papers: List[Paper],
        search_query: str,
        domain: str = "sales_psychology",
        thinking_mode: str = "thesis",
        metadata: Dict = None,
    ) -> Path:
        """æ¤œç´¢çµæœã‚’Obsidianã«ä¿å­˜"""

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        date_stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

        # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        japanese_title = self._generate_japanese_filename(search_query)
        filename = f"{timestamp.split()[0]}_{japanese_title}.md"

        # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€æ±ºå®š
        folder_name = self.domain_mapping.get(domain, "research-papers")
        folder = self.folders[folder_name]

        # ã‚¿ã‚°ç”Ÿæˆ
        tags = self._generate_tags(domain, thinking_mode, papers)

        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
        markdown_content = self._generate_markdown_content(
            papers, search_query, domain, thinking_mode, timestamp, tags, metadata
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        file_path = folder / filename
        file_path.write_text(markdown_content, encoding="utf-8")

        print(f"ğŸ“š è«–æ–‡æ¤œç´¢çµæœã‚’Obsidianã«ä¿å­˜: {filename}")
        print(f"ğŸ“ ã‚«ãƒ†ã‚´ãƒª: {folder_name}")
        print(f"ğŸ“„ è«–æ–‡æ•°: {len(papers)}ä»¶")

        return file_path

    def _generate_tags(
        self, domain: str, thinking_mode: str, papers: List[Paper]
    ) -> List[str]:
        """ã‚¿ã‚°ã‚’è‡ªå‹•ç”Ÿæˆ"""
        tags = ["è«–æ–‡æ¤œç´¢", "å­¦è¡“ç ”ç©¶"]

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚°
        domain_tags = {
            "sales_psychology": ["å–¶æ¥­å¿ƒç†å­¦", "ã‚»ãƒ¼ãƒ«ã‚¹", "é¡§å®¢å¿ƒç†"],
            "management_psychology": [
                "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦",
                "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—",
                "çµ„ç¹”è¡Œå‹•",
            ],
            "behavioral_economics": ["è¡Œå‹•çµŒæ¸ˆå­¦", "æ„æ€æ±ºå®š", "èªçŸ¥ãƒã‚¤ã‚¢ã‚¹"],
            "general_human_psychology": ["äººé–“å¿ƒç†å­¦", "ç¤¾ä¼šå¿ƒç†å­¦", "èªçŸ¥å¿ƒç†å­¦"],
        }
        tags.extend(domain_tags.get(domain, []))

        # æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã‚¿ã‚°
        mode_tag = self.thinking_mode_tags.get(thinking_mode, thinking_mode)
        tags.append(mode_tag)

        # è«–æ–‡ã®ç‰¹å¾´ã‹ã‚‰è¿½åŠ ã‚¿ã‚°
        high_citation_count = any(
            p.citation_count and p.citation_count > 1000
            for p in papers
            if p.citation_count
        )
        if high_citation_count:
            tags.append("é«˜è¢«å¼•ç”¨è«–æ–‡")

        recent_papers = any(
            p.publication_year and p.publication_year >= 2020
            for p in papers
            if p.publication_year
        )
        if recent_papers:
            tags.append("æœ€æ–°ç ”ç©¶")

        return tags

    def _generate_markdown_content(
        self,
        papers: List[Paper],
        search_query: str,
        domain: str,
        thinking_mode: str,
        timestamp: str,
        tags: List[str],
        metadata: Dict = None,
    ) -> str:
        """Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""

        domain_names = {
            "sales_psychology": "å–¶æ¥­å¿ƒç†å­¦",
            "management_psychology": "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆå¿ƒç†å­¦",
            "behavioral_economics": "è¡Œå‹•çµŒæ¸ˆå­¦",
            "general_human_psychology": "æ±ç”¨äººé–“å¿ƒç†å­¦",
        }

        thinking_mode_names = {
            "thesis": "ãƒ†ãƒ¼ã‚¼ï¼ˆä¸»æµç†è«–ï¼‰",
            "antithesis": "ã‚¢ãƒ³ãƒãƒ†ãƒ¼ã‚¼ï¼ˆåè«–ãƒ»æ–°è¦–ç‚¹ï¼‰",
            "synthesis": "ã‚¸ãƒ³ãƒ†ãƒ¼ã‚¼ï¼ˆçµ±åˆç†è«–ï¼‰",
            "meta_analysis": "ãƒ¡ã‚¿åˆ†æé‡è¦–",
        }

        content = f"""# ğŸ“š {search_query} - è«–æ–‡æ¤œç´¢çµæœ

> ğŸ” **æ¤œç´¢ã‚¯ã‚¨ãƒª**: {search_query}
> ğŸ“… **æ¤œç´¢æ—¥æ™‚**: {timestamp}
> ğŸ¯ **å°‚é–€åˆ†é‡**: {domain_names.get(domain, domain)}
> ğŸ§  **æ€è€ƒãƒ¢ãƒ¼ãƒ‰**: {thinking_mode_names.get(thinking_mode, thinking_mode)}
> ğŸ“Š **å–å¾—è«–æ–‡æ•°**: {len(papers)}ä»¶

## ğŸ“‹ æ¤œç´¢æ¦‚è¦

"""

        if metadata:
            content += f"""### ğŸ“ˆ æ¤œç´¢çµ±è¨ˆ
- **ç·æ¤œç´¢æ•°**: {metadata.get('total_found', 'N/A')}ä»¶
- **ãƒ•ã‚£ãƒ«ã‚¿å¾Œ**: {metadata.get('after_filtering', 'N/A')}ä»¶
- **æœ€çµ‚çµæœ**: {metadata.get('final_results', len(papers))}ä»¶

"""

        content += """## ğŸ“„ è«–æ–‡ä¸€è¦§

"""

        # å„è«–æ–‡ã®è©³ç´°
        for i, paper in enumerate(papers, 1):
            content += self._format_paper(paper, i)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if metadata and metadata.get("generated_queries"):
            content += f"""
## ğŸ” ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª

{chr(10).join([f"- {query}" for query in metadata['generated_queries']])}

"""

        # ã‚¿ã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content += f"""
## ğŸ·ï¸ ã‚¿ã‚°

{' '.join([f'#{tag}' for tag in tags])}

## ğŸ’¡ æ´»ç”¨æ–¹æ³•

ã“ã®æ¤œç´¢çµæœã¯ä»¥ä¸‹ã®ç”¨é€”ã§æ´»ç”¨ã§ãã¾ã™ï¼š

- **å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Š**: ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã®å–¶æ¥­æ‰‹æ³•ã®å­¦ç¿’
- **ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæ”¹å–„**: å­¦è¡“çš„æ ¹æ‹ ã«åŸºã¥ãçµ„ç¹”é‹å–¶
- **ç ”ä¿®è³‡æ–™ä½œæˆ**: è«–æ–‡ã®å¼•ç”¨ã«ã‚ˆã‚‹èª¬å¾—åŠ›ã®ã‚ã‚‹è³‡æ–™ä½œæˆ
- **æ›´ãªã‚‹ç ”ç©¶**: å¼•ç”¨æ–‡çŒ®ã‹ã‚‰ã®é–¢é€£ç ”ç©¶ã®ç™ºè¦‹

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯

- [[è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨æ–¹æ³•]]
- [[å–¶æ¥­å¿ƒç†å­¦ç ”ç©¶ãƒãƒ¼ãƒˆ]]
- [[ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹å–¶æ¥­æˆ¦ç•¥]]

---

*ğŸ“š ã“ã®æ¤œç´¢çµæœã¯è«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
*ğŸ”„ æœ€æ–°ã®ç ”ç©¶ã«ã¤ã„ã¦ã¯å®šæœŸçš„ãªå†æ¤œç´¢ã‚’ãŠå‹§ã‚ã—ã¾ã™*
"""

        return content

    def _format_paper(self, paper: Paper, index: int) -> str:
        """å€‹åˆ¥è«–æ–‡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ—¥æœ¬èªåŒ–å¯¾å¿œï¼‰"""

        # è‘—è€…åã‚’ã‚«ã‚¿ã‚«ãƒŠä»˜ãã§è¡¨ç¤º
        if paper.authors:
            author_names_with_katakana = []
            for author in paper.authors:
                katakana_name = self._convert_name_to_katakana(author.name)
                author_names_with_katakana.append(katakana_name)
            authors_display = ", ".join(author_names_with_katakana)
        else:
            authors_display = "N/A"

        content = f"""### {index}. ğŸ“„ {paper.title}

**åŸºæœ¬æƒ…å ±**:
- **è‘—è€…**: {authors_display}
- **ç™ºè¡¨å¹´**: {paper.publication_year if paper.publication_year else 'N/A'}å¹´
- **å¼•ç”¨æ•°**: {paper.citation_count if paper.citation_count is not None else 'N/A'}å›
- **æ²è¼‰ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«**: {paper.journal if paper.journal else 'N/A'}

"""

        if paper.doi:
            content += f"- **DOI**: {paper.doi}\n"

        if paper.url:
            content += f"- **URL**: {paper.url}\n"

        content += "\n"

        if paper.abstract:
            # è¦ç´„ã‚’æ—¥æœ¬èªç¿»è¨³
            translated_abstract = self._translate_abstract_to_japanese(paper.abstract)
            # æ¦‚è¦ã‚’é©åˆ‡ãªé•·ã•ã«åˆ¶é™
            if len(translated_abstract) > 500:
                translated_abstract = (
                    translated_abstract[:500]
                    + "...\n\nï¼ˆç¶šãã¯å…ƒè«–æ–‡ã‚’ã”ç¢ºèªãã ã•ã„ï¼‰"
                )
            content += f"**è¦ç´„**: \n{translated_abstract}\n\n"

        # ã‚¹ã‚³ã‚¢æƒ…å ±
        if hasattr(paper, "total_score") and paper.total_score:
            content += f"**ç·åˆã‚¹ã‚³ã‚¢**: {paper.total_score:.1f}\n"

        if hasattr(paper, "domain_score") and paper.domain_score:
            content += f"**ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¹ã‚³ã‚¢**: {paper.domain_score:.1f}\n"

        if hasattr(paper, "mode_score") and paper.mode_score:
            content += f"**ãƒ¢ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢**: {paper.mode_score:.1f}\n"

        content += "\n---\n\n"

        return content

    def save_search_session(self, session_data: Dict) -> Path:
        """æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’ä¿å­˜"""
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        date_stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³_{date_stamp}.md"
        folder = self.folders["search-sessions"]

        content = f"""# ğŸ” è«–æ–‡æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³

> ğŸ“… **ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹**: {timestamp}
> ğŸ¯ **æ¤œç´¢å›æ•°**: {session_data.get('search_count', 0)}å›

## ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ

- **ç·æ¤œç´¢è«–æ–‡æ•°**: {session_data.get('total_papers', 0)}ä»¶
- **ãƒ¦ãƒ‹ãƒ¼ã‚¯è«–æ–‡æ•°**: {session_data.get('unique_papers', 0)}ä»¶
- **å¹³å‡é–¢é€£æ€§ã‚¹ã‚³ã‚¢**: {session_data.get('avg_relevance', 0):.2f}

## ğŸ” å®Ÿè¡Œã—ãŸæ¤œç´¢

{chr(10).join([f"### {i + 1}. {search['query']}" + chr(10) + f"- **åˆ†é‡**: {search['domain']}" + chr(10) + f"- **ãƒ¢ãƒ¼ãƒ‰**: {search['thinking_mode']}" + chr(10) + f"- **çµæœ**: {search['result_count']}ä»¶" + chr(10) for i, search in enumerate(session_data.get('searches', []))])}

## ğŸ·ï¸ ã‚¿ã‚°

#æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³ #è«–æ–‡ç ”ç©¶ #å­¦è¡“èª¿æŸ»

---

*ğŸ¤– ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""

        file_path = folder / filename
        file_path.write_text(content, encoding="utf-8")

        print(f"ğŸ“ æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ã‚’Obsidianã«ä¿å­˜: {filename}")

        return file_path


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆç”¨ã®é–¢æ•°


def test_obsidian_paper_saver():
    """ãƒ†ã‚¹ãƒˆç”¨ã®è«–æ–‡ä¿å­˜"""
    from ..core.paper_model import Paper, Author

    # ãƒ†ã‚¹ãƒˆç”¨è«–æ–‡ãƒ‡ãƒ¼ã‚¿
    test_papers = [
        Paper(
            title="The Impact of Trust on Sales Performance: A Meta-Analysis",
            authors=[Author(name="John Smith"), Author(name="Jane Doe")],
            publication_year=2023,
            citation_count=150,
            abstract="This meta-analysis examines the relationship between trust and sales performance across 50 studies...",
            journal="Journal of Sales Research",
            doi="https://doi.org/10.1000/test.2023.001",
            source_api="semantic_scholar",
        )
    ]

    saver = ObsidianPaperSaver()

    file_path = saver.save_search_results(
        papers=test_papers,
        search_query="ä¿¡é ¼é–¢ä¿‚ã¨å–¶æ¥­æˆç¸¾",
        domain="sales_psychology",
        thinking_mode="thesis",
        metadata={"total_found": 15, "after_filtering": 8, "final_results": 1},
    )

    print(f"âœ… ãƒ†ã‚¹ãƒˆä¿å­˜å®Œäº†: {file_path}")


if __name__ == "__main__":
    test_obsidian_paper_saver()
