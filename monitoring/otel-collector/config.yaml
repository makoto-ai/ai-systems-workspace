receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 1s
    send_batch_size: 1024
  memory_limiter:
    check_interval: 1s
    limit_mib: 1500
  resource:
    attributes:
      - key: environment
        value: "production"
        action: upsert
      - key: service.name
        value: "ai-systems-hybrid"
        action: upsert

exporters:
  prometheus:
    endpoint: "0.0.0.0:9464"
    namespace: "ai_systems"
    const_labels:
      label1: value1
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
  logging:
    loglevel: debug
  otlp:
    endpoint: "http://prometheus:9090"
    tls:
      insecure: true

extensions:
  health_check:
    endpoint: "0.0.0.0:13133"
  pprof:
    endpoint: "0.0.0.0:1777"
  zpages:
    endpoint: "0.0.0.0:55679"

service:
  extensions: [health_check, pprof, zpages]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch, memory_limiter, resource]
      exporters: [logging, otlp]
    metrics:
      receivers: [otlp]
      processors: [batch, memory_limiter, resource]
      exporters: [prometheus, logging]
    logs:
      receivers: [otlp]
      processors: [batch, memory_limiter, resource]
      exporters: [logging] 