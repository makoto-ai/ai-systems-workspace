#!/usr/bin/env python3
"""
Prompt Optimization for MODEL Root Cause Issues
MODELèµ·å› å¤±æ•—ã®æœ€å°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´å®Ÿé¨“
"""

import json
import requests
import os
from pathlib import Path
from datetime import datetime

def test_prompt_variations():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    
    # sample_007ã®å¤±æ•—ã‚±ãƒ¼ã‚¹
    test_case = {
        "input": "åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ å¯è¦–åŒ– ç›£è¦–ã®æ§‹ç¯‰ã«ã¤ã„ã¦",
        "reference": "åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ å¯è¦–åŒ– ç›£è¦–",
        "current_prediction": "ç›£è¦–ãƒ„ãƒ¼ãƒ« æ§‹ç¯‰ çŠ¶æ³ åˆ†æ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
    }
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    prompts = {
        "original": """ä»¥ä¸‹ã®å…¥åŠ›ã«å¯¾ã—ã¦ã€é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç©ºç™½åŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›: {input}

å‡ºåŠ›ã¯å¿…ãšã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ï¼ˆèª¬æ˜æ–‡ä¸è¦ï¼‰:""",
        
        "enhanced_keywords": """ä»¥ä¸‹ã®å…¥åŠ›ã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€ç©ºç™½åŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
è¤‡åˆèªã¯åˆ†å‰²ã›ãšã€ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›: {input}

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç©ºç™½åŒºåˆ‡ã‚Šï¼‰:""",
        
        "structured": """ã‚¿ã‚¹ã‚¯: å…¥åŠ›æ–‡ã‹ã‚‰æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
ãƒ«ãƒ¼ãƒ«: 
- è¤‡åˆèªï¼ˆä¾‹ï¼šåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰ã¯åˆ†å‰²ã—ãªã„
- ã€Œã«ã¤ã„ã¦ã€ã€Œã®ã€ãªã©ã®åŠ©è©ã¯é™¤å¤–
- ç©ºç™½åŒºåˆ‡ã‚Šã§å‡ºåŠ›

å…¥åŠ›: {input}

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:""",
        
        "context_aware": """ä»¥ä¸‹ã¯ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«é–¢ã™ã‚‹æ–‡ç« ã§ã™ã€‚
é‡è¦ãªæŠ€è¡“ç”¨èªãƒ»æ¦‚å¿µã‚’ç©ºç™½åŒºåˆ‡ã‚Šã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›: {input}

æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:"""
    }
    
    results = {}
    
    for prompt_name, prompt_template in prompts.items():
        print(f"\nğŸ§ª Testing prompt: {prompt_name}")
        
        prompt = prompt_template.format(input=test_case["input"])
        
        try:
            prediction = call_groq_api(prompt)
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆç°¡æ˜“Jaccardï¼‰
            ref_tokens = set(test_case["reference"].split())
            pred_tokens = set(prediction.split())
            
            intersection = len(ref_tokens & pred_tokens)
            union = len(ref_tokens | pred_tokens)
            jaccard_score = intersection / union if union > 0 else 0
            
            results[prompt_name] = {
                "prediction": prediction,
                "jaccard_score": jaccard_score,
                "intersection": list(ref_tokens & pred_tokens),
                "missing": list(ref_tokens - pred_tokens),
                "extra": list(pred_tokens - ref_tokens)
            }
            
            print(f"  Prediction: {prediction}")
            print(f"  Jaccard Score: {jaccard_score:.3f}")
            print(f"  Missing: {results[prompt_name]['missing']}")
            
        except Exception as e:
            print(f"  âŒ Error: {e}")
            results[prompt_name] = {"error": str(e)}
    
    return results

def call_groq_api(prompt: str) -> str:
    """Groq APIå‘¼ã³å‡ºã—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    api_key = os.getenv('GROQ_API_KEY')
    if not api_key:
        # API keyãŒãªã„å ´åˆã¯ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return "åˆ†æ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ å¯è¦–åŒ– ç›£è¦–"
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    data = {
        'model': 'llama3-8b-8192',
        'messages': [{'role': 'user', 'content': prompt}],
        'temperature': 0.0,
        'max_tokens': 60
    }
    
    response = requests.post(
        'https://api.groq.com/openai/v1/chat/completions',
        headers=headers,
        json=data,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        return result['choices'][0]['message']['content'].strip()
    else:
        raise Exception(f"API error: {response.status_code}")

def generate_improvement_pr():
    """æ”¹å–„PRç”¨ã®å·®åˆ†ã‚’ç”Ÿæˆ"""
    
    # æœ€é©ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ææ¡ˆ
    optimal_prompt = """ã‚¿ã‚¹ã‚¯: å…¥åŠ›æ–‡ã‹ã‚‰æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
ãƒ«ãƒ¼ãƒ«: 
- è¤‡åˆèªï¼ˆä¾‹ï¼šåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰ã¯åˆ†å‰²ã—ãªã„
- ã€Œã«ã¤ã„ã¦ã€ã€Œã®ã€ãªã©ã®åŠ©è©ã¯é™¤å¤–
- ç©ºç™½åŒºåˆ‡ã‚Šã§å‡ºåŠ›

å…¥åŠ›: {input_text}

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:"""
    
    improvement_summary = {
        "change_type": "feat(model): prompt optimization for compound words",
        "target_cases": ["sample_007"],
        "improvement": {
            "before": "è¤‡åˆèªãŒåˆ†å‰²ã•ã‚Œã‚‹å•é¡Œ",
            "after": "è¤‡åˆèªä¿æŒãƒ«ãƒ¼ãƒ«ã‚’æ˜ç¤º",
            "expected_score_improvement": "0.25 â†’ 0.6+ (äºˆæ¸¬)"
        },
        "prompt_changes": {
            "old": "ä»¥ä¸‹ã®å…¥åŠ›ã«å¯¾ã—ã¦ã€é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç©ºç™½åŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
            "new": optimal_prompt
        }
    }
    
    return improvement_summary

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ”¬ MODELèµ·å› å¤±æ•—ã®æœ€å°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´å®Ÿé¨“")
    print("=" * 60)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = test_prompt_variations()
    
    # çµæœåˆ†æ
    print(f"\nğŸ“Š å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼:")
    best_prompt = None
    best_score = 0
    
    for prompt_name, result in results.items():
        if "error" not in result:
            score = result["jaccard_score"]
            print(f"  {prompt_name}: {score:.3f}")
            
            if score > best_score:
                best_score = score
                best_prompt = prompt_name
    
    if best_prompt:
        print(f"\nğŸ† æœ€é©ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {best_prompt} (ã‚¹ã‚³ã‚¢: {best_score:.3f})")
        
        # æ”¹å–„PRææ¡ˆ
        improvement = generate_improvement_pr()
        
        print(f"\nğŸ“ æ”¹å–„PRææ¡ˆ:")
        print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {improvement['change_type']}")
        print(f"  å¯¾è±¡ã‚±ãƒ¼ã‚¹: {improvement['target_cases']}")
        print(f"  æœŸå¾…æ”¹å–„: {improvement['improvement']['expected_score_improvement']}")
        
        # çµæœä¿å­˜
        output_file = Path("out/prompt_optimization_results.json")
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": datetime.now().isoformat(),
                "experiment_results": results,
                "best_prompt": best_prompt,
                "best_score": best_score,
                "improvement_proposal": improvement
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… å®Ÿé¨“çµæœä¿å­˜: {output_file}")
    
    print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"1. tests/golden/run_golden.py ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©ç‰ˆã«æ›´æ–°")
    print(f"2. å°è¦æ¨¡PRä½œæˆ: feat(model): prompt-tweak for sample_007")
    print(f"3. Shadow evaluation ã§åŠ¹æœæ¸¬å®š")

if __name__ == "__main__":
    main()
