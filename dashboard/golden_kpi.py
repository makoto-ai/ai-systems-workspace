#!/usr/bin/env python3
"""
Golden Test KPI Dashboard
Streamlit-based visualization for Golden Test metrics
"""

import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from datetime import datetime, timedelta
import re

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Golden Test KPI Dashboard",
    page_icon="ğŸ¯",
    layout="wide"
)

def load_golden_logs():
    """Golden Testã®ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
    logs_dir = Path("tests/golden/logs")
    if not logs_dir.exists():
        return pd.DataFrame()
    
    all_data = []
    for log_file in logs_dir.glob("*.jsonl"):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        data = json.loads(line)
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥æ™‚ã‚’æŠ½å‡º
                        date_str = log_file.stem  # 20250829_211416
                        try:
                            date_obj = datetime.strptime(date_str, "%Y%m%d_%H%M%S")
                            data['timestamp'] = date_obj
                            data['date'] = date_obj.date()
                            all_data.append(data)
                        except ValueError:
                            continue
        except Exception as e:
            st.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {log_file}: {e}")
            continue
    
    return pd.DataFrame(all_data)

def load_observation_log():
    """è¦³æ¸¬ãƒ­ã‚°ã‹ã‚‰é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    log_file = Path("tests/golden/observation_log.md")
    if not log_file.exists():
        return pd.DataFrame()
    
    weekly_data = []
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # é€±æ¬¡è¦³æ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
        pattern = r'## (\d{4}-\d{2}-\d{2}) - é€±æ¬¡è¦³æ¸¬.*?åˆæ ¼ç‡.*?(\d+)/(\d+) \((\d+)%\)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            date_str, passed, total, percentage = match
            
            # è©²å½“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰freshnessæƒ…å ±ã‚’æŠ½å‡º
            section_pattern = rf'## {re.escape(date_str)} - é€±æ¬¡è¦³æ¸¬(.*?)(?=## |\Z)'
            section_match = re.search(section_pattern, content, re.DOTALL)
            
            new_failures = 0
            total_failures = 0
            
            if section_match:
                section_content = section_match.group(1)
                # å¤±æ•—åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
                failure_matches = re.findall(r'- \*\*([^*]+)\*\*: `root_cause:([^`]+)`(?:\s*\|\s*`freshness:([^`]+)`)?', section_content)
                for case_id, root_cause, freshness in failure_matches:
                    total_failures += 1
                    if freshness == "NEW":
                        new_failures += 1
            
            new_fail_ratio = new_failures / max(total_failures, 1) if total_failures > 0 else 0.0
            
            weekly_data.append({
                'date': datetime.strptime(date_str, "%Y-%m-%d").date(),
                'passed': int(passed),
                'total': int(total),
                'pass_rate': int(percentage),
                'total_failures': total_failures,
                'new_failures': new_failures,
                'new_fail_ratio': new_fail_ratio
            })
    
    except Exception as e:
        st.error(f"è¦³æ¸¬ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return pd.DataFrame(weekly_data)

def analyze_failure_reasons(df):
    """å¤±æ•—ç†ç”±ã®åˆ†æï¼ˆRoot Causeåˆ†æå«ã‚€ï¼‰"""
    failed_cases = df[df['passed'] == False]
    if failed_cases.empty:
        return pd.DataFrame()
    
    failure_analysis = []
    for _, case in failed_cases.iterrows():
        ref_words = set(case['reference'].split())
        pred_words = set(case['prediction'].split()) if case['prediction'] else set()
        
        missing_words = ref_words - pred_words
        extra_words = pred_words - ref_words
        
        # Root Causeåˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        root_cause = analyze_root_cause(case['score'], missing_words, pred_words)
        
        failure_analysis.append({
            'case_id': case['id'],
            'score': case['score'],
            'missing_words': ', '.join(missing_words) if missing_words else 'ãªã—',
            'extra_words': ', '.join(extra_words) if extra_words else 'ãªã—',
            'missing_count': len(missing_words),
            'root_cause': root_cause,
            'date': case.get('date', 'Unknown')
        })
    
    return pd.DataFrame(failure_analysis)

def analyze_root_cause(score, missing_words, pred_words):
    """Root Causeç°¡æ˜“åˆ†æ"""
    if not pred_words:
        return "INFRA"
    elif score == 0:
        return "MODEL"
    elif score < 0.3 and missing_words:
        return "NORMALIZE"
    elif score < 0.7:
        return "TOKENIZE"
    else:
        return "FLAKY"

def calculate_flaky_rate(df):
    """Flakyç‡ã®è¨ˆç®—"""
    if df.empty:
        return 0.0
    
    failed_cases = df[df['passed'] == False]
    if failed_cases.empty:
        return 0.0
    
    # ã‚¹ã‚³ã‚¢0.7ä»¥ä¸Šã®å¤±æ•—ã‚’Flakyã¨åˆ¤å®š
    flaky_cases = failed_cases[failed_cases['score'] >= 0.7]
    return len(flaky_cases) / len(failed_cases) * 100

def load_shadow_evaluation():
    """Shadow Evaluationçµæœã‚’èª­ã¿è¾¼ã¿ï¼ˆæ®µéšæ˜‡æ ¼å¯¾å¿œï¼‰"""
    
    # æ®µéšæ˜‡æ ¼ç”¨ã‚°ãƒªãƒƒãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€å„ªå…ˆ
    grid_file = Path("out/shadow_grid.json") 
    if grid_file.exists():
        try:
            with open(grid_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            multi_eval = data.get("multi_shadow_evaluation", {})
            thresholds = multi_eval.get("thresholds", {})
            staged_promotion = multi_eval.get("staged_promotion", {})
            
            # ã‚°ãƒªãƒƒãƒ‰è©•ä¾¡çµæœã‚’å–å¾—
            grid_data = {}
            for threshold_str, threshold_data in thresholds.items():
                threshold = float(threshold_str)
                pass_rate = threshold_data.get("weighted_pass_rate", threshold_data.get("shadow_pass_rate", 0))
                grid_data[threshold_str] = pass_rate
            
            return {
                "0.7": grid_data.get("0.7", grid_data.get("0.70", 0)),
                "0.85": grid_data.get("0.85", 0),
                "grid": grid_data,
                "staged_promotion": staged_promotion,
                "weighted": any(thresholds[t].get("weighted_pass_rate") is not None for t in thresholds),
                "multi": True,
                "grid_enabled": True
            }
        except Exception as e:
            st.error(f"Grid evaluationèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒãƒ«ãƒã‚·ãƒ£ãƒ‰ãƒ¼è©•ä¾¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¬¡ã«ç¢ºèª
    multi_shadow_file = Path("out/shadow_multi.json")
    if multi_shadow_file.exists():
        try:
            with open(multi_shadow_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            multi_eval = data.get("multi_shadow_evaluation", {})
            thresholds = multi_eval.get("thresholds", {})
            
            # 0.7ã¨0.85ã®çµæœã‚’å–å¾—ï¼ˆé‡ã¿ä»˜ãå„ªå…ˆï¼‰
            threshold_0_7 = thresholds.get("0.7", {})
            threshold_0_85 = thresholds.get("0.85", {})
            
            shadow_0_7 = threshold_0_7.get("weighted_pass_rate", threshold_0_7.get("shadow_pass_rate", 0))
            shadow_0_85 = threshold_0_85.get("weighted_pass_rate", threshold_0_85.get("shadow_pass_rate", 0))
            
            return {
                "0.7": shadow_0_7,
                "0.85": shadow_0_85,
                "weighted": threshold_0_85.get("weighted_pass_rate") is not None,
                "multi": True,
                "grid_enabled": False
            }
        except Exception as e:
            st.error(f"Multi-shadow evaluationèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å¾“æ¥ã®0.7å˜ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    shadow_file = Path("out/shadow_0_7.json")
    if shadow_file.exists():
        try:
            with open(shadow_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            shadow_0_7 = data["shadow_evaluation"]["shadow_pass_rate"]
            return {
                "0.7": shadow_0_7,
                "0.85": 0.0,  # ãƒ‡ãƒ¼ã‚¿ãªã—
                "weighted": False,
                "multi": False,
                "grid_enabled": False
            }
        except Exception as e:
            st.error(f"Shadow evaluationèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return {
        "0.7": 0.0,
        "0.85": 0.0,
        "weighted": False,
        "multi": False,
        "grid_enabled": False
    }

def load_canary_window_status():
    """Canary 7-Day Windowè©•ä¾¡çµæœã‚’èª­ã¿è¾¼ã¿"""
    canary_file = Path("out/canary_window.json")
    if canary_file.exists():
        try:
            with open(canary_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            decision = data.get("decision", "unknown")
            avg_pass_rate = data.get("metrics", {}).get("avg_pass_rate", 0)
            
            if decision == "promote":
                status = "âœ… æœ¬æ¡ç”¨"
                decision_text = "è‡ªå‹•æ˜‡æ ¼"
            elif decision == "continue_canary":
                status = f"ğŸ¤ ç¶™ç¶š ({avg_pass_rate:.1f}%)"
                decision_text = "æ”¹å–„è¦æ±‚"
            else:
                status = "â“ ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
                decision_text = "æ‰‹å‹•ç¢ºèª"
            
            return status, decision_text
            
        except Exception as e:
            st.error(f"Canary windowèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return "âŒ ã‚¨ãƒ©ãƒ¼", "èª­ã¿è¾¼ã¿å¤±æ•—"
    else:
        return "â³ è©•ä¾¡å¾…ã¡", "æœªå®Ÿè¡Œ"

def calculate_model_efficiency(df):
    """ãƒ¢ãƒ‡ãƒ«åˆ¥åŠ¹ç‡æ€§ã®è¨ˆç®—ï¼ˆåˆæ ¼1ä»¶ã‚ãŸã‚Šã®è©¦è¡Œå›æ•°ï¼‰"""
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã¯è©¦è¡Œå›æ•°ã®æƒ…å ±ãŒãªã„ãŸã‚ã€
    # åˆæ ¼ç‡ã‹ã‚‰æ¨å®šåŠ¹ç‡ã‚’è¨ˆç®—
    model_stats = []
    
    for date in df['date'].unique():
        day_data = df[df['date'] == date]
        if day_data.empty:
            continue
            
        total_cases = len(day_data)
        passed_cases = len(day_data[day_data['passed'] == True])
        pass_rate = passed_cases / total_cases if total_cases > 0 else 0
        
        # åŠ¹ç‡æ€§ã®æ¨å®šï¼ˆåˆæ ¼1ä»¶ã‚ãŸã‚Šã®æƒ³å®šè©¦è¡Œå›æ•°ï¼‰
        efficiency = 1 / pass_rate if pass_rate > 0 else float('inf')
        
        model_stats.append({
            'date': date,
            'model': 'Groq (llama-3.3-70b)',  # ç¾åœ¨å›ºå®š
            'total_cases': total_cases,
            'passed_cases': passed_cases,
            'pass_rate': pass_rate,
            'trials_per_success': efficiency
        })
    
    return pd.DataFrame(model_stats)

# ãƒ¡ã‚¤ãƒ³ç”»é¢
st.title("ğŸ¯ Golden Test KPI Dashboard")
st.markdown("AIãƒ¢ãƒ‡ãƒ«å‡ºåŠ›å“è³ªã®ç¶™ç¶šç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
    df = load_golden_logs()
    weekly_df = load_observation_log()

if df.empty and weekly_df.empty:
    st.warning("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Golden Testã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
if not df.empty:
    date_range = st.sidebar.date_input(
        "æœŸé–“é¸æŠ",
        value=(df['date'].min(), df['date'].max()),
        min_value=df['date'].min(),
        max_value=df['date'].max()
    )
    
    # æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if len(date_range) == 2:
        start_date, end_date = date_range
        df_filtered = df[(df['date'] >= start_date) & (df['date'] <= end_date)]
    else:
        df_filtered = df
else:
    df_filtered = df

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
col1, col2, col3, col4, col5, col6, col7, col8 = st.columns(8)
    
    # Canary 7-Day Windowè©•ä¾¡ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºå‰ã«å–å¾—ï¼‰
    canary_status, canary_decision = load_canary_window_status()

    if not df_filtered.empty:
        total_cases = len(df_filtered)
        passed_cases = len(df_filtered[df_filtered['passed'] == True])
        pass_rate = passed_cases / total_cases * 100 if total_cases > 0 else 0
        avg_score = df_filtered['score'].mean()
        flaky_rate = calculate_flaky_rate(df_filtered)
        
        # New Fail Ratioè¨ˆç®—ï¼ˆé€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        if not weekly_df.empty and 'new_fail_ratio' in weekly_df.columns:
            latest_new_fail_ratio = weekly_df.iloc[-1]['new_fail_ratio'] * 100
        else:
            latest_new_fail_ratio = 0.0
        
        # Shadow Evaluationçµæœèª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ã—ãã„å€¤å¯¾å¿œï¼‰
        shadow_data = load_shadow_evaluation()
        
        col1.metric("ç·ãƒ†ã‚¹ãƒˆæ•°", total_cases)
        col2.metric("åˆæ ¼æ•°", passed_cases)
        col3.metric("åˆæ ¼ç‡", f"{pass_rate:.1f}%")
        col4.metric("å¹³å‡ã‚¹ã‚³ã‚¢", f"{avg_score:.3f}")
        col5.metric("Flakyç‡", f"{flaky_rate:.1f}%")
        col6.metric("æ–°è¦å¤±æ•—ç‡", f"{latest_new_fail_ratio:.1f}%")
        col7.metric("Predicted@0.7", f"{shadow_data['0.7']:.1f}%")
        
        # Phase4 Gapè¨ˆç®—
        phase4_gap = max(0, 85.0 - shadow_data['0.85']) if shadow_data['0.85'] > 0 else 85.0
        gap_status = "âœ… æº–å‚™å®Œäº†" if phase4_gap <= 0 else f"ğŸ”„ Gap: {phase4_gap:.1f}pp"
        
        col8.metric("Predicted@0.85", f"{shadow_data['0.85']:.1f}%", 
                   delta=gap_status)
    
    # Canary 7-Day Windowè¡¨ç¤ºï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡Œã®ä¸‹ï¼‰
    st.subheader("ğŸ¤ Canary 7-Day Window Status")
    col_canary1, col_canary2 = st.columns(2)
    col_canary1.metric("Status", canary_status)
    col_canary2.metric("Decision", canary_decision)
    
    # é‡ã¿ä»˜ãè©•ä¾¡ã®è¡¨ç¤º
    if shadow_data.get('weighted', False):
        st.info("ğŸ¯ **é‡ã¿ä»˜ãè©•ä¾¡**: é »å‡ºå¤±æ•—ãƒ»é‡è¦ã‚±ãƒ¼ã‚¹ã‚’1.5xé‡ã¿ã§è©•ä¾¡ä¸­")

# 1. é€±æ¬¡åˆæ ¼ç‡ï¼ˆãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆï¼‰
st.header("ğŸ“ˆ é€±æ¬¡åˆæ ¼ç‡ãƒˆãƒ¬ãƒ³ãƒ‰")

if not weekly_df.empty:
    fig_weekly = px.line(
        weekly_df, 
        x='date', 
        y='pass_rate',
        title='é€±æ¬¡åˆæ ¼ç‡ã®æ¨ç§»',
        labels={'pass_rate': 'åˆæ ¼ç‡ (%)', 'date': 'æ—¥ä»˜'},
        markers=True
    )
    
    # ã—ãã„å€¤ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
    fig_weekly.add_hline(y=90, line_dash="dash", line_color="green", 
                        annotation_text="ç›®æ¨™: 90%")
    fig_weekly.add_hline(y=80, line_dash="dash", line_color="orange", 
                        annotation_text="è­¦å‘Š: 80%")
    
    fig_weekly.update_layout(height=400)
    st.plotly_chart(fig_weekly, use_container_width=True)
    
    # æ–°è¦å¤±æ•—ç‡ãƒˆãƒ¬ãƒ³ãƒ‰
    if 'new_fail_ratio' in weekly_df.columns:
        st.subheader("ğŸ“Š æ–°è¦å¤±æ•—ç‡ãƒˆãƒ¬ãƒ³ãƒ‰")
        fig_new_fail = px.line(
            weekly_df,
            x='date',
            y='new_fail_ratio',
            title='é€±æ¬¡æ–°è¦å¤±æ•—ç‡ã®æ¨ç§»',
            labels={'new_fail_ratio': 'æ–°è¦å¤±æ•—ç‡', 'date': 'æ—¥ä»˜'},
            markers=True
        )
        fig_new_fail.update_traces(line_color='red')
        fig_new_fail.update_layout(
            height=300,
            yaxis=dict(tickformat=".1%")
        )
        st.plotly_chart(fig_new_fail, use_container_width=True)

    # æ®µéšæ˜‡æ ¼ã‚°ãƒªãƒƒãƒ‰å¯è¦–åŒ–
st.subheader("ğŸš€ æ®µéšæ˜‡æ ¼ã‚°ãƒªãƒƒãƒ‰")

shadow_data = load_shadow_evaluation()

# æ®µéšæ˜‡æ ¼æƒ…å ±è¡¨ç¤º
if shadow_data.get('grid_enabled') and 'staged_promotion' in shadow_data:
    staged_promotion = shadow_data['staged_promotion']
    
    # Next Recommended Thresholdè¡¨ç¤º
    st.subheader("ğŸ¯ Next Recommended Threshold")
    next_col1, next_col2, next_col3 = st.columns(3)
    
    with next_col1:
        current_threshold = staged_promotion.get('current_threshold', 0.5)
        st.metric("Current Threshold", f"{current_threshold:.2f}")
    
    with next_col2:
        next_recommended = staged_promotion.get('next_recommended', 0.5)
        promotion_step = staged_promotion.get('promotion_step', 0)
        st.metric("Next Recommended", f"{next_recommended:.2f}", 
                 delta=f"+{promotion_step:.2f}" if promotion_step > 0 else "å¾…æ©Ÿä¸­")
    
    with next_col3:
        promotion_ready = staged_promotion.get('promotion_ready', False)
        status_text = "âœ… æ˜‡æ ¼å¯èƒ½" if promotion_ready else "ğŸŸ¡ æ¡ä»¶å¾…ã¡"
        st.metric("æ˜‡æ ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", status_text)
    
    # ã‚°ãƒªãƒƒãƒ‰å¯è¦–åŒ–
    if 'grid' in shadow_data and shadow_data['grid']:
        st.subheader("ğŸ“Š ã—ãã„å€¤ã‚°ãƒªãƒƒãƒ‰åˆ†æ")
        
        grid_data = shadow_data['grid']
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        thresholds = sorted([float(t) for t in grid_data.keys()])
        pass_rates = [grid_data[str(t)] for t in thresholds]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        statuses = []
        for rate in pass_rates:
            if rate >= 80:
                statuses.append('âœ… æ˜‡æ ¼å¯èƒ½')
            elif rate >= 70:
                statuses.append('ğŸ”„ æ”¹å–„ä¸­')
            else:
                statuses.append('âŒ è¦æ”¹å–„')
        
        grid_df = pd.DataFrame({
            'Threshold': [f"{t:.2f}" for t in thresholds],
            'Pass Rate': pass_rates,
            'Status': statuses
        })
        
        # æ£’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–
        fig_grid = px.bar(
            grid_df,
            x='Threshold',
            y='Pass Rate',
            title='æ®µéšæ˜‡æ ¼ã‚°ãƒªãƒƒãƒ‰: ã—ãã„å€¤åˆ¥äºˆæ¸¬åˆæ ¼ç‡',
            labels={'Pass Rate': 'äºˆæ¸¬åˆæ ¼ç‡ (%)', 'Threshold': 'ã—ãã„å€¤'},
            color='Pass Rate',
            color_continuous_scale='RdYlGn',
            text='Status'
        )
        
        # åŸºæº–ç·šè¿½åŠ 
        fig_grid.add_hline(y=85, line_dash="dash", line_color="red", 
                          annotation_text="Phase 4åŸºæº–: 85%")
        fig_grid.add_hline(y=80, line_dash="dash", line_color="green", 
                          annotation_text="æ˜‡æ ¼åŸºæº–: 80%")
        fig_grid.add_hline(y=70, line_dash="dash", line_color="orange", 
                          annotation_text="Phase 3åŸºæº–: 70%")
        
        # Next Recommendedã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if promotion_ready:
            next_idx = thresholds.index(next_recommended) if next_recommended in thresholds else -1
            if next_idx >= 0:
                fig_grid.add_shape(
                    type="rect",
                    x0=next_idx - 0.4,
                    x1=next_idx + 0.4,
                    y0=0,
                    y1=pass_rates[next_idx] + 5,
                    line=dict(color="gold", width=3),
                    fillcolor="gold",
                    opacity=0.2
                )
        
        fig_grid.update_traces(textposition='outside')
        fig_grid.update_layout(height=500, showlegend=False)
        
        st.plotly_chart(fig_grid, use_container_width=True)
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.subheader("ğŸ“‹ ã‚°ãƒªãƒƒãƒ‰è©³ç´°")
        st.dataframe(grid_df, use_container_width=True)

# å¾“æ¥ã®Shadow Evaluationæ¯”è¼ƒï¼ˆã‚°ãƒªãƒƒãƒ‰ãŒãªã„å ´åˆï¼‰
elif shadow_data['multi'] and shadow_data['0.85'] > 0:
    st.subheader("ğŸ”® Shadow Evaluation æ¯”è¼ƒ")
    # 0.7ã¨0.85ã®æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ
    shadow_comparison_data = {
        'Threshold': ['0.7 (Current)', '0.85 (Phase 4)'],
        'Pass Rate': [shadow_data['0.7'], shadow_data['0.85']],
        'Status': ['âœ… é‹ç”¨ä¸­' if shadow_data['0.7'] >= 70 else 'âš ï¸ è¦æ”¹å–„', 
                  'âœ… æº–å‚™å®Œäº†' if shadow_data['0.85'] >= 85 else 'ğŸ”„ æº–å‚™ä¸­']
    }
    
    fig_shadow = px.bar(
        shadow_comparison_data,
        x='Threshold',
        y='Pass Rate',
        title='Shadow Evaluation: ã—ãã„å€¤åˆ¥äºˆæ¸¬åˆæ ¼ç‡',
        labels={'Pass Rate': 'äºˆæ¸¬åˆæ ¼ç‡ (%)', 'Threshold': 'ã—ãã„å€¤'},
        color='Pass Rate',
        color_continuous_scale='RdYlGn',
        text='Status'
    )
    
    # åŸºæº–ç·šè¿½åŠ 
    fig_shadow.add_hline(y=85, line_dash="dash", line_color="red", 
                        annotation_text="Phase 4åŸºæº–: 85%")
    fig_shadow.add_hline(y=70, line_dash="dash", line_color="orange", 
                        annotation_text="Phase 3åŸºæº–: 70%")
    
    fig_shadow.update_traces(textposition='outside')
    fig_shadow.update_layout(height=400, showlegend=False)
    
    st.plotly_chart(fig_shadow, use_container_width=True)
    
    # Phase 4æ˜‡æ ¼æ¡ä»¶è¡¨ç¤ºï¼ˆå¼·åŒ–ç‰ˆï¼‰
    phase4_gap = max(0, 85.0 - shadow_data['0.85']) if shadow_data['0.85'] > 0 else 85.0
    latest_new_fail_ratio = latest_new_fail_ratio if not weekly_df.empty else 0.0
    new_fail_ok = latest_new_fail_ratio <= 70.0
    
    st.info(f"""
    **Phase 4 æ˜‡æ ¼æ¡ä»¶**:
    - Predicted@0.85 â‰¥ 85% (ç¾åœ¨: {shadow_data['0.85']:.1f}%, Gap: {phase4_gap:.1f}pp)
    - 2é€±é€£ç¶šã§æ¡ä»¶é”æˆ
    - new_fail_ratio â‰¤ 70% (ç¾åœ¨: {latest_new_fail_ratio:.1f}% {'âœ…' if new_fail_ok else 'âŒ'})
    
    **ç¾åœ¨ã®çŠ¶æ³**: {'âœ… æ¡ä»¶é”æˆ' if shadow_data['0.85'] >= 85 and new_fail_ok else 'ğŸ”„ æ”¹å–„ç¶™ç¶šä¸­'}
    
    **æ®‹ã‚Šæ”¹å–„é …ç›®**:
    {f'- Predicted@0.85ã‚’{phase4_gap:.1f}ppå‘ä¸Š' if phase4_gap > 0 else ''}
    {f'- æ–°è¦å¤±æ•—ç‡ã‚’{latest_new_fail_ratio - 70:.1f}ppå‰Šæ¸›' if not new_fail_ok else ''}
    """)
    
    # Phase4 Gapã‚«ãƒ¼ãƒ‰è¡¨ç¤º
    st.subheader("ğŸ“Š Phase 4 Gap Analysis")
    gap_col1, gap_col2, gap_col3 = st.columns(3)
    
    with gap_col1:
        st.metric("Phase 4 Gap", f"{phase4_gap:.1f}pp", 
                 delta=f"ç›®æ¨™ã¾ã§{phase4_gap:.1f}pp" if phase4_gap > 0 else "ç›®æ¨™é”æˆ")
    
    with gap_col2:
        # Flakyç‡ã¨Newå¤±æ•—ç‡ã®ã‚µãƒ–æŒ‡æ¨™
        st.metric("Flakyç‡", f"{flaky_rate:.1f}%", 
                 delta="è¦æ”¹å–„" if flaky_rate > 15 else "è‰¯å¥½")
    
    with gap_col3:
        st.metric("æ–°è¦å¤±æ•—ç‡", f"{latest_new_fail_ratio:.1f}%",
                 delta="è‰¯å¥½" if new_fail_ok else "è¦æ”¹å–„")
else:
    st.info("ğŸ“Š Phase 4 Shadow Evaluation ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    st.code("python tests/golden/runner.py --threshold-shadow '0.7,0.85' --report out/shadow_multi.json")
else:
    st.info("é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è¦³æ¸¬ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# 2. å¤±æ•—ç†ç”±ã®ä¸Šä½ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
st.header("ğŸ” å¤±æ•—ç†ç”±åˆ†æ")

if not df_filtered.empty:
    failure_df = analyze_failure_reasons(df_filtered)
    
    if not failure_df.empty:
        # Root Cause Top3ã®è¡¨ç¤º
        st.subheader("ğŸ“Š Root Cause Top3")
        root_cause_counts = failure_df['root_cause'].value_counts().head(3)
        
        if not root_cause_counts.empty:
            col1, col2, col3 = st.columns(3)
            
            for i, (cause, count) in enumerate(root_cause_counts.items()):
                percentage = (count / len(failure_df)) * 100
                with [col1, col2, col3][i]:
                    st.metric(
                        f"#{i+1} {cause}",
                        f"{count}ä»¶",
                        f"{percentage:.1f}%"
                    )
        
        # ä¸è¶³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é »åº¦åˆ†æ
        st.subheader("ğŸ”¤ ä¸è¶³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸Šä½10")
        missing_words_flat = []
        for words_str in failure_df['missing_words']:
            if words_str != 'ãªã—':
                missing_words_flat.extend(words_str.split(', '))
        
        if missing_words_flat:
            missing_freq = pd.Series(missing_words_flat).value_counts().head(10)
            
            fig_failures = px.bar(
                x=missing_freq.values,
                y=missing_freq.index,
                orientation='h',
                title='ä¸è¶³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é »åº¦',
                labels={'x': 'å‡ºç¾å›æ•°', 'y': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'}
            )
            fig_failures.update_layout(height=400)
            st.plotly_chart(fig_failures, use_container_width=True)
        else:
            st.success("åˆ†ææœŸé–“ä¸­ã«å¤±æ•—ã‚±ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼")
    else:
        st.success("åˆ†ææœŸé–“ä¸­ã«å¤±æ•—ã‚±ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼")
else:
    st.info("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# 3. ãƒ¢ãƒ‡ãƒ«åˆ¥åŠ¹ç‡æ€§ï¼ˆè¡¨å½¢å¼ï¼‰
st.header("âš¡ ãƒ¢ãƒ‡ãƒ«åŠ¹ç‡æ€§")

if not df_filtered.empty:
    efficiency_df = calculate_model_efficiency(df_filtered)
    
    if not efficiency_df.empty:
        # åŠ¹ç‡æ€§ãƒ†ãƒ¼ãƒ–ãƒ«
        st.subheader("åˆæ ¼1ä»¶ã‚ãŸã‚Šã®æ¨å®šè©¦è¡Œå›æ•°")
        
        display_df = efficiency_df[['date', 'model', 'total_cases', 'passed_cases', 'pass_rate', 'trials_per_success']].copy()
        display_df['pass_rate'] = display_df['pass_rate'].apply(lambda x: f"{x*100:.1f}%")
        display_df['trials_per_success'] = display_df['trials_per_success'].apply(
            lambda x: f"{x:.2f}" if x != float('inf') else "âˆ"
        )
        
        display_df.columns = ['æ—¥ä»˜', 'ãƒ¢ãƒ‡ãƒ«', 'ç·ã‚±ãƒ¼ã‚¹æ•°', 'åˆæ ¼æ•°', 'åˆæ ¼ç‡', 'è©¦è¡Œå›æ•°/åˆæ ¼']
        st.dataframe(display_df, use_container_width=True)
    else:
        st.info("åŠ¹ç‡æ€§ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿"):
    if not df_filtered.empty:
        st.subheader("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è©³ç´°")
        detail_df = df_filtered[['id', 'date', 'score', 'passed', 'reference', 'prediction']].copy()
        detail_df = detail_df.sort_values('date', ascending=False)
        st.dataframe(detail_df, use_container_width=True)
    
    if not weekly_df.empty:
        st.subheader("é€±æ¬¡è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(weekly_df, use_container_width=True)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("ğŸ¯ **Golden Test Dashboard** - AIãƒ¢ãƒ‡ãƒ«å“è³ªã®ç¶™ç¶šçš„ç›£è¦–")
st.markdown(f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
