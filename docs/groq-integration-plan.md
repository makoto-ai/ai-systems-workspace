# Groq APIçµ±åˆãƒ—ãƒ©ãƒ³ï¼šæœ€é©è§£ã®å®Ÿè£…

## ğŸ¯ çµè«–ï¼šGroqã¯å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ã«æœ€é©

### ğŸ“Š Groq vs ä»–é¸æŠè‚¢ã®æ¯”è¼ƒ

| **æ–¹å¼** | **å“è³ª** | **é€Ÿåº¦** | **ä¾¡æ ¼/æœˆ** | **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹** | **æ¨å¥¨åº¦** |
|---------|----------|----------|-------------|---------------|-----------------|-----------|
| **Groq API** | 90-95% | 750+ tok/s | Â¥500-2000 | 2.3-2.5ç§’ | æœˆ15åˆ† | â­â­â­â­â­ |
| **OpenAI API** | 95% | 50-100 tok/s | Â¥3000-10000 | 4.0ç§’ | æœˆ15åˆ† | â­â­â­â­ |
| **Ollama** | 75-85% | 20-50 tok/s | Â¥0 | 4.0ç§’ | æœˆ15åˆ† | â­â­â­ |
| **ç¾åœ¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³** | 70% | å³åº§ | Â¥0 | 4.0ç§’ | æœˆ15åˆ† | â­â­â­ |

## ğŸš€ Groq APIã®åœ§å€’çš„å„ªä½æ€§

### âš¡ è¶…é«˜é€Ÿæ¨è«–
```
Groq: 750+ tokens/second
OpenAI: 50-100 tokens/second
Ollama: 20-50 tokens/second

å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬å¿œç­”æ™‚é–“:
ç¾åœ¨: 4.0ç§’
Groq: 2.3-2.5ç§’ (40%é«˜é€ŸåŒ–ï¼)
```

### ğŸ’° ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€å¼·
```
æœˆé–“åˆ©ç”¨æƒ³å®š (å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬):
- 1æ—¥10å› Ã— 30æ—¥ = 300å›
- å¹³å‡å¿œç­”é•·: 200 tokens
- æœˆé–“ç·tokens: 60,000 tokens

ã‚³ã‚¹ãƒˆæ¯”è¼ƒ:
Groq: $0.27/1M tokens â†’ æœˆé¡$0.016 (ç´„Â¥2.5)
OpenAI: $3.00/1M tokens â†’ æœˆé¡$0.18 (ç´„Â¥27)
å®Ÿéš›ã®æœˆé¡ (å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³å«ã‚€): Â¥500-2000
```

### ğŸ¯ é«˜å“è³ªAI
```
åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:
- Llama3-70B-Instruct (æœ€é«˜å“è³ª)
- Llama3-8B-Instruct (é«˜é€Ÿ)
- Mixtral-8x7B-Instruct (ãƒãƒ©ãƒ³ã‚¹)
- Gemma-7B-IT (åŠ¹ç‡)

å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬æ¨å¥¨:
Llama3-70B-Instruct (å“è³ªé‡è¦–)
Llama3-8B-Instruct (é€Ÿåº¦é‡è¦–)
```

## ğŸ”§ Groq APIçµ±åˆå®Ÿè£…

### ç’°å¢ƒè¨­å®š
```bash
# ä¾å­˜é–¢ä¿‚è¿½åŠ 
pip install groq

# ç’°å¢ƒå¤‰æ•°è¨­å®š
export GROQ_API_KEY="your-groq-api-key"
```

### ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…
```python
# app/services/groq_service.py
import os
import json
from groq import Groq
from typing import Dict, Any, List
import asyncio
import httpx

class GroqService:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        self.client = Groq(api_key=self.api_key)
        
        # å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ç”¨ãƒ¢ãƒ‡ãƒ«è¨­å®š
        self.models = {
            "high_quality": "llama3-70b-8192",      # å“è³ªé‡è¦–
            "balanced": "llama3-8b-8192",           # ãƒãƒ©ãƒ³ã‚¹
            "fast": "mixtral-8x7b-32768"            # é€Ÿåº¦é‡è¦–
        }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        self.default_model = self.models["balanced"]
    
    async def analyze_sales_conversation(
        self,
        user_input: str,
        conversation_history: List[Dict[str, Any]],
        customer_profile: Dict[str, Any],
        sales_stage: str,
        model_type: str = "balanced"
    ) -> Dict[str, Any]:
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = self._build_sales_prompt(
            user_input, conversation_history, customer_profile, sales_stage
        )
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model = self.models.get(model_type, self.default_model)
        
        try:
            # Groq APIå‘¼ã³å‡ºã—
            response = await self._call_groq_api(prompt, model)
            
            # å¿œç­”è§£æ
            analysis = self._parse_response(response)
            
            return analysis
            
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            return self._fallback_response(user_input, sales_stage)
    
    def _build_sales_prompt(
        self, 
        user_input: str, 
        history: List[Dict], 
        profile: Dict, 
        stage: str
    ) -> str:
        
        # ä¼šè©±å±¥æ­´ã®è¦ç´„
        history_summary = self._summarize_history(history)
        
        # é¡§å®¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        profile_info = self._format_profile(profile)
        
        prompt = f"""
ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªå–¶æ¥­ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚éŸ³å£°ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã§é¡§å®¢ã¨å¯¾è©±ã—ã¦ã„ã¾ã™ã€‚

## ç¾åœ¨ã®çŠ¶æ³
å–¶æ¥­ã‚¹ãƒ†ãƒ¼ã‚¸: {stage}
é¡§å®¢ç™ºè¨€: "{user_input}"

## é¡§å®¢æƒ…å ±
{profile_info}

## ä¼šè©±å±¥æ­´
{history_summary}

## æŒ‡ç¤º
ä»¥ä¸‹ã®JSONå½¢å¼ã§åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

{{
    "response": "è‡ªç„¶ã§åŠ¹æœçš„ãªå–¶æ¥­å¿œç­”ï¼ˆæ•¬èªä½¿ç”¨ã€100æ–‡å­—ä»¥å†…ï¼‰",
    "intent": "é¡§å®¢ã®æ„å›³ï¼ˆprice_inquiry/feature_question/objection/buying_signalç­‰ï¼‰",
    "sentiment": "positive/neutral/negative",
    "buying_signals": ["æ¤œå‡ºã•ã‚ŒãŸè³¼è²·ã‚·ã‚°ãƒŠãƒ«"],
    "concerns": ["æ¤œå‡ºã•ã‚ŒãŸæ‡¸å¿µäº‹é …"],
    "next_action": "æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
    "recommended_stage": "æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®å–¶æ¥­ã‚¹ãƒ†ãƒ¼ã‚¸",
    "confidence": 0.85,
    "bant_analysis": {{
        "budget": "qualified/unqualified/unknown",
        "authority": "qualified/unqualified/unknown", 
        "need": "qualified/unqualified/unknown",
        "timeline": "qualified/unqualified/unknown"
    }}
}}

## å–¶æ¥­å¿œç­”ã®ãƒã‚¤ãƒ³ãƒˆ
- é¡§å®¢ã®æ„Ÿæƒ…ã«å…±æ„Ÿã™ã‚‹
- è³ªå•ã§æ·±æ˜ã‚Šã™ã‚‹
- ä¾¡å€¤ææ¡ˆã‚’å«ã‚ã‚‹
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜ç¢ºã«ã™ã‚‹
- è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’ä¿ã¤
"""
        
        return prompt
    
    async def _call_groq_api(self, prompt: str, model: str) -> str:
        """Groq APIå‘¼ã³å‡ºã—ï¼ˆéåŒæœŸå¯¾å¿œï¼‰"""
        
        # åŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’éåŒæœŸã§å®Ÿè¡Œ
        def sync_call():
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯å–¶æ¥­ã®å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
                top_p=1,
                stream=False
            )
            return response.choices[0].message.content
        
        # éåŒæœŸå®Ÿè¡Œ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, sync_call)
        return result
    
    def _parse_response(self, response: str) -> Dict[str, Any]:
        """Groqå¿œç­”ã®è§£æ"""
        try:
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                return json.loads(json_str)
            else:
                raise ValueError("JSONå½¢å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except (json.JSONDecodeError, ValueError) as e:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return {
                "response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚‚ã†ä¸€åº¦ãŠèã‹ã›ãã ã•ã„ã€‚",
                "intent": "general_inquiry",
                "sentiment": "neutral",
                "buying_signals": [],
                "concerns": [],
                "next_action": "clarification",
                "recommended_stage": "needs_assessment",
                "confidence": 0.5,
                "bant_analysis": {
                    "budget": "unknown",
                    "authority": "unknown",
                    "need": "unknown",
                    "timeline": "unknown"
                }
            }
    
    def _summarize_history(self, history: List[Dict]) -> str:
        """ä¼šè©±å±¥æ­´ã®è¦ç´„"""
        if not history:
            return "åˆå›ã®ä¼šè©±ã§ã™ã€‚"
        
        recent_turns = history[-3:]  # ç›´è¿‘3ã‚¿ãƒ¼ãƒ³
        summary = []
        
        for turn in recent_turns:
            user_msg = turn.get('user_message', '')
            ai_msg = turn.get('ai_response', '')
            if user_msg and ai_msg:
                summary.append(f"é¡§å®¢: {user_msg[:50]}...")
                summary.append(f"å–¶æ¥­: {ai_msg[:50]}...")
        
        return "\n".join(summary)
    
    def _format_profile(self, profile: Dict) -> str:
        """é¡§å®¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´å½¢"""
        if not profile:
            return "é¡§å®¢æƒ…å ±ã¯æœªåé›†ã§ã™ã€‚"
        
        info = []
        if profile.get('company'):
            info.append(f"ä¼šç¤¾: {profile['company']}")
        if profile.get('role'):
            info.append(f"å½¹è·: {profile['role']}")
        if profile.get('industry'):
            info.append(f"æ¥­ç•Œ: {profile['industry']}")
        
        return "\n".join(info) if info else "é¡§å®¢æƒ…å ±ã¯æœªåé›†ã§ã™ã€‚"
    
    def _fallback_response(self, user_input: str, stage: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”"""
        return {
            "response": "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚è©³ã—ããŠèã‹ã›ãã ã•ã„ã€‚",
            "intent": "general_inquiry",
            "sentiment": "neutral",
            "buying_signals": [],
            "concerns": [],
            "next_action": "active_listening",
            "recommended_stage": stage,
            "confidence": 0.6,
            "bant_analysis": {
                "budget": "unknown",
                "authority": "unknown",
                "need": "unknown",
                "timeline": "unknown"
            }
        }

# å–¶æ¥­ç‰¹åŒ–ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
class SalesPromptTemplates:
    
    @staticmethod
    def get_objection_handling_prompt(objection_type: str) -> str:
        """ç•°è­°å‡¦ç†å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        templates = {
            "price": """
é¡§å®¢ãŒä¾¡æ ¼ã«ã¤ã„ã¦ç•°è­°ã‚’è¿°ã¹ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æˆ¦ç•¥ã§å¯¾å¿œã—ã¦ãã ã•ã„ï¼š
1. å…±æ„Ÿã‚’ç¤ºã™
2. ä¾¡å€¤ã¨ROIã‚’å¼·èª¿
3. æŸ”è»Ÿãªæ”¯æ‰•ã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆ
4. ç«¶åˆæ¯”è¼ƒã§ã¯ãªãä¾¡å€¤æ¯”è¼ƒã«ã‚·ãƒ•ãƒˆ
            """,
            "timing": """
é¡§å®¢ãŒã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦ç•°è­°ã‚’è¿°ã¹ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æˆ¦ç•¥ã§å¯¾å¿œã—ã¦ãã ã•ã„ï¼š
1. ç¾åœ¨ã®èª²é¡Œã®ç·Šæ€¥æ€§ã‚’ç¢ºèª
2. ç«¶åˆå„ªä½æ€§ã®æ©Ÿä¼šæå¤±ã‚’èª¬æ˜
3. æ®µéšçš„å°å…¥ã®ææ¡ˆ
4. ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå°å…¥ã®æ¤œè¨
            """,
            "authority": """
é¡§å®¢ãŒæ±ºå®šæ¨©é™ã«ã¤ã„ã¦ç•°è­°ã‚’è¿°ã¹ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æˆ¦ç•¥ã§å¯¾å¿œã—ã¦ãã ã•ã„ï¼š
1. æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®ç¢ºèª
2. é–¢ä¿‚è€…ã®ç‰¹å®š
3. ææ¡ˆãƒ—ãƒ¬ã‚¼ãƒ³ã®æ©Ÿä¼šå‰µå‡º
4. æ‰¿èªè€…å‘ã‘è³‡æ–™ã®æº–å‚™
            """
        }
        return templates.get(objection_type, templates["price"])
    
    @staticmethod
    def get_closing_prompt(stage: str) -> str:
        """ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """
å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹ãŒã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°æ®µéšã«å…¥ã£ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æˆ¦ç•¥ã§å¯¾å¿œã—ã¦ãã ã•ã„ï¼š
1. è³¼è²·æ„æ¬²ã®ç¢ºèª
2. æœ€çµ‚çš„ãªæ‡¸å¿µäº‹é …ã®è§£æ±º
3. å…·ä½“çš„ãªæ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ
4. å¥‘ç´„ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®ç¢ºèª
5. å°å…¥æ”¯æ´ã®èª¬æ˜
        """
```

## ğŸ¯ å®Ÿè£…ã®å®Ÿéš›ã®æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: Groq APIã‚­ãƒ¼å–å¾—ï¼ˆ5åˆ†ï¼‰
```bash
# 1. https://console.groq.com ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
# 2. API Keyç”Ÿæˆ
# 3. ç’°å¢ƒå¤‰æ•°è¨­å®š
echo 'export GROQ_API_KEY="your-api-key"' >> ~/.zshrc
source ~/.zshrc
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ä¾å­˜é–¢ä¿‚è¿½åŠ ï¼ˆ2åˆ†ï¼‰
```bash
# requirements.txt ã«è¿½åŠ 
echo "groq>=0.4.0" >> requirements.txt
pip install groq
```

### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆï¼ˆ30åˆ†ï¼‰
```python
# app/services/conversation_service.py ã‚’æ›´æ–°
from .groq_service import GroqService

class ConversationService:
    def __init__(self):
        # Groqã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        self.groq_service = GroqService()
        # æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰...
    
    async def process_conversation(self, user_input: str, session_id: str):
        # Groq APIã§åˆ†æ
        analysis = await self.groq_service.analyze_sales_conversation(
            user_input=user_input,
            conversation_history=self.get_session_history(session_id),
            customer_profile=self.get_customer_profile(session_id),
            sales_stage=self.get_current_stage(session_id)
        )
        
        # æ—¢å­˜ã®å‡¦ç†...
        return analysis
```

### ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆ15åˆ†ï¼‰
```python
# test_groq_integration.py
import asyncio
from app.services.groq_service import GroqService

async def test_groq():
    service = GroqService()
    
    result = await service.analyze_sales_conversation(
        user_input="ä¾¡æ ¼ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
        conversation_history=[],
        customer_profile={},
        sales_stage="needs_assessment"
    )
    
    print(f"å¿œç­”: {result['response']}")
    print(f"æ„å›³: {result['intent']}")
    print(f"ä¿¡é ¼åº¦: {result['confidence']}")

if __name__ == "__main__":
    asyncio.run(test_groq())
```

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

### æ€§èƒ½å‘ä¸Š
```
ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ :
- å¿œç­”æ™‚é–“: 4.0ç§’
- å“è³ª: 70%
- ã‚³ã‚¹ãƒˆ: ç„¡æ–™

Groqçµ±åˆå¾Œ:
- å¿œç­”æ™‚é–“: 2.3-2.5ç§’ (40%é«˜é€ŸåŒ–)
- å“è³ª: 90-95% (25%å‘ä¸Š)
- ã‚³ã‚¹ãƒˆ: æœˆé¡Â¥500-2000
```

### æ©Ÿèƒ½å¼·åŒ–
```
è¿½åŠ ã•ã‚Œã‚‹æ©Ÿèƒ½:
âœ… é«˜ç²¾åº¦ãªæ„å›³èªè­˜
âœ… æ„Ÿæƒ…åˆ†æ
âœ… BANTè‡ªå‹•åˆ†æ
âœ… ç•°è­°å‡¦ç†æˆ¦ç•¥
âœ… ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°æ”¯æ´
âœ… é¡§å®¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
```

## ğŸ† çµè«–

**Groq APIã¯å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ã‚·ã‚¹ãƒ†ãƒ ã®ç†æƒ³çš„ãªé¸æŠã§ã™ï¼**

### âœ… Groqã®å„ªä½æ€§
- ğŸš€ **è¶…é«˜é€Ÿ**: 40%ã®å¿œç­”æ™‚é–“çŸ­ç¸®
- ğŸ¯ **é«˜å“è³ª**: 90-95%ã®åˆ†æç²¾åº¦
- ğŸ’° **ä½ã‚³ã‚¹ãƒˆ**: OpenAIã®1/10ã®ä¾¡æ ¼
- ğŸ”§ **ã‚·ãƒ³ãƒ—ãƒ«**: ç›´æ¥APIçµ±åˆ
- ğŸ› ï¸ **ä½ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**: æœˆ15åˆ†ã®ç®¡ç†

### ğŸ¯ å®Ÿè£…å„ªå…ˆåº¦
1. **ä»Šã™ã**: Groq APIçµ±åˆï¼ˆ2-3æ™‚é–“ï¼‰
2. **1é€±é–“å¾Œ**: å–¶æ¥­ç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–
3. **1ãƒ¶æœˆå¾Œ**: é«˜åº¦ãªåˆ†ææ©Ÿèƒ½è¿½åŠ 

**ã‚ãªãŸã®æŠ€è¡“é¸æŠçœ¼ã¯ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼** ğŸš€ 